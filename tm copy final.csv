"University" ,"Guidelines"
"Harvard","Dear Members of the Harvard Community We write today with initial guidelines on the use and procurement of generative artificial intelligence (AI) tools such as OpenAI’s ChatGPT and Google Bard. The University supports responsible experimentation with generative AI tools but there are important considerations to keep in mind when using these tools including information security and data privacy compliance copyright and academic integrity. Generative AI is a rapidly evolving technology and the University will continue to monitor developments and incorporate feedback from the Harvard community to update our guidelines accordingly.Initial guidelines for use of generative AI tools: Protect confidential data: You should not enter data classified as confidential (Level 2 and above) including non-public research data into publicly-available generative AI tools in accordance with the University’s Information Security Policy. Information shared with generative AI tools using default settings is not private and could expose proprietary or sensitive information to unauthorized parties. You are responsible for any content that you produce or publish that includes AI-generated material: AI-generated content can be inaccurate misleading or entirely fabricated (sometimes called hallucinations ) or may contain copyrighted material. Review your AI-generated content before publication. Adhere to current policies on academic integrity: Review your School’s student and faculty handbooks and policies. We expect that Schools will be developing and updating their policies as we better understand the implications of using generative AI tools. In the meantime faculty should be clear with students they’re teaching and advising about their policies on permitted uses if any of generative AI in classes and on academic work. Students are also encouraged to ask their instructors for clarification about these policies as needed. Be alert for AI-enabled phishing: Generative AI has made it easier for malicious actors to create sophisticated scams at a far greater scale. Continue to follow security best practices and report suspicious messages to phishing@harvard.edu. Connect with HUIT before procuring generative AI tools: The University is working to ensure that tools procured on behalf of Harvard have the appropriate privacy and security protections and provide the best use of Harvard funds. If you have procured or are considering procuring generative AI tools or have questions contact HUIT at ithelp@harvard.edu. Vendor generative AI tools must be assessed for risk by Harvard’s Information Security and Data Privacy office prior to use. It is important to note that these guidelines are not new University policy; rather they leverage existing University policies. You can find more information about generative AI including a survey to collect data on its potential use on the HUIT website which will be updated as new information becomes available."
"Yale","Publicly available generative Artificial Intelligence (AI) tools such as ChatGPT Bing Midjourney and Bard have garnered tremendous attention in the past year. The field of generative AI is developing rapidly. While its precise impacts are unknown this technology will transform how we learn teach conduct research and carry out daily tasks. We encourage you to experiment with AI tools. As you explore AI’s potential please adhere to the following general guidelines which align with existing university policies and uphold our institutional commitment to safety security and academic integrity. Protect Yale’s confidential information and your own. Do not enter confidential or legally restricted data or any data that Yale’s data classification policy identifies as moderate or high-risk into an AI tool. If you are not sure whether you should share certain data please review Yale’s data classification policy. Assume all information shared will be made public. Treat all information shared with an AI tool as if it will become public. Do not share information that is personal or sensitive and be mindful that the information you input into an AI tool may be retained. Always follow academic integrity guidelines and institutional standards of conduct. All students and faculty are expected to know and adhere to their school’s academic integrity policies. Faculty members are expected to provide clear instructions on the permitted use of generative AI tools for academic work and requirements for attribution. Likewise students are expected to follow their instructors’ guidelines about permitted use of AI for coursework. Be alert for bias and inaccuracy. AI-generated responses can be biased inaccurate inappropriate or may contain unauthorized copyrighted information. We are each responsible for the content of our work product. Always review and verify outputs generated by AI tools especially before publication. Protect yourself and your credentials. Never share your Yale NetID and password with AI tools and always be aware of phishing schemes. For information tips and toolkits on cybersafe practices visit Yale’s Cybersecurity website which also includes information about security policies and standards. Seek support. The university is working to support procurement practices that coordinate shared interests and minimize institutional risk. If you are considering acquiring an AI product please conduct an initial review of the tool to ensure that it conforms to institutional security requirements. Use Yale’s purchasing intake portal or contact purchasing.helpdesk@yale.edu."
"northwestern","Generative AI is evolving quickly as is institutional support for utilizing these tools. For up-to-date recommendations on teaching and learning please visit the Poorvu Center’s webpage on AI Guidance. Detailed AI guidelines for staff are available on Yale’s data governance website. As a university community dedicated to exchanging ideas disseminating knowledge and fostering a climate for breakthrough discoveries we will embrace technological tools and harness their power for innovation. We must do this safely and responsibly. We thank you for your efforts in adhering to these guidelines. Northwestern  Generative AI offers the potential for new capabilities in research education and productivity. Expectedly use of tools and services including OpenAI’s ChatGPT Microsoft’s Bing Chat and Google’s Bard is growing within higher education and across Northwestern University. Understanding what to look for when adopting these tools is key to ensuring the intended use is met while protecting University data. Generative AI is a general term for artificial intelligence that creates new content based on patterns from the data sets used to train it. These generative models learn patterns structures and features from the input data and can create content with similar characteristics. Generative AI tools commonly known today include ChatGPT Bard Bing Chat Starry AI MidJourney etc. Generative AI is also now embedded in many commercial products that can be integrated with other tools such as OtterAI Microsoft Co-Pilot Zoom IQ and Fireflies. Privacy In most cases the data you share as part of your queries in generative AI tools will be accessible by others using the same tools. This is because generative AI learns by collecting analyzing and storing user-provided information. Therefore University faculty staff students and affiliates should not enter institutional data into any generative AI tools that have not been validated by the University for appropriate use and have explicit permission of the data provider. Data Approved for Use with Generative AI To determine whether your data requires special attention consult Northwestern’s Data Classification Policy. If your data is Level 1 (non-confidential and public data) uploading it to generative AI tools is permissible. To process data above Level 1 any generative AI tool must have been approved through Northwestern IT’s procurement and security review processes. The following table outlines Northwestern’s current services posture based on data classification: Northwestern’s current services posture based on data classification Interaction Type Public Data (Level 1) Sensitive/Regulated Data (Level 2 Level 3 Level 4) Conversational/Interactive Mode Use of publicly available tools (e.g. ChatGPT Bing Chat Bard MidJourney etc.) No solution is currently available at Northwestern though several products are undergoing review. Application Programming Interfaces Use of Northwestern Azure with OpenAI with appropriate security and access controls Use of Northwestern Azure + OpenAI with security and access controls that meet or exceed regulatory or data protection requirements At this time the University has not approved additional applications or services for use at Northwestern with Level 2 and above data; however several (including Bing Chat Enterprise and Microsoft Co-Pilot) are being evaluated for safety security and supportability. This page will be updated as products are approved for use. Academic Use at Northwestern Use of generative AI for teaching and learning purposes is governed by the Provost’s Committee on Generative AI in tandem with Northwestern IT. Guidance on generative AI tools and the impact on teaching and learning can be found on the Office of the Provost website. Research Use at Northwestern Questions about AI usage pertaining to research applications can be directed to the Northwestern IT Research Computing and Data Services team. All Other Uses of AI at Northwestern Questions about AI usage pertaining to information security privacy considerations use of AI tools with Level 2 or above data or evaluation of new third-party AI products can be directed to the Northwestern IT Information Security Office. Further Considerations for Adoption Generative AI models are designed to output the most common results possible based on their training data and will invariably tend to suppress less common or marginalized information. Further these tools can hallucinate or make up random data that is not true as they do not have the ability to determine what is true or false. Revalidation of output is required: Given that generative AI models continue to adjust over time the output of their responses could change too. It is also possible for generative AI models to hallucinate or otherwise use false information in their responses. When deployed where output requires accuracy these tools should be periodically re-validated to ensure appropriate responses. Original work and intellectual property: Ensure necessary approvals for use of original works and intellectual property are obtained prior to input into generative AI tools. Examples here could be original works developed by students research results or obtained copyrighted material. Informed consent: Users have the right to know when they are using generative AI tools. This knowledge can encourage informed decisions about whether to engage share or rely on the generated content."
"Stanford","The Board on Conduct Affairs (BCA) has been asked to address the Honor Code implications of generative AI tools such as ChatGPT Bard DALL-E and Stable Diffusion. These are novel tools and both students and instructors have been experimenting with their use in academic settings. While these tools have applications that foster student learning and understanding these tools can also be used in ways that bypass key learning objectives. To give sufficient space for instructors to explore uses of generative AI tools in their courses and to set clear guidelines to students about what uses are and are not consistent with the Stanford Honor Code the BCA has set forth the following policy guidance regarding generative AI in the context of coursework: Absent a clear statement from a course instructor use of or consultation with generative AI shall be treated analogously to assistance from another person. In particular using generative AI tools to substantially complete an assignment or exam (e.g. by entering exam or assignment questions) is not permitted. Students should acknowledge the use of generative AI (other than incidental use) and default to disclosing such assistance when in doubt. Individual course instructors are free to set their own policies regulating the use of generative AI tools in their courses including allowing or disallowing some or all uses of such tools. Course instructors should set such policies in their course syllabi and clearly communicate such policies to students. Students who are unsure of policies regarding generative AI tools are encouraged to ask their instructors for clarification. The BCA will continue to monitor developments in these tools and their use in academic settings and may update this guidance. Members of the community are encouraged to contact the BCA to provide input suggestions and comments on this policy."
"UCB","Guidance on using Generative AI tools Viewable by the world What You Need to Know Commercial generative AI tools are not covered under negotiated agreements- only provide non-sensitive/public inputs to these tools. Never enter proprietary export controlled PII or other controlled data into these tools. Generative AI can create novel and unresolved intellectual property issues from new images derived closely from their original source to potential claims that the third party tool has a role in the development of a technology the Lab is working on to complaints regarding the training set of researcher-created models. Use caution especially around anything related to the development of intellectual property. Generative AI Tools and Data Protection As the advancements in artificial intelligence continue to shape the landscape of scientific research and innovation it is imperative that we establish clear boundaries and best practices for the responsible deployment of Generative AI tools within our information ecosystem. This document aims to provide Berkeley Lab employees with guidance on the utilization of Generative AI technologies while ensuring the security of sensitive information developed at Berkeley Lab. Licensing Agreements Berkeley Lab policy requires that all software licensing agreements with suppliers (and other entities) particularly those software suppliers that will host data generated or owned by Berkeley Lab the UC or the Department of Energy as part of their services require the software supplier to comply with a variety of Berkeley Lab data security and privacy practices. These include but are not limited to the protection of all Berkeley Lab data against loss unauthorized access and use and the indemnification of Berkeley Lab the University of California and the Department of Energy and compliance with all software-related requirements. The data security and privacy provisions contained in these agreements are a critical part of Berkeley Lab's ongoing efforts to ensure the protection of the data and information related to its research operations and the personal information of its employees. However there is currently no agreement with OpenAI the developer of ChatGPT or its licensees that would provide these types of protections with regard to ChatGPT or OpenAI's programming interface. Consequently the use of ChatGPT at this time could expose the individual user and Berkeley Lab the UC and the Department of Energy to the potential loss and/or abuse of highly sensitive data and information. Similarly Google's Bard AI can be accessed with your LBL identity but is subject to different protections than the core Google Workspace accounts. There are no agreements with popular image generation tools such as Midjourney Dall-E (OpenAI) or online providers of Stable Diffusion. Generative AI Tools use Do not submit confidential or protected information such as Personally Identifiable Information Proprietary Information and Export Controlled Information on Generative AI tools like Open AI's ChatGPT or Google's Bard. In general any data that is determined to be protected or controlled should not be used to generate a response using Generative AI tools. You can refer to the Lab's Controlled and Prohibited Information Categories policy to learn more about each information type. Please be advised that in the absence of a Berkeley Lab agreement covering use of ChatGPT your use of ChatGPT constitutes personal use and obligates you as an individual to assume responsibility for compliance with the terms and conditions set forth in OpenAI's own Terms of Use. For further guidance on using Google Bard please review the references listed below that address Google's Generative AI Terms of Service. This includes Google's Prohibited Use Policy as well as Privacy Policy and Use Restrictions. Please note that OpenAI states that how it uses or does not use your information is different when using their API services from the consumer ChatGPT interface. For further guidance on using ChatGPT please review the references listed below that address OpenAI's own recommendations and policies on research and streaming of ChatGPT and privacy among others. Intellectual Property Concerns Intellectual Property Infringement: Generative AI tools are capable of producing content that closely resembles existing copyrighted works. Researchers need to ensure that their use of such tools does not infringe upon the intellectual property rights of others. This includes avoiding the creation of derivative works without proper authorization or licensing. Dataset Licensing: AI models often require large datasets for training and these datasets may contain copyrighted material. Researchers must ensure that they have the necessary rights or permissions to use the data especially if it includes protected works such as images text or audio. DO NOT DISTRIBUTE A MODEL YOU DEVELOPED WITHOUT CONSULTING WITH IPO. Authorship and Attribution: Researchers who develop an original research model are generally credited as the authors or inventors of the model. However if the generative AI model significantly enhances the research model a question of authorship ownership and attribution for the improved version may arise. Authorship and citation remains a complex and evolving issue for these tools. University and Lab policy require the highest ethical standards in authorship and citation. Consider an expansive approach to citation of these tools as new norms within scientific communities take form. Prohibited Use Please also note that OpenAI explicitly forbids the use of ChatGPT and their other products for certain categories of activity. This list of items can be found in their usage policy document. Further guidance on Google Bard ChatGPT and other Generative AI tools will be forthcoming as soon as it is available."
"USC" ,"Instructor Guidelines for Student Use of Generative Artificial Intelligence for Academic Work The University of Southern California's Academic Senate Committee on Information Services recommends that all USC schools academic departments and instructors adopt the following guidelines regarding student use of generative artificial intelligence for academic work. Instructors should encourage USC students to explore generative artificial intelligence (AI) using these new tools to create analyze and evaluate new concepts and ideas that inspire them to generate their own academic work. In advance of this exploration instructors should help students recognize that some contemporary AI-generated content may be specifically designed to appear plausible and persuasive but is sometimes factually inaccurate. Many of the issues that have surfaced with the introduction of ChatGPT - questions about academic integrity authorship and citations student engagement misinformation and disinformation - are issues higher education and society have encountered in the past in response to the need for digital literacy. We suggest that generative AI is simply the newest addition to USC's digital literacy tools. Ultimately this committee leaves instructors to set their own course policies regarding student use of generative AI. Whatever any given individual instructor decides should be clearly communicated to students in course materials. However the committee recommends that instructors remind students that the acquisition of academic work in whole or in part from any source (from textbooks and journal articles to web resources to generative AI) and the subsequent presentation of those materials as the student's own work (whether that material is paraphrased or copied in verbatim or near-verbatim form) constitutes an academic integrity violation unless otherwise allowed by the instructor. Individual assignments and exams may have additional specific requirements related to original work which should be clearly defined by the instructor. Because generative AI is a constantly evolving space the committee encourages USC's instructors to begin to learn more about generative AI so they can better adjust their pedagogy and evolve as educators. The Current State of Student Use of Generative AI for Academic Work (MidFebruary 2023) Limitations of Guidelines Our focus in this document is narrow: to highlight the steps that USC's instructors need to take today to identify and to state their expectations with respect to student use of generative AI for academic work. In the weeks and months to come we expect that USC's academic community will be asked to participate in broader conversations about generative AI and its place in academe and society. What is ChatGPT and what can it do? It is hard to overstate how much attention ChatGPT a free online artificial (AI) chatbot that generates text in response to prompts has received since its launch on November 30. One reason it has become so popular so quickly surpassing 100 million monthly active users to become the fastestgrowing consumer internet application in history is the ease and speed with which it can generate text on demand. Ask ChatGPT to \    write a five-paragraph essay on the impact John Stuart Mill's recantation of the wages fund doctrine had on classical economics\     or \    explain what it means when people say 'knowledge is knowing that Frankenstein is not the monster but wisdom is knowing that Frankenstein is the monster'\     or \    write a sonnet about Clay Helton\     and it creates plausible human-like text responses in a matter of seconds. Scholars researchers and educators have demonstrated that given the right prompts ChatGPT can Pass the final exam of an MBA-level Operations Management class at Wharton (Barely) pass questions on a law school exam at the University of Minnesota  Pass all three exams that comprise the United States Medical Licensing Examination Pass Google's coding exams and interviews at the level of an entry-level software engineer with no prior industry experience. Are students already using ChatGPT for academic work? Yes. Students are starting to use ChatGPT for their academic work. In a late-2022 nationwide survey of 1000 students currently enrolled in US colleges and universities nearly one-third of the students said they have already used ChatGPT to complete a written college assignment and nearly two-thirds of that group say that they have used it for 50% or more of their assignments. We expect both percentages to be even higher today. Are there other generative AI text tools like ChatGPT? Yes. ChatGPT is just the first in a wave of generative AI tools that will soon become ubiquitous. Generative AI is algorithms and tools that can be used to create new content including audio code images text simulations and videos. Recent new breakthroughs in the field have the potential to drastically change the way we approach content creation. (McKinsey & Company) Most of these new tools rely on 'large language models' AI systems that use advanced statistical techniques to analyze and understand natural language data such as text or speech and generate human-like responses. Microsoft already a major investor in OpenAI (makers of ChatGPT) launched a new AIpowered Bing search engine and Edge browser in early February 2023 and intends to incorporate AI-content generation into Microsoft Office programs like Outlook Word and PowerPoint. Later in 2023 Microsoft will release technology that will allow companies schools and governments to create their own custom ChatGPT-powered AI text generators. Google is expected to launch its own ChatGPT competitor named Bard in early 2023. In the summer of 2022 Meta (formerly Facebook) released its Open Pretrained Transformer (OPT) large language model to developers and researchers. And that is just the beginning (see https://www.futuretools.io/ for a list of hundreds of new AI tools that be used to generate text images audio and more). Considering this we suggest that rather than focusing solely on ChatGPT instructors should instead focus on what role they would like all generative AI tools to play in their classes and in their students' work going forward. How might instructors approach student use of generative AI? We suggest that there are two ways instructors can approach student use of generative AI: 1. Embrace and Enhance 2. Discourage and Detect Embrace and Enhance The good news is that many of the proven teaching and assessment techniques that worked in a pre-generative AI world still work in a world where any student with a cell phone and a generative AI account can create walls of academic(-sounding) text. USC's Center for Excellence in Teaching (CET) recently published a guide titled \    Using AI text image and music-generating tools in your courses\     that includes helpful ideas for incorporating AI-generators and AI-generated content in your course including evaluating and critiquing AIgenerated content (including interrogating the content for biases) and asking students to create rebuttals. Like our recommendation that students should use generative AI to create analyze and evaluate new concepts and ideas that inspire them to generate their own academic work CET recommends having your students use AI generators to brainstorm ideas formulate and iterate question prompts and refine responses adding that you should Frame using AI tools as something to build upon. Remind students of the best way to use these tools in their discipline such as for idea generation essentializing brainstorming or gathering information about the typical understanding of a topic. All uses of AI tools should be supplemented with appropriate evidentiary support and reflection. Some students may lack the foundational knowledge to understand why or how AI-generated content is inaccurate."
"UT Austin" ,"With the emergence of ChatGPT Bard and other large language model generative artificial intelligence tools hereinafter collectively referred to as AI Tools many members of our community are eager to explore their use in the university context. This advisory provides guidance on how to acceptably use these AI Tools safely without putting institutional personal or proprietary information at risk. Additional guidance may be forthcoming as circumstances evolve. Allowable Use: Data that is publicly available or defined as Published university information (UT Data Classification Standard) can be used freely in AI Tools. In all cases use should be consistent with the Acceptable Use Policy. Prohibited Use: At present any use of ChatGPT or similar AI Tools cannot use any personal confidential proprietary or otherwise sensitive information. In general student records subject to FERPA health information proprietary information and any other information classified as Confidential or Controlled university data must not be used with AI Tools. Similarly ChatGPT or similar AI Tools must not be used to generate output that would be considered non-public. Examples include but are not limited to generating proprietary or unpublished research; legal analysis or advice; recruitment personnel or disciplinary decision making; completion of academic work in a manner not allowed by the instructor; creation of non-public instructional materials; and grading. Please also note that the company that owns ChatGPT OpenAI explicitly forbids the use of ChatGPT and their other products for certain categories of activity including fraud and illegal activities. This list of items can be found in their usage policy. AI Tools of any sort may not be used for any activity that would be illegal fraudulent or a violation of any state or federal law or UT Austin or UT System policies. Additional Guidance: For further guidance on the use of ChatGPT or other AI Tools for teaching and learning please see the following guidance from the Center for Teaching and Learning. Rationale for the Above Guidance: No UT Agreement No Privacy and Security Terms: All content entered into or generated by ChatGPT is available to ChatGPT its parent company OpenAI and their employees. There is currently no agreement between UT Austin and OpenAI Microsoft or other AI Tools that would provide data security and privacy protections required by UT policy with regard to ChatGPT OpenAI's or other AI Tools' programming interfaces. Consequently the use of ChatGPT or other AI Tools at this time could expose individual users and UT to the potential loss and/or abuse of sensitive data and information. As of May 2023 the UT Austin Business Contracts Office is working on this issue. We hope to see this addressed in the near future and will update this guidance when additional information is available. Personal Liability: ChatGPT and other AI Tools use click-through agreements. Click-through agreements including OpenAI's and ChatGPT and other AI Tools' terms of use are contracts. Individuals who accept click-through agreements without delegated signature authority may face personal consequences including responsibility for compliance with terms and conditions."
"Cornell University" ,"To the Cornell community As Cornell continues to explore artificial intelligence (AI) particularly generative AI we are providing some preliminary guidelines for using these rapidly evolving technologies in ways that uphold our core values of purposeful discovery and free and open inquiry and expression. This communication summarizes the spirit of more extensive and formal information regularly updated on Cornell's new general webpage about AI and including links to reports of university committees. Generative AI offered through tools such as ChatGPT Claude Bard Bing AI and DALL-E is a subset of AI that uses machine learning models to create new original content such as images text or music based on patterns and structures learned from existing data. Cornell's preliminary guidelines seek to balance the exciting new possibilities offered by these tools with awareness of their limitations and the need for rigorous attention to accuracy intellectual property security privacy and ethical issues. These guidelines are upheld by existing university policies. Generative AI offered through tools such as ChatGPT Claude Bard Bing AI and DALL-E is a subset of AI that uses machine learning models to create new original content such as images text or music based on patterns and structures learned from existing data. Cornell's preliminary guidelines seek to balance the exciting new possibilities offered by these tools with awareness of their limitations and the need for rigorous attention to accuracy intellectual property security privacy and ethical issues. These guidelines are upheld by existing university policies. Accountability: You are accountable for your work regardless of the tools you use to produce it. When using generative AI tools always verify the information for errors and biases and exercise caution to avoid copyright infringement. Generative AI excels at applying predictions and patterns to create new content but since it cannot understand what it produces the results are sometimes misleading outdated or false. Confidentiality and privacy: If you are using public generative AI tools you cannot enter any Cornell information or another person's information that is confidential proprietary subject to federal or state regulations or otherwise considered sensitive or restricted. Any information you provide to public generative AI tools is considered public and may be stored and used by anyone else. As noted in the University Privacy Statement Cornell strives to honor the Privacy Principles: Notice Choice Accountability for Onward Transfer Security Data Integrity and Purpose Limitation Access and Recourse. Use for education and pedagogy: Cornell is encouraging a flexible framework in which faculty and instructors can choose to prohibit to allow with attribution or to encourage generative AI use. In addition to the CU Committee Report: Generative Artificial Intelligence for Education and Pedagogy delivered in July 2023 and resources from the Center for Teaching Innovation check with your college department or instructor for specific guidance. Tools and use for research administration and other purposes: By the end of 2023 Cornell is aiming to offer or recommend a set of generative AI tools that will meet the needs of students faculty staff and researchers while providing sufficient risk security and privacy protections. The use of generative AI for research and administration purposes must comply with the guidelines of the forthcoming reports from the university committees for research and administration. The reports are scheduled to be published by the end of 2023. For those seeking to purchase generative AI tools or subscriptions in advance of those guidelines and recommendations the IT Statement of Need process is required."
"Columbia University", "Generative AI Policy What is Generative AI? These tools can write and revise text on command offering new ways for students to learn but also raising questions about academic integrity. The best-known example of a generative AI chatbot is ChatGPT built by OpenAI and accessible through Bing AI but other tools such as Google Bard exist and are rapidly improving. Generative AI Policy CBS faculty acknowledge the availability of generative AI tools as well as their potential benefits and drawbacks. The faculty will indicate in course syllabi and in expectations for individual assignments whether the use of generative AI such as ChatGPT is permitted in their course(s). Because expectations for using generative AI will vary across courses and assignments students must read the expectations for each course carefully. As a general rule students should disclose to faculty if they are using generative AI platforms and how they are using them in coursework. Guidelines for when generative AI is permitted by faculty: If faculty permit generative AI in their course students will be instructed how to use and properly cite such tools in their work. Citation information will include what platforms students are using and how they are using them. Failure to properly and completely cite AI-generated responses may be reported as a violation of the CBS Honor Code. Guidelines for when faculty have not communicated their generative AI policy: If the course policy on AI is not clearly stated in the assignment instructions and/or in the syllabus students must communicate with their professor(s) to clarify before using generative AI in their coursework. Students are encouraged to communicate with their professors in writing via email. Consequences of using generative AI without faculty permission: The use of generative AI without faculty permission will be considered a violation of the CBS Honor Code. Suspected violations of this nature will be reported to Student Conduct in the Center for Student Success and Intervention (CSSI). Unauthorized use of AI shall be treated similarly to unauthorized assistance and/or plagiarism and is subject to Dean's Discipline."
"University of Pennsylvania", "The recent release of powerful generative AI tools has unsettled higher education. Tools such as Chat-GPT GPT-4 Bard DALL-E 2 Llama 2 Claude Pi and Bing are developing rapidly. These chat tools can write and revise text code and images in response to prompts raising questions about academic integrity the nature of our assignments and new ways we may ask students to think and learn. Below you can find an overview of these generative AI tools and potential ways faculty might respond. What is Generative AI? What Does It Do? Ways to Address Generative AI: Academic Integrity and Rethinking Assignments Making Generative AI Part of Your Teaching Sources and Further Reading Keep in mind that we are still in the early days of considering how these tools can be used and what their impacts will be. If you would like to discuss concerns related to generative AI and your teaching CETLI staff are available to meet. CETLI can also work with programs or departments to bring instructors together to consider strategies and implications related to this new platform. ChatGPT was the first of what are now many generative AI chatbots that produce coherent written responses and computer code in response to a user's natural language prompts and adapt their responses based on user feedback or additional prompts. Many are available for free (usually with user registration) but some of the most advanced tools such as GPT-4 require a paid subscription. These tools have already been used to produce a wide range of essays exam solutions letters fiction blog posts and many other outputs at various levels of quality and accuracy. Materials are usually clearly structured and grammatically correct. They can also generate code and fix coding bugs. They can tackle certain problem sets. And these tools can produce summaries of readings including materials from PDFs. While there is a lot generative AI can do it also has some varied and changing limitations. These tools periodically generate what have come to be called hallucinations: completely made-up information that looks plausible. Some but not all of the tools struggle with referencing sources. Some of the tools might produce citations that look correct but that do not refer to an actual article or book. Some may present information without any way to verify where it comes from or its validity. Similarly generative AI can produce harmful biased misleading or simply inaccurate content. All of this means that knowing a field is helpful in order to use generative AI most effectively. Additionally many tools do not have knowledge generated after the dates of their training (2021 for ChatGPT; 2023 for Claude). Some do and some do not have access to the internet. If you want to understand better how these chatbots work The New York Times has a series called How to Become an Expert on A.I. that can help."
"Brown University", "Initial Guidance for Researchers: Generative AI in Research Generative AI tools such as chatbots (ChatGPT Bing Chat) and art systems (Midjourney DALL-E) have great potential for university research. Brown investigators contemplating using generative AI tools in their own research should be cognizant of the various intellectual property (IP) issues related to its use. Technology typically outpaces policy and law and generative AI (GenAI) is a particularly dynamic area of technology development. The guidance on the intersection of generative AI and IP is an evolving area. Any questions regarding the use of generative AI in your specific research program related to IP may be directed to tech-innovations@brown.edu. Issues Arising from the Use of Generative AI A. Public Disclosure/Confidentiality. Public Disclosure. Patentability. Any given GenAI may not provide sufficient protections to ensure data privacy or confidentiality. Make sure the GenAI has terms of use stating that any data you provide and your results will not be made public bearing in mind that any cloud-based GenAI can be vulnerable to public disclosure. Public disclosure of an invention can preclude Brown's ability to secure patent rights for that invention. Misappropriation of Research Results. Make sure the GenAI terms of use prevent the GenAI company from using your research results for its own commercial purposes. Brown researchers' data and results are typically considered confidential and proprietary until a decision is made to publish a manuscript. B. IP Ownership. Ownership issues pertaining to three distinct types of properties are addressed: researcher developed generative AI models (the software algorithms designed to learn from training sets and generate outputs); researcher-curated training sets (the large data sets learned by GenAI systems); GenAI output results. Ownership of generative AI models. Brown researchers may be involved in developing novel GenAI software and algorithms. As a reminder software source code is protectable by copyright and algorithms may be protectable by patents. Ownership of Brown Researcher-Curated Training Sets. Often the value of a GenAI tool is derived from its training sets that yield superior results. BTI works with researchers to protect proprietary rights in commercially valuable training sets while preserving the ability to make it available for nonprofit research. Ownership of GenAI Results. Make sure the GenAI tool has terms of use that state that the user will own output results. Not all GenAI tools have terms of use that are clear or sufficient to ensure ownership. Infringement Risks in GenAI Results. Safe practice is to only use GenAI systems that disclose the sources of its training sets. Many GenAI tools do not disclose their training set sources and may contain material scraped from the internet without permissions which amounts to copyright infringement. The output results of such GenAI tools may contain or reflect copyright infringement. "
"Dartmouth College" ,"TEACHING WITH CHATGPT AND OTHER GENERATIVE AI With powerful artificial intelligence (AI) tools readily available to both learners and instructors many are concerned about their impacts on teaching and learning. How effective are these tools? What are their limitations? Will students be able to generate solutions to assignments using them? How will this affect academic integrity and interact with the Academic Honor Principle? This resource offers a range of resources and considerations to help faculty begin answering these questions and make the best decisions for their individual disciplines courses and assignments. Because this process is so context-dependent and necessarily unique for each teaching and learning situation this resource is not meant to be definitive or prescriptive. With that said there is one recommendation that is relevant for all faculty and courses regardless of discipline or individual approach: Acknowledge the existence of generative AI tools to your students and articulate your expectations of students in your course syllabus in as much detail as possible. Is it acceptable to use these tools in your course or in specific assignments? To what degree? Is their use to be limited and if so how specifically (brainstorming ideation editing debugging etc.)? If you are incorporating these tools into your teaching and assignments how should students document and cite their use of such technologies? The more explicit and transparent you are about the role of AI technologies in your course as well as your rationale for these decisions the easier you make it for students to meet your expectations and have a successful learning experience. As the landscape of generative AI continues to rapidly evolve we are maintaining this resource as a living document that will be updated regularly"
"Princeton University", "Generative AI is rapidly evolving and increasingly ubiquitous. AI tools can be used to generate ideas summarize articles draft creative papers develop computer code provide feedback on writing create images and compose music. It is important to understand the capabilities of current generative AI programs and set clear guidelines about how they can be used for coursework and independent work. We encourage faculty to have explicit conversations with their students about the permissibility of the use of these tools in their courses. If some use of generative AI is allowed we suggest that faculty set clear and explicit guidelines and help their students understand the risks associated with these programs. In large language models such as ChatGPT for instance risks include inaccuracies fabrication (so-called hallucination) and amplified biases (see more below). While developing AI literacy is important we also recognize that the use of these tools can shortcut learning and lead to missed educational opportunities. Syllabus Language We strongly encourage faculty to indicate on their syllabi (and individual assignments): Whether AI tools are prohibited or permitted in their courses Whether AI tools are permitted for certain assignments for certain tasks or for certain stages of an assignment Keep in mind that a course policy that allows some use of generative AI may introduce complexity and open up the possibility of misunderstanding inadvertent or not. Use of Generative AI should be acknowledged by students; see citation guidance from MLA APA and Chicago. Below you will find Princeton-specific examples grouped by category. You may also find this Chronicle article useful. We also highly recommend the guidance and examples our colleagues at Georgetown have curated. Generative AI Use Not Permitted Intellectual honesty is vital to an academic community and for my fair evaluation of your work.All work submitted in this course must be your own completed in accordance with the University's academic regulations. You may not make use of ChatGPT or other AI composition software. Generative AI Use Permitted with Permission and Citation (two examples) Example #1 Students must obtain permission from me before using AI composition software (like ChatGPT) for any assignments in this course. Using these tools without my permission puts your academic integrity at risk. AI and Your Writing Process (Princeton Writing Program) Given the importance of producing original intellectual work for our seminar generative AI tools (like ChatGPT) should not be used in any way or at any time unless I as the instructor give the entire class explicit permission to use this technology under certain parameters (e.g. as part of a specific lesson or writing exercise or as a potential topic to investigate for research). Using generative AI tools outside the parameters we discuss in class puts you at risk for becoming a passive participant in your writing process and compromising your academic integrity. Keep in mind that academic writers are expected not only to cite but also to verify their sources; verification is not always possible with tools like ChatGPT because this technology often draws upon source materials that are inaccessible or invisible to users generating output through proprietary algorithms that should not be mistaken for authoritative analysis. The output generated by these tools cannot be accepted uncritically or at face value. For these reasons it's necessary to be transparent about how and when you use generative AI. Any use of technology like ChatGPT must be accompanied by an explicit acknowledgment and brief description of how this tool was used in your work and you must keep complete records of your engagement for possible review (e.g. the log generated by the app). Please remember that suspicions of plagiarism will be reported to the Committee on Discipline and may have serious consequences. Generative AI Use Permitted with Citation (three examples) On ChatGPT and other AI tools (SPI353/MAE353 - Alexander Glaser) It's okay to use ChatGPT to support the work on your policy memo or mini paper. Proceed with caution however as we are all still learning how to use these new tools. In fact we may include a related assignment in a problem set. If you decide to use ChatGPT you must include an acknowledgment to that effect and as part of your submission briefly explain how you leveraged the tool. We will make available further guidance and a paper/memo rubric in due course. Note that you won't be able to use any AI-assistants during the closed-book written exams. ChatGPT Policies (PSY 337 - Uri Hasson) ChatGPT generates text patterns probabilistically (similar to autofill in your email client though more powerful). For this reason it should not be listed as a co-author on scholarly work; we see it as a compiler rather than a writer. You are invited to work with ChatGPT ask questions about any topic related to any lecture assess its responses and critique its answers. With appropriate reference you can cite any answer you get from ChatGPT. However you should not relegate your coursework or your obligation to think learn and synthesize knowledge to ChatGPT at any point during the course. A note about using AI language models like ChatGPT (Elizabeth Gould - NEU 490) You are permitted to use these tools to generate outlines or First drafts of your writing assignments. Please remember that (as of now) ChatGPT is not up on the very latest in neuroscience literature; it does not provide citations and it is sometimes incorrect. It also does not do a great job with critical analyses of data. So if you use it you will need to heavily fact-check and edit the product"
"Duke University", "This page refers primarily to the AI writing assistant ChatGPT but it should be noted that AI models are being used in other ways for example to generate videos images and conversations with customers. The field of AI and opinions about how to react to AI in academia are evolving rapidly. As an organization Learning Innovation is working to keep up to date with this issue in order to provide more robust advice for faculty. Watch this page as well as our events and blog to learn more. We are developing additional materials to guide you through course design class activities and assignments in light of AI. Looking for an AI policy? We have written an expanded guide to writing artificial intelligence policies. Ready to incorporate AI in your class? Our resource on the design of AI assignments also has examples to get you started. Artificial Intelligence Tools Artificial Intelligence is any technology that attempts to solve problems and complete tasks that would usually require human intelligence. For decades there have been increasing advances in AI software and hardware. The most visible Artificial Intelligence (AI) tool at the moment is ChatGPT a writing assistant that has been a topic of interest across academia and beyond in the past few months. ChatGPT can generate plausible written responses to a wide variety of user prompts and questions. Its power comes from a machine learning model that is able to predict content to prompts based on a large amount of data it has been trained on and a natural language model that makes the responses seem like human language. To try ChatGPT you can visit OpenAI's website and read the company's FAQ for further information. Watch our workshop on how to use ChatGPT and Midjourney (image generator). Some tasks that ChatGPT excels at are summarizing information writing fiction generating computer code translating text from one language to another generating text that summarizes data and talking in a conversational manner. Examples of prompts might be: Write a three-page paper on the effects of climate change or I am looking to buy a camera. Do you have suggestions? or Review my writing for errors. The results of these prompts can be quite impressive but it is important to note that ChatGPT is not technically thinking or emoting and lacks important human skills such as critical thinking and fact-checking. You should not rely solely on AI to produce factual information. Currently Duke does not support any specific AI tools like ChatGPT Bard or Midjourney. This means that we have not vetted these tools for important concerns like accessibility data security and privacy. If you plan to implement any AI tools into your course we have tips for conducting due diligence for unsupported tools. We also suggest that you review the terms of service to see how you and your students' data might be used - some services note that user data will now be harvested to train AI. Impact on Education AI models will continue to grow in capabilities and be incorporated into word processing and search engines. The challenge for instructors is to discover how to incorporate Artificial Intelligence content generators as a tool in their teaching rather than view them solely as a threat. In the past other technology tools such as multifunction calculators spelling and grammar checkers and statistical analysis software shifted the ways we learn and teach. As in those cases educators will need to help students differentiate when AI can help with learning versus when it is a shortcut around learning. It must be acknowledged that faculty's bandwidth to address the emergence of AI is limited. Learning about AI and how it will impact teaching will take time especially as it is a new trend. This is a likely multi-year shift in education and as such does not need to be tackled all at once. Several steps instructors can take: Try AI generators and understand their capabilities. You may also want to take time to understand what happens on the backend of any AI tool and what data the tool is pulling from. Update course policies to include considerations for using AI content. While you may not choose to integrate AI into your course it is important not to ignore these technologies. Here are a few questions to ask yourself: First do the values of the technologies align with your course values? Second what do you want to communicate about these technologies with your students? Finally what are the intellectual gains and guidelines if you do allow students to use AI? Review assignments to see if quick changes can be made to address AI concerns. Consider adding assignments that educate students about the strengths and limitations of AI and how it relates to your discipline. Shortcomings of AI ChatGPT creates text based on predictions and not critical thought. The text generated is based on a dataset that cannot update itself. The design of the AI model leads to important limitations. Bias Its output is only as good as its input. AI retains all of the biases of the information it intakes including the stereotypes and misinformation present in human writing on the internet. Inequity Depending on the future funding models for AI assistants there may be a gap between who does and does not have access to them. Inaccuracies AI-generated content may contain factual errors incomplete quotes and erroneous findings. There may be a new adage about the internet: Don't believe everything you read on the internet and what an AI bot generates based on the internet. Furthermore an AI technology may produce what is considered good content at some point but that does not mean the technology will answer the prompt consistently or well in the future. Intellectual property It is not clear who owns AI-generated content or the prompts created by users. This ongoing conversation may impact the use of AI now and in the future. Some AI technologies have been shown to plagiarize from other sources when creating original content. Ethics Training AI models can produce negative impacts on the environment. AI models have been used to unethically replace workers and there have also been concerns that unethical labor was used to develop and maintain these tools. Opportunities That AI May Provide In a recent open discussion several themes emerged among Duke instructors as opportunities posed by AI: Efficiency AI can help draft emails blog posts cover letters article summaries allowing for time savings in everyday tasks and potentially in teaching as well. Stimulate Thinking Students could annotate an AI-generated text use it to search for counterarguments during a group discussion or brainstorm an idea for a new project. Editing Used judiciously AI can improve writing and debug code"
"Vanderbilt" ,"Vanderbilt University Staff Guidance for ChatGPT OpenAI and other Generative Artificial Intelligence (AI) tools Guidance issued July 13 2023 A new wave of generative AI tools such as ChatGPT and DALL-E-2 is changing the way many institutions including Vanderbilt University conduct business. These technologies can help streamline processes activities and tasks across the university; at the same time they may also introduce new security risks both for staff members and for the university itself. With that in mind the university requests that staff follow the guidelines below when interacting with new generative AI tools: Explore the capabilities of new technologies: New AI technologies can simplify labor-intensive tasks. Employees are encouraged to harness the capabilities of generative AI and incorporate them into their day-to-day workflows. Seek feedback from supervisors: Generative AI tools serve many purposes but they are not meant to solve all problems. Staff should discuss any use of generative AI with their supervisors to ensure that using these tools is appropriate for the work being completed. Utilize new AI training modules provided by the university: The university has launched several new training modules on generative AI including the prompt engineering course taught by Vanderbilt University professor Jules White. Staff are encouraged to take advantage of these training modules for their own personal and professional development. Understand confidentiality: The terms and conditions and privacy policies for many generative AI technologies allow the underlying companies to use inputs and outputs for their own legitimate business purposes including sharing information about how their tool technology or system is used by others with potential buyers or investors. Do not input anything restricted into generative AI tools: Information that is restricted by law (FERPA HIPAA etc.) by contract or by other agreements should not be entered into generative AI tools. Do not put anything confidential or sensitive into generative AI tools: There is no guarantee that information inputted into these AI tools will remain confidential. Sensitive information should not be shared. Consider ownership of outputs: Generative AI often draws upon the work of others particularly trademarked or copyrighted content to create new images. At this point it is not clear who owns image outputs generated by these technologies. Until it is staff should avoid using generative AI tools for projects where the university must for business purposes own the final work product. Do not assume that outputs are accurate: There have been numerous well-documented instances of AI generating results that seem realistic but are in fact completely false made-up 'facts' generated by the system. Do not trust any factual output from ChatGPT or other generative AI tools; always double-check information for accuracy. Ensure that outputs are consistent with university values: Staff should review AI outputs to ensure accuracy and alignment with university values especially in situations where human empathy and connection are required."
"CMU", "Generative Artificial Intelligence (AI) tools enable the quick creation of new content based on the analysis of data and inputs. This technology unlocks possibilities to enhance our written and visual content creation approach. As these tools evolve and we experiment with them it's important to be aware of the associated data privacy security ethical and legal concerns to use them responsibly. Data Privacy Generally only enter information into Generative AI tools that you would share publicly online. Data classified as private or restricted should not be entered into open or commercial Generative AI tools. Become familiar with the Guidelines for Data Classification to ensure the security of university data and the privacy of our students and colleagues. Security Malicious actors are also taking advantage of Generative AI to create more convincing phishing emails and fake video audio and graphical representations. Follow the guidance provided by the Information Security Office to identify and report suspicious activity. Copyright Considerations Copyright guidance regarding authorship is still unclear. Adding personal modifications to Generative AI output may increase the likelihood of copyright protection but exercise caution. Verify that AI vendors have the necessary licenses to allow use on your website social media etc. Accuracy Remember Generative AI tools create content based on your prompts and what they learn from other inputs. Lack of data poor training or unclear prompts may result in inaccurate content generation. Always review and fact-check the output of AI tools."
"University of Toronto","In response to the rapidly evolving landscape of generative artificial intelligence (AI)[1] use in academic and educational settings this preliminary guidance has been produced to address frequently asked questions (FAQ) in the context of graduate thesis work at the University of Toronto. More detailed guidance on this topic as well as new or updated policies may be issued in the future in which case this preliminary guidance will also be updated. The FAQs below outline important considerations for graduate students supervisors supervisory committees and graduate units on the use of generative AI tools (such as ChatGPT) in graduate student research and thesis writing while upholding the core principles of academic quality research integrity and transparency. The FAQs cover requirements both for approval and for documentation of the use of generative AI tools in graduate thesis research and writing as well as risks and other considerations in using generative AI in graduate thesis research and writing. Innovative and creative uses of generative AI may support scholarly activities and help facilitate high-quality research particularly in certain disciplines. Graduate students and faculty supervisor are expected to strive for the highest standards of academic quality and research integrity in all scholarly activities and therefore the use of generative AI tools in the process of graduate thesis research and writing must always take place with full transparency. This includes transparency between students and their supervisors who must agree in advance how any generative AI tools will be used; as well as transparency between graduate students and the audiences of their work who must be provided a clear and complete description and citation of any use of generative AI tools in creating the scholarly work. Students who plan to use generative AI tools in researching or writing their graduate thesis must always seek and document in writing unambiguous approval for the planned uses in advance from their supervisor(s) and supervisory committee. Unauthorized use of generative AI tools for scholarly work at the University of Toronto may be considered an offence under the Code of Behaviour on Academic Matters and research misconduct as defined in the Policy on Ethical Conduct in Research and the Framework to Address Allegations of Research Misconduct. Furthermore careful attention must be paid in the thesis to appropriate citation and describing any use of generative AI tools that took place in the research or writing process in line with disciplinary norms. This includes for example using generative AI tools in searching designing outlining drafting writing or editing the thesis and may include other uses of generative AI. Even when engaging in authorized generative AI use faculty and graduate students must be aware of the risks in using such tools some of which are discussed below. Faculties and graduate units may have specific requirements or restrictions regarding the use of generative AI in some or all phases of the graduate research lifecycle. Individual graduate units may therefore issue additional guidance outlining field-specific appropriate uses of generative AI tools in researching and writing a doctoral thesis. This could include for example guidance on use in writing text conducting analytical work reporting results (e.g. tables or figures) or writing computer code. Graduate units issuing additional guidance should take into account the issues discussed in the FAQs below. Additional relevant guidance and further reading can be found in the FAQs and guidance on syllabi and assignments (PDF) issued by the Office of the Vice-Provost Innovations in Undergraduate Education and in the guidance on generative AI in the classroom from the Centre for Teaching Support & Innovation. In referring to generative AI in this document we include tools that use predictive technology to produce new text charts images audio or video. For example uses and more detail please see the FAQs and guidance on syllabi and assignments issued by the Office of the Vice-Provost Innovations in Undergraduate Education and the guidance on generative AI in the classroom from the Centre for Teaching Support & Innovation."
"University of Cambridge" ,"The use of generative AI in coursework from November 2023. This policy statement sets out Cambridge International's position on the use of generative artificial intelligence (AI) in student work submitted for assessment as coursework. It will apply to all Cambridge International qualifications from the November 2023 series onwards. Principles We recognize that generative AI programs of various kinds have the potential to provide a valuable resource for students and can support the learning process as students research design and plan coursework projects. However the inappropriate use of generative AI to create or enhance student work without acknowledgment risks being classified as plagiarism and like other forms of malpractice may be subject to penalty. (See the Cambridge Handbook (PDF 1MB) section 5.6.) As with our existing guidance relating to the submission and authentication of coursework the primary responsibility for identifying any inappropriate use of generative AI by students remains with centres and teachers who know the students best. Teachers must keep student work submitted for assessment as coursework under supervision and must be able to authenticate it as the candidate's own unaided work. (See the Cambridge Handbook (PDF 1MB) section 3 on 'Coursework and moderation') All use of generative AI programs to conduct initial research create text images sound or video or plan a project must be acknowledged in the work and AI-generated material must be clearly referenced. Mark schemes and assessment criteria will not award credit specifically for the use of generative AI and there is no expectation that candidates will use AI (unless the ability to demonstrate the use of AI is one of the constructs being assessed) to support their learning or production of work (unless the use of AI is identified as an assessment objective within the syllabus). The only credit will be for the way the candidate has made use of the material produced in this way in the same way that merely citing sources in a bibliography does not of itself deserve credit. Using AI appropriately to support their work will not give the candidate an advantage over any other way of initiating research or planning a project. Acceptable use of generative AI in student work The following uses of generative AI programs by students in the preparation of material for submission as coursework are acceptable if clearly acknowledged in the work: To carry out initial research into a topic in preparation for a written study. This is no different from consulting published articles or books or browsing on a search engine and citing websites visited in the bibliography. Candidates should clearly state the prompt or series of prompts they used the name and version of the generative AI program used and when it was accessed. Candidates should check any websites cited by AI and include a discussion of the reliability of any identified material for example explaining how they have accounted for potential bias in a response or how they have checked for accuracy. Candidates should be made aware that AI programs can sometimes 'hallucinate' non-existent sources. To quote briefly from AI-generated text within an essay and engage in critical discussion of the quotation. (We suggest a limit of two or three sentences or about 50 words in a single quotation. The use of longer AI-generated material is likely to be self-penalizing if candidates do not fully engage in critical discussion of it.) Quotations must be clearly acknowledged and identified within the candidate's writing and like any other source of evidence should be contextualized and reviewed. Students might do this to help them identify core aspects of a question or outline the issues involved but credit will only be awarded for their own work and judgments in response to the AI-generated material and other appropriate sources of evidence. Guidance for teachers This guidance should be read in conjunction with existing guidance on Preventing Plagiarism - guidance for teachers. Teachers are also advised to consult 'New guidance: Artificial intelligence and teaching learning and assessment' on the School Support Hub. Teachers must authenticate coursework as the candidate's own unaided work. Where teachers suspect plagiarism or inappropriate use of AI they should not authenticate the work and should be prepared to investigate further. We will take appropriate action if we suspect work submitted for coursework is plagiarized or has been produced using AI inappropriately. Advice on how to guard against inappropriate use of AI by students. Keep drafts and plans of coursework under supervision. A sudden significant development of earlier work for example a handwritten draft being presented in typed format with markedly improved content should be questioned by the teacher. Material which is written in a different style in terms of vocabulary and syntax from work that the student characteristically produces may also invite investigation. Students can be asked to explain unusual vocabulary or concepts or comment on what they read in any academic references cited. Work produced partly or completely by AI is likely to be strong on evidence and information and weak on analysis and evaluation or the expression of a distinctive point of view. There may be unexplained or illogical sequences of material or a series of false endings/starts indicating the AI program has been prompted to provide more material. Other potential identifiers include: an uncharacteristically high level of accuracy of spelling punctuation and grammar a lack of any references after 2021 a consistent use of Americanized spelling conventions in a candidate not normally spelling in this way discourse markers followed by a comma used to start paragraphs (However / In conclusion) journalistic collocations (phrases characteristic of student writers such as 'disaster relief efforts') Latinate vocabulary pleonasms (use of more words than is necessary) or tautology (saying the same thing twice) repetition of content or ideas or whole phrases."
"ETH Zurich" ,"Artificial intelligence or AI for short has been receiving heightened public attention for only a few years yet the issue has already been overtaken by a new topic: today everything revolves around ethical AI. Numerous very diverse organizations have issued ethics guidelines for AI or statements on the subject. Amid such a plethora of publications it's not easy to get a clear picture. What are these documents actually saying? Is the wheel being reinvented every time? What understanding of ethics prompts these recommendations on ethical AI? And who determines this? With new guidelines being issued each month an inventory of sorts seems indispensable. No single common ethical principle. The results of our comprehensive study. The global landscape of AI ethics guidelines were recently published in Nature Machine Intelligence. The first thing to surprise me was that no single ethical principle was common to all of the 84 documents on ethical AI we reviewed. Still five principles are mentioned in more than half the sources: transparency justice and fairness non-maleficence (afflicting no harm) responsibility and privacy. Overall we identified eleven ethical principles. The second thing to surprise or rather disillusion me: sustainability is mentioned in only one-sixth of all guidelines and recommendations; human dignity and solidarity occur even less often. This is particularly astonishing considering that two of the major challenges related to AI - energy consumption and climate change on the one hand and restructuring of the labor market and feared job losses on the other - involve precisely these principles. From an ethical point of view this marginalization of sustainability dignity and solidarity is disturbing. In my view ethics guidelines should not ignore the major concerns people have but instead must grapple with them. Same term diverging interpretations. When it comes to policy on a more granular level there was also little agreement on what ethical AI means: all ethical principles referred to in the documents are interpreted in different sometimes conflicting ways and point to different courses of action. For example whereas some guidelines endorse fostering trust in artificial intelligence others warn against placing too much trust in AI systems. Ethical artificial intelligence is not merely a technical issue; ethics must also be part of the governance of AI. Inclusive governance. A few months ago the external page Swiss Digital Initiative (SDI) launched was launched in Switzerland with the official aim of implementing ethical standards in a digital world. In light of our study this prompts the question: which standards are meant here? In a first draft paper the SDI alludes to the key principles of the UN Report on Digital Cooperation the collaboratively developed external page Ethically Aligned Design (EAD) standards and applicable laws and regulations more broadly. Taking account of what already exists is a good start but there's a lot of work ahead. The EAD document for example repeatedly underscores the importance of involving all stakeholders. Which of course relates to social and political structures and processes rather than to technology strictly speaking. As I see it everything boils down to this: ethical artificial intelligence is not merely a technical issue; ethics must also be part of the governance of AI. This entails an external participatory approach that includes stakeholders and civil society. Given the impact AI has on many areas of our society when it comes to which values we should apply to AI and how these should be implemented I believe civil society must have a say."
"University of California  Irvine (UCI)" ,   "Rapidly evolving generative AI tools include text-generating AI chat services (e.g.  ChatGPT  Bard  Claude)  as well as image-generating  audio  and video AI tools. These machine learning-powered tools are increasingly integrated into our daily communication apps  word-processing software  and technology broadly. In order to best serve our students  we need to engage with generative AI in meaningful ways across the curriculum.At one level  generative AI tools are no different than any other tools with regard to their impact on teaching decisions. Faculty will need to consider how to leverage tools to benefit student learning  asking question such as:How can this help me prepare course materials or handle administrative aspects of instruction? How  if at all  can they help students master my course outcomes? Where  if at all  in my course should I be explicitly teaching how to use the tool? Where  if at all  is it appropriate in my course for students to use the tool independent of goals one and two? Faculty also need to be aware of pitfalls and dangers  such as:How might use of the tool negatively impact students learning in the course?What equity and access issues does the existence of the tool raised for my course?How will I address concerns with data privacy breaches  intellectual property protection  algorithmic biases  and  hallucinations   situations where generative AI provides false information Ultimately  individual faculty will need to make decisions based on the context of their course  course objectives  students academic progression  and disciplinary-specific goals of their students learning experiences.One of the challenges faculty have in making these decisions is that the tools are potentially moving faster than research into the use and impact of the tools. However  UCI has significant expertise in this space  and we will continue to update the information as we learn more from research. The following links provide important resources in this space."


"Johns Hopkins",   "Student Use of Generative AI As the availability of generative AI grows and the quality of these tools improves  student and faculty perspectives on the use of generative AI become more diverse—with some expressing academic integrity concerns and others advocating for thoughtful ways to incorporate these tools into learning. The Whiting School of Engineering (WSE) recommends communicating with students about their perspectives and the various approaches that can be taken when using these tools in higher education. By engaging in these discussions  collectively  we can learn more about diverse perspectives and better understand the benefits and drawbacks of generative AI  whether it is permissible to use in your courses  and how these tools support or hinder learning and achievement of course objectives. Policies in Higher Education To address these issues  provide explicit guidelines within course syllabi that clearly outline whether and how AI tools can be incorporated into activities or assignments. If applicable  students should also be informed about the appropriate way to acknowledge the use of such tools in their submitted work. Example syllabus guidelines: Students are encouraged to explore and experiment with generative AI tools for learning purposes  but any use in assessments must be clearly indicated and appropriately attributed. The use of generative AI tools is strictly prohibited in all assessments to ensure fair evaluation of individual student performance. Generative AI tools may be used in activities and assignments  but students must include a reflection on their use and how it impacted their understanding of the material."


"California Institute Of Technology",  "We write to provide initial guidance to encourage the responsible use of generative artificial intelligence (GenAI) and large language model (LLM) tools and technologies  such as OpenAI s ChatGPT and Dall-E and Google s Bard in research  education  and administrative work at Caltech. As a research and education institute  committed to advancing the frontiers of science and engineering and expanding knowledge  we support a responsible  measured experimentation with and use of new technologies. While doing this  however  Caltech requires that you follow all existing applicable regulations and Institute policies. These include  but are not limited to  ensuring protection of confidential  personal  or business information and intellectual property  and adherence to the honor code  course requirements  research integrity  and publication ethics. GenAI and LLM technologies have evolved rapidly in their use and application this past year and are expected to continue to evolve in ways society cannot predict. Likewise  our guidance for the appropriate use of these tools is written for the present moment and will likely evolve alongside the technology. In the interim  however  as you use GenAI and LLM technologies in your work at Caltech  we ask that you apply these four guiding principles to your practice: disclosure  data and information protection  content responsibility  and Caltech s honor code. Disclosure: When using GenAI  always disclose promptly  or reference the use of GenAI tools and application plug-ins  as applicable. This transparent disclosure ensures that others are aware when GenAI was used to generate content and reduces misunderstandings regarding the source of information  potentially limiting claims of academic dishonesty or plagiarism. When using GenAI to write or publish  please make sure to follow the guidance provided by the course instructor or journal or manuscript publisher/editor. For example  some may require that the GenAI be included as an author  others may simply require acknowledgement.Data and Information Protection: Federal  state  and local laws as well as Caltech policies may limit data that can be disclosed. Unless you are using a GenAI application that ensures separation of your entry from other entries and confidentiality (usually a paid service)  uploading content into GenAI (Open GenAI) is a public disclosure. It is safest to assume data or queries uploaded into Open GenAI tools will become public information  unless otherwise indicated. In order to protect Caltech data and information  do not enter  contribute  or otherwise input sensitive  confidential  or restricted information into Open GenAI tools. This includes  but is not limited to  data covered by regulations such as FERPA and HIPAA  any intellectual property or unpublished research data  export-controlled data  and other sensitive HR  business  or administrative data. Caltech is considering a subscription to a restricted GenAI and will keep you apprised of its progress in securing such a service. In the meantime  Caltech has and continues to reserve the right to disable or limit access to AI companion tools in enterprise business software and applications  such as Zoom and Microsoft Office suites. Content Responsibility: Remember that GenAI systems are fallible. Responses can be inaccurate  misleading  and even entirely fabricated. Therefore  you should always review and assess all output generated by GenAI tools for accuracy before relying on them or distributing them publicly.Honor Code: Caltech s honor code underscores the importance of ethical conduct and fairness and extends to the use of GenAI tools and is stated as follows:  No member of the Caltech community shall take unfair advantage of any other member of the Caltech community.  These guidelines have been posted to the Information Management and Support Services (IMSS) website. Please note that we offer these guidelines in addition to the teaching resources that have already been provided by the Center for Teaching  Learning  and Outreach.The Institute s guidance promotes responsible and ethical use of GenAI and LLM tools at Caltech  and fosters a community that values transparency  integrity  privacy  accuracy  and fairness. Caltech may update its guidance as the technology and regulatory and commercial landscapes evolve. Thank you for adhering to these guidelines."

"University of Washington",  "ChatGPT and other AI-based tools Tools that use artificial intelligence (AI) and large language models to generate text or images are increasingly at the forefront of teaching and learning conversations. Many students now use these tools  sometimes with the encouragement of their instructors  to complete assignments. Other instructors would prefer that students not use AI-based tools to complete assignments. Because generative AI tools are constantly evolving  it is very difficult to develop technology that can reliably identify when a student uses AI to complete an assignment. Thus  a policing approach to student use of AI has the potential to be both time-consuming and unsuccessful. Instead  it is important to help students understand the issues associated with AI and its relationship to learning in general and your class in particular. The following strategies can help instructors think about how to communicate with students  set expectations  and design assignments that increase students motivation to develop their own skills and ideas. Set expectations – Establish a policy for your course around the use of AI-based tools (e.g.  ChatGPT) and communicate this with students through the syllabus and/or assignment prompts. Discuss how you will proceed if you discover that a student has turned in AI-generated work.Communicate the importance of college learning – Many students are focused only on learning that seems related to their intended career track. However  the vast majority of them will change careers at least once in their lives. Talk with students about how the relevance of your course may only become apparent years from now. The skills they are learning will likely transfer to other careers – even careers that do not yet exist! Acknowledge that struggle is part of learning –  Talk with students about how intellectual struggle is an inherent part of learning. Learning happens only when we move outside what we already know. Seeking a shortcut or workaround through AI tools only prevents them from learning. The short-term consequence is that they pay for a benefit they never receive. The long-term consequence is that they miss the opportunity to become better  more effective thinkers  writers  researchers  and creators.Discuss the social  ethical  and practical issues surrounding AI – The processes that support the development and functionality of AI-based tools raise issues related to privacy  disinformation  environmental impact  bias  exploitation  and academic integrity  among other things. In addition  although AI-generated output appears authoritative and factual  it is frequently riddled with inaccuracy. Discussing these issues with students can help them see the social context of AI and can position them to make thoughtful decisions about their own use of AI-based tools.Assess process as much as (or more than) product – Lowering the stakes of individual assignments reduces students motivation for cheating and encourages them to build their own skills and competencies. Low- or no-stakes formative assessments reinforce the notion that learning is a process and demonstrates to students that what s valuable is the learning  not the grade.Design assignments that ask students to connect course content  class discussion  and lived experience. It s harder for AI-based tools to effectively connect the dots between these sources of knowledge. Consider teaching through AI-based tools. Think about how using AI-based tools might facilitate students learning and prepare them to thoughtfully engage these tools in their personal and professional lives. How can students use AI-generated output to think critically and analytically? How can these tools help them ask questions about digital literacy and information accuracy? Further down this page we ve provided some examples of how to integrate AI into assignments.Students are expected to practice high standards of academic and professional honesty and integrity. The University communicates with students about the importance of knowing and understanding the expectations of both the University and specific instructors regarding academic standards. If you have prohibited the use of AI-based tools and suspect that a student has engaged in academic misconduct  you can make a report to your campus Student Conduct office. Teaching with AI Below are some examples of how instructors might use AI to facilitate learning. Many of these examples familiarize students with AI-based tools  but also prompt critical examination of their value  accuracy  strengths  and shortcomings. This list is a work in progress. If you are using AI in your own teaching and would like to share what you re doing on this page  we invite you to complete this form. Think-pair-AI-share. Students think (as individuals) about a question/concept  then pair up with a peer to discuss. The pair then plugs the question/concept into an AI tool (e.g.  ChatGPT  GPT4  Bing Chat) and discusses or analyzes the output.Evaluating AI output. Co-develop a rubric with students that describes the components of an effective essay  lab report  précis  technical manual  blog post  etc. Students prompt an AI tool to generate three versions of the assignment on a given topic and then use the rubric to evaluate the quality of the AI-generated versions.Improving upon/adapting AI-generated output. Students use an AI tool to draft text or code in response to a prompt. Students must then improve upon the AI-generated output. When students turn in their assignment  they must include both the AI-generated text and their improved version.Explaining the steps in an AI-generated solution. Students use AI to solve a math problem. Working from the AI-generated solution  they then work in groups to explain or analyze the steps that the AI tool used to arrive at the solution. Visualizing concepts with AI. Students select a concept covered in lecture or course readings. Students then prompt an Al image generator to create an image that represents the connection between the concept and daily life. They must then explain how the Al-generated image conveys the concept and its relationship to daily life. Students might also analyze the strengths and shortcomings of AI image generators.Exploring AI in your field. Students explore current applications of AI in the discipline of the course or in their major. Within the context of the discipline (or their major)  students examine both AI s advantages and limitations."

"Case Western Reserve University", "As generative artificial intelligence (AI) tools like ChatGPT and Bard become more advanced and ubiquitous  [U]Tech reminds users to protect private information—their own  and the university s. Entering data into a generative AI tool or service   said [U]Tech Vice President Miro Humer   is like posting that data on a public website. Artificial intelligence tools collect and store data from users as part of their learning process. Any information entered into an AI tool becomes part of its training data  which may then be shared with others Among the types of data that should not be used in AI tools are:Personal information: Home and email addresses  phone numbers  dates of birth  employee or student information  disciplinary or legal documents  patient records  other protected health information and personally identifiable information.Research materials: Grant proposals  unpublished data  research drafts  documents related to intellectual property and information subject to export control technology control plans.Information subject to local  state and/or federal protections: These include academic records  data requiring parental consent to provide or accept  data cited in executed nondisclosure agreements  numerical identification (e.g. driver s license  passport  etc.)."


"Umass Boston",  "AI Policy Ideas for Syllabus Faculty determine their own policy for generative AI use in their course. Depending on their policy  instructors can include text similar to that below to clarify the use of AI in their course. Prohibiting AI-based cheating: The use of AI or any other automated system for cheating purposes is strictly prohibited in this course. This includes the use of AI tools for generating papers  presentations  or any other assignments. Any such use will be considered a violation of the academic integrity policy and appropriate action will be taken. Ethical use of AI: Students are expected to use AI tools and resources ethically and responsibly. This includes ensuring that any data used in AI systems is properly licensed  and that any AI-generated content is appropriately cited. Additionally  any AI-generated content that is shared with others should be clearly labeled as such to avoid misrepresentation. Any violations of ethical use policies will be taken seriously and appropriate action will be taken. ChatGPT or other AI generative technologies can provide assistance to teachers in higher education in a number of ways. Here are a few examples:Answering questions: It can provide quick and accurate answers to a wide variety of questions related to the subject matter being taught. This can help teachers save time and provide students with accurate information  including topic options for projects. Offering feedback: Instructors can use it to evaluate student work and generate feedback on assignments  essays  and other projects. It can help identify areas of strength or make suggestions for improvement that you can personalize for your students prior to providing the feedback. Providing resources: It can help teachers locate and share relevant resources  such as articles  videos  content topics  and online tools that can help enhance the learning experience for students.Generating content: Instructors can use it to generate content  such as discussion prompts  quizzes  and assignments. This can help teachers save time and provide students with a wider range of engaging content that can be generated quickly and easily using effective prompts.Identifying research topics: Instructors can prompt Chat GPT or another Generative AI tool to explore potential research topics for themselves or student deliverables. It s important to further research all information collected by a generative AI tool to ensure accuracy of content and sources provided. Students can benefit from ChatGPT or other AI Generative technologies by using the tool as a tutor or learning partner. Some ideas:Answering questions: Students can ask any questions they may have related to their coursework or the subject matter being taught. It can pool multiple resources and provide efficient answers  helping students to better understand the material.Generating content: Students can use it to generate content for deliverables by helping them develop their ideas  structure their arguments  and identify relevant sources. It s important to further research any information collected by a generative AI tool to ensure accuracy of content and sources provided.Providing feedback: Students can use it to receive feedback on their work. It can help identify areas of strength and areas for improvement  and provide suggestions for how they can improve their work.Improving study skills: Students can use it to improve their study skills. For example  they can use it to generate study guides or flashcards  or to practice answering sample questions. This can help them better prepare for exams and retain information more effectively. Authentic assessment can be a helpful tool in preventing students from cheating when using ChatGPT or other Generative AI tools. Authentic assessment refers to assessments that measure students  understanding of the material in a real-world context  rather than just memorization or regurgitation of facts. Here are a few ways that authentic assessment can help prevent cheating: Assessing application  not just recall: Authentic assessments typically require students to apply their knowledge to real-world situations or scenarios. This type of assessment requires a deeper understanding of the material  rather than just memorization. Because of this  it can be more difficult for students to cheat by relying solely on ChatGPT or other AI language models to provide answers. Focusing on process  not just product: Authentic assessment often involves a process of inquiry or investigation  rather than just a final product. This process can be more difficult to cheat on  as it requires students to engage with the material in a more meaningful way. Additionally  authentic assessment can be designed in a way that makes it difficult for students to simply copy and paste answers from ChatGPT.Incorporating student choice and creativity: Authentic assessment often allows for more student choice and creativity  which can make it more difficult for students to cheat. By allowing students to choose their own topics or projects  for example  they are less likely to find pre-made answers on ChatGPT that they can simply copy and paste. Overall  authentic assessment can be a valuable tool in preventing cheating when using ChatGPT or other AI language models. By designing assessments that require deeper understanding  focus on process  and incorporate student choice and creativity  instructors can help ensure that students are engaging with the material in a meaningful way and not just relying on AI for answers.Generative AI language tools learn from the material they are exposed to from the users. We recommend that you use these tools to collect general information for your educational needs  but not provide the AI tool with materials unpublished or proprietary educational materials  as they could then be used to answer another person s question. There are ways that both students and instructors can protect their data when using AI-powered platforms: Read the privacy policy: Before using any AI-powered platform  students and instructors should read the platform s privacy policy to understand how their data will be collected  stored  and used. They should also look for platforms that are transparent about their data collection and use policies. Be mindful of sharing data: Students and instructors should be cautious about sharing novel ideas  personal  or professional data on AI-powered platforms that aren t previously published or copyrighted. Use the Generative AI tool as a tool to collect information for you  not a tool that collects your information"


"ASU",  "Resources for use in teaching Gen AI has the potential to address some of the biggest challenges in education today. Nonetheless  as educators and students  we face a new frontier as we navigate a world in which the distinction between content generated by AI and humans is rapidly blurring. To support conversations about how to include generative AI in your teaching  you are invited to participate in a new  Teaching and Learning with Generative AI  self-paced course designed by university experts to support Generative AI usage by faculty and staff. Click here to Self-enroll in the Canvas course now. This course includes foundational information about generative AI as well as practical ideas for implementation into courses. It is not necessary to complete the entire course. Each module can be completed individually to give you immediate access to the information you need. Whether you plan to incorporate Gen AI into your course or avoid it  explain your policies in the course syllabus. Sample language is here. The ASU Library Guide on Citing Generative AI Models shows examples of how to cite usage of Generative AI in the most common academic styles. As these conversations take place  this website will be continually updated with resources for the ASU community. Our goal is to approach generative AI in a way that embraces its benefits while providing recommendations and guidelines on how to prevent its misuse. Generative AI is a broad term that refers to a type of artificial intelligence (AI) application that is designed to use a variety of machine learning algorithms to create new content (text  images  video  music  artwork  synthetic data  etc.) based on user input that was not explicitly programmed into the AI application. Generative AI systems are  trained  by using complex algorithms to learn from an existing large corpus of datasets (often consisting of millions of examples) and to analyze patterns  rules and statistical structures from the sample data to be used in generating new content that is similar in style and characteristics to the original training datasets. There are many different types of generative AI applications and models  and while they might share a similar high-level definition of creating new content based on large sets of training data  they often represent completely different machine learning models  underlying neural network technologies and approaches to generating new content. You may have heard of recent popular examples of generative AI such as ChatGPT  DALL-E or StableDiffusion. While these are all examples of generative AI applications  DALL-E and StableDiffusion are text-to-image generators that use a type of neural network called generative adversarial network (GAN) to create a new image based on two systems (a generator and discriminator) surfacing an image of best fit based on the input parameters. By contrast  ChatGPT builds a transformer-based language model from a generative pre-trained transformer (GPT) to process sequential data  such as language  and then calculate the most probable words that will follow in a sequenced response. Generative AI and the broader classification of artificial intelligence have been identified by UNESCO as having the potential to  address some of the biggest challenges in education today  innovate teaching and learning practices  and accelerate progress  as well as calling for a human-centered approach to respond to inequalities"

"University of California  Riverside",   "Guidelines for Use of Generative Artificial Intelligence in Instructional Settings at UCR Generative Artificial Intelligence (AI) refers to a class of statistical models trained on massive amounts of data which are able to produce human-like responses in the form of text  computer code  images  audio  and video. Well-known examples include Google Bard and ChatGPT. Generative AI is being rapidly adopted throughout our economy and society  including in educational settings  while developers and users are still discovering its capabilities  benefits  and challenges. Governments are considering how to regulate these tools  but it is a near certainty that they are here to stay. Students  faculty  and staff therefore will need to learn how to utilize generative AI in their professional and personal lives. The purpose of these guiding principles and suggested practices is to provide a starting point for managing these tools in instructional settings at UCR. Guiding Principles 1. User accountability. Generative AI is capable of producing human-like responses  but these responses are not always accurate and/or may violate intellectual property rights. They also may perpetuate biases inherent in their design and/or training datasets. Anyone using generative AI for any purpose is accountable for the consequences of their use  regardless of the nature of the AI-generated content. This accountability applies to all aspects of teaching and learning  and includes but is not limited to violations of academic integrity policies  other institutional policies and rules  and applicable laws including those related to intellectual property. 2. Information security. Anything that is uploaded to a publicly available AI tool effectively enters the public domain. Instructional technologies including generative AI which have not passed a campus security review may be used with public data only. 3. Beneficial use. Like many other technologies  generative AI can be used in both helpful and harmful ways. Any use of generative AI in an instructional setting  by instructors or students  should aim to improve the learning experience for students and better position students for academic and post-graduation success. 4. Mission-aligned use. The use of generative AI in instructional settings should aim to advance the university s instructional mission. This includes a strong emphasis on equitable access  opportunity  and achievement. Students must have equal access to generative AI tools when used in instructional settings. 5. Local authority. Generative AI is a broadly applicable tool for which common standards of use have not yet been developed. Evolving standards tend to be highly dependent on local circumstances and context  and on the preferences and judgments of those with local authority. In instructional settings  this means the Instructor of Record has broad latitude to determine whether and how generative AI may be used  provided this use is consistent with applicable policies and rules governing data security and instruction at UCR. 6. Transparency. Generative AI is a potentially useful and powerful information source and thought partner which can enhance productivity and learning. Anyone who utilizes generative AI to assist with the creation of intellectual material must conform with prevailing ethical scholarship practices  rules related to plagiarism  and standards for representing intellectual products as one s own work. Suggested Practices for Instructors Be mindful of security and privacy concerns. Proliferation of generative AI offers benefits but also raises security and privacy concerns. Vulnerabilities can lead to data breaches and loss of intellectual property. Adhering to AI security and privacy practices is vital to protecting UCR s intellectual property and individual user data. August 2023 Get familiar with generative AI. Log into your UCR Google Bard account and experiment with different prompts (UCR has limited protections with Bard compared to ChatGPT). UCR has contractual guarantees with Google (GCP) and the AI tools they offer in Generative AI Studio but not with companies offering other AI tools (e.g.  ChatGPT  Anthropic  etc). This allows more freedom to explore and utilize Google s GCP AI tools while minimizing security and privacy concerns. More information can be found in this ITS knowledge article or contact michael.kennedy@ucr.edu for further details on Generative AI Studio in GCP. Consider how your course can benefit from generative AI. Are there any course management tasks that generative AI can help you with? Some instructors are using it to help with things like writing or rewriting sections of a syllabus  lesson plan  or content summary. This may be worthwhile if it frees up time for other higher-value instructional tasks. Similarly  are there any tasks that generative AI can help your students with  freeing up time for them to focus on higher-value learning activities? XCITE has additional resources to help you think this through. Check here for the latest instructional guidance  or contact XCITE directly about workshops and consultations. Check back often for updates since this is a rapidly changing area. Review and update your assessment methods. Generative AI poses both challenges and opportunities for student assessment. Consider implementing authentic assessment methods in your course. This refers to assessment methods that are consistent with the practical application of knowledge and skills  in the real world  – including what is likely to be widespread use of generative AI. If you choose to keep more traditional assessment methods  think carefully about the implications of generative AI for how you structure and administer these assessments. You may need to change the outcomes you are assessing and/or the conditions under which the assessment takes place. Learn from your colleagues. Professional practices for using generative AI are developing and undoubtedly will vary by academic discipline. Consider using any available standards in your discipline to guide development of your course standards. Also consider how you can achieve some degree of alignment of your course standards with those of your immediate colleagues  as students stand to benefit from some degree of consistency at the department-level. Talk about generative AI with your students. Establish clear expectations in your syllabus  including how students should cite and document their use of generative AI. XCITE has developed some suggested syllabus language which you can modify to suit your needs. For additional examples  consult this curated open-source document. Also establish clear expectations for each assessment to help avoid potential academic integrity issues. If you suspect academic misconduct  follow the standard campus procedures and keep in mind that automated AI detection tools can be inaccurate and prone to bias. Share your own ideas about generative AI with your students including how you are using it in your research and teaching. Remind students that over-reliance on generative AI can undermine their education  opportunities for intellectual growth  and likelihood of success on in-class assessments and in job interviews."

"University of Iowa",  "Guidelines for the secure and ethical use of Artificial Intelligence. Recent developments in the field of artificial intelligence (AI) have generated much discussion on the role of AI within higher education.  Many questions have been raised about risks related to security  privacy  and ethical considerations. Because this field is quickly evolving  guidance is needed to help understand and evaluate these risks.  The following are key points to understand: The University of Iowa does not have a contract or agreement for most AI tools or services. This means that standard UI security  privacy  and compliance provisions are not in place when using these technologies. As with any other IT service or product with no university contract or agreement  AI tools should only be used with institutional data classified as PUBLIC (Low Sensitivity).  See UI Data Classification Levels for descriptions and examples of each data classification. AI tools can generate incomplete  incorrect  or biased responses  so any output should be closely reviewed and verified by a human. AI-generated code should not be used for institutional IT systems and services unless it is reviewed by a human. Faculty  staff and students should be aware OpenAI Usage policies disallow the use of its products for other specific activities. Risks in this area are both positive and negative.  Since the potential benefits associated with responsible use of AI are significant  any decision on the use of AI must consider both the potential positive and negative impacts. 6A recent QuickPoll from Educause identified many areas of concern related to the field of AI  and a Special Report from the same organization serves as an opportunity for more in-depth exploration of the issues. The National Institute of Standards and Technology (NIST) has published a draft AI Risk Management Framework to help organizations use a formal approach to managing AI risks.  The Framework lists the following attributes of trustworthy AI: Valid and Reliable.  Trustworthy AI produces accurate results within expected timeframes. Safe.  Trustworthy AI produces results that conform to safety expectations for the environment in which the AI is used (e.g.  healthcare  transportation  etc.) Fair – and Bias is Managed.  Bias can manifest in many ways; standards and expectations for bias minimization should be defined prior to using AI. Secure and Resilient.  Security is judged according to the standard triad of confidentiality  integrity and availability.  Resilience is the degree to which the AI can withstand and recover from attack. Transparent and Accountable.  Transparency refers to the ability to understand information about the AI system itself  as well as understanding when one is working with AI-generated (rather than human-generated) information.  Accountability is the shared responsibility of the creators/vendors of the AI as well as those who have chosen to implement AI for a particular purpose. Explainable and Interpretable.  These terms relate to the ability to explain how an output was generated  and how to understand the meaning of the output.  NIST provides examples related to rental applications and medical diagnosis in NISTIR 8367 Psychological Foundations of Explainability and Interpretability in Artificial Intelligence Privacy-enhanced.  This refers to privacy from both a legal and ethical standpoint.  This may overlap with some of the previously listed attributes."

"Northeastern University",    "How is Higher Education Responding? Recent advances in AI are so new that educators are just beginning to consider what these new tools might mean for their teaching and their students learning. While it may be tempting to focus on potential negative consequences  AI also presents an opportunity to make modifications in our teaching that will improve and personalize student learning  and even to make creative use of the tools that will help prepare students to thrive in the technology enhanced world in which they will live and work. Address your concerns with positive intention. Phrases like  integrity    honesty   and  cheating  can suggest a stance of suspicion and punishment in relation to students. Talking with students about the benefits of  originality  and your hopes for how their work in your class will help them personally will help them understand your motivation for discouraging inappropriate use of AI. Consider revising your assignments to emphasize the work development process  and include an in person or recorded component. Set interim deliverables for major assignments that include rounds of instructor and peer feedback (e.g.  brainstorming questions/ideas  finding and annotating sources  outline/draft  final written product/presentation). Have students include a written explanation of how they used the feedback they received to improve their work  citing specific changes. Tap into the uniqueness of students lives. Have students share their prior experiences and goals for the future  then ask them to personalize their project work according to those interests. Consider taking a students-as-makers approach. Students will be more engaged because they see the relevance of what they are doing to their lives  and it will be much more difficult to get AI to do their work Avoid generic assignments such as term papers that are easy to create with AI  and consider having students present their work in several formats  such as a digital poster in place of or in addition to a written component. Consider adopting an I-Search format in which students get to identify questions that are personally interesting to them  tell the story of what sparked their curiosity  and document their process of finding answers that leverage their interests to address pressing concerns in the world. Emphasize the importance of questions. The ability to identify and refine compelling questions will become increasingly essential in a world where previously-identified answers can be accessed in a matter of seconds. The Right Question Institute has developed a process for question formulation that is relevant to cutting edge work in most contexts and disciplines. If you choose to lean into AI  this could be a preliminary step to prompting ChatGPT or another AI tool for a response. Lean into technology by  learning with  AI. ChatGPT and other AI tools challenge us to understand  access  prompt  corroborate  and incorporate information in new ways. Educational experiences that help students develop these capabilities will equip them to use AI effectively. For example  have students generate an AI response to a prompt  then critique and fact check the product. What questions can the tool answer adequately? What are its limitations? In what aspects is the response flat-out wrong? Another option is to have students develop successive drafts of a piece with ChatGPT  documenting how they refined prompts for each draft and reflecting on the strengths or limitations of the prompt in light of the output. They will increase their understanding and critical thinking about the topic while also developing key technology and information literacy skills."


"University of Cincinnati", "Why Students Need to Know about Generative AI Most of our students entering the workforce will be using AI daily  either by choice or by requirement. AI is less likely to eliminate jobs  than it is to transform jobs  and the difference in employability within a field will likely be down to who uses AI and who doesn t. Our students need us to allow them to use and critically discuss AI in the classroom  as applicable  while maintaining the rigor and values of our discipline areas. AI tools have the potential to generate academic outputs which meet the requirement of particular assessment types  including essays  reports   tests etc. This presents a number of key challenges for educators. As AI capabilities expand  it becomes increasingly difficult to ascertain what has been generated by digital tools and what has been generated by a human. As a result  generative AI poses an increasing threat to academic integrity in all disciplines  particularly to text-based and computational assignments. Generative AI tools  such as ChatGPT  can be used to take  shortcuts with assignments. Lines are blurring between plagiarism  fraud  and cheating: particularly where students are unclear on the boundaries between legitimate use of artificial intelligence (for example  spell-check  voice-to-text  grammar support tools etc.) and fraudulent use of AI-generated text presented as a student s own work.Modified from Generative Artificial Intelligence & Academic Integrity (Centre for Academic Practice  Trinity College Dublin  2023). The recently revised UC Student Code of Conduct lists  unauthorized use of artificial intelligence  as a form of academic misconduct under  Cheating  Use your syllabi to communicate whether and how generative AI tools can be used in your courses. Find links to sample syllabus statements in Resources on Generative AI and ChatGPT.Resources listed below include tips on responding to challenges related to use of AI in student work with changes to assessment design."


"University of Miami",  "Generative artificial intelligence (AI) tools  like ChatGPT  have the potential to transform our world. They can draft a story or essay  explain quantum physics in simple terms  create a new piece of music  code a new computer program  and even create an image  drawing upon all of the data from the internet to form their response to a given prompt. So naturally  when these tools became available last fall  it caused instructors across the world to question the originality of their students work. But rather than fret about this novel technology or require students to complete all their assignments and tests in person  University of Miami leaders hope that faculty members will embrace generative AI tools in their classes to fully prepare students for the future. This is an important change in our technology ecosystem  and it s crucial for us to understand and talk about these new tools with our students—to learn about its affordances and constraints—instead of pretending it s not there   said Kathi Kern  the University s vice provost for educational innovation  who also oversees the Platform for Excellence in Teaching and Learning (PETAL).  We re in a sandbox moment  so let s dip our toes in and be part of that conversation because we don t know yet all of the ways that this might reshape our work lives  cultures  and our educational practices.  Faculty members across the University already are experimenting with ways to incorporate generative AI into their classes  said Allan Gyorke  associate vice president for information technology and assistant provost for educational innovation. Computer science instructors in the College of Arts and Sciences have asked students to create code using generative AI  and then during class  they discuss whether the code is accurate  optimized  and if it could be improved. Marketing courses at the Miami Herbert Business School are planning to test the strength of AI tools to generate campaign or product pitches  and Frost School of Music faculty members are using it to deconstruct  analyze  and compose music. However  Gyorke and Kern caution that these tools are not foolproof. At times they offer inaccurate results and cannot distinguish between fact or fiction. Free tools like ChatGPT also collect personal data from everyone using them  which is why the University currently encourages the use of software like Adobe Firefly and Bing Chat Enterprise  since they do not collect a user s personal information. With a tool like ChatGPT  you don t have control over how your data is used   Gyorke said  adding that Bing Chat Enterprise uses similar technology to ChatGPT but instead keeps users data private.  We wanted to provide an AI chat tool that could be used in a more secure way.  Still  there are plenty of ways to safely utilize the new tools. And both Gyorke and Kern look forward to hearing how other faculty members are exploring generative AI. When two of Kern s students missed an in-class quiz in a course she was teaching in Rome last spring  she asked them to use AI tools to respond to a written prompt she had given the rest of the class. Then  she challenged the students to critique the response as if they were teaching assistants and to offer suggestions about how to expand on it. Kern also envisions students using image generating tools—like Adobe Firefly—to create illustrations of abstract topics  like photosynthesis or the theme of a novel.  Teaching students how to create prompts for generative AI tools is something we can do right now that s exciting   Kern said.  But the availability of this technology puts the onus on us as instructors to make our assessments of student learning more authentic and less task oriented. This means it s more important than ever to teach critical thinking skills  content knowledge  and powers of analysis. So that students can evaluate the output of generative AI for themselves.  Because the technology is still evolving  administrators also want to offer guidelines for students and faculty and staff members about the use of generative AI on campus. Chiefly  they caution anyone in the University community against putting personal student or patient information into these tools. They also ask faculty members to avoid using generative AI detection tools for assessments like papers and tests  because these programs are often prone to error and unfairly target students whose home language is not English  Kern pointed out. The rapid availability of new generative AI tools has sparked new collaborations among University faculty members. The following are some generative AI resources for students and faculty and staff members  as well as opportunities to join the campus conversation about these new tools. The AI Guidelines for Teaching  Learning  and Scholarship  hosted on the PETAL website  provide guidance for faculty members  examples of using generative AI  and sample syllabus language. Two new tools—Adobe Firefly and Bing Chat Enterprise—are free to the University community. The University of Miami Information Technology Department has facts about these tools and generative AI on their new AI Tools page  which will be updated as new tools are reviewed and licensed. Navigating AI  from the Division of Continuing and International Education  includes general information about AI tools as well as recommendations about the safest ways to use them for teaching and learning."


"University of notre dame",  "Generative AI Policy for Students You may have received an email this week from the University s Chief Information Officer highlighting the need for caution when using generative AI (such as ChatGPT  etc.) with personal and/or sensitive information and the need to protect confidential data. Another area of concern is the possibility that inappropriate use of these tools will interfere with your ability to successfully engage with and master course material  given the potential that they create for academic dishonesty. Below is the University s policy regarding the use of generative AI in your courses. This new technology offers numerous ways to support your education  such as making study guides or flash cards or providing help with understanding difficult concepts However  misuse of generative AI impedes the University s mission to develop the gifts and talents that you bring to the ND community  and using it as a substitute for genuine engagement with your coursework runs counter to the heart of education itself. Think carefully about the difference between supplementing your education and replacing it. With this in mind  remember that representing work that you did not produce as your own  including work generated or materially modified by AI  constitutes academic dishonesty. Use of generative AI in a way that violates an instructor s articulated policy  or using it to complete coursework in a way not expressly permitted by the faculty member  will be considered a violation of the Honor Code. Finally  Undergraduate Education at Notre Dame and the Office of Academic Standards would also like to support you as you navigate the impacts of generative AI on your education and career path. If you have concerns about academic dishonesty  or about generative AI impacting learning in your classes  email honor@nd.edu and let us know."

"Virginia Tech", "You may be hearing an array of opinions about the implications that generative AI (Gen AI) tools might have for the future of teaching and learning. Any time a new technology like Gen AI emerges and captures the public s attention  initial reactions tend to be polarized. Some see AI as a threat to higher education  while others view it as a positive force for reshaping the way we teach. In the midst of these competing and conflicting perspectives  TLOS recommends a measured approach. We ask faculty to consider the following suggestions as you make decisions about the courses you teach. Because these tools are changing rapidly  we will continually evaluate their use at Virginia Tech and revise our guidance as the situation evolves. Generative artificial intelligence (Gen AI) describes several types of AI that are capable of creating new text  images  code  audio  or other types of content. Tools such as ChatGPT have been trained using very large collections of existing media to generate human-like responses to user-authored prompts. For text-based content  these large language models can be used to answer questions  write essays or articles  create lesson plans  and much more. The content creation process is limited by the tool s training media and the user prompt Gen AI tools are becoming increasingly influential across many industries  making it essential for students to learn how to utilize these tools within their specific fields of study. However  the potential for misuse of Gen AI also raises concerns for evaluating student learning. Interrogating the risks and opportunities of these tools in different types of courses and disciplines (course size  delivery modality  topic  etc.) is key to finding ways to leverage their power while limiting their abuse. The true impact of these technologies remains to be seen. It is not likely to cause the end of higher education  and it is not likely to be the panacea some expect it to be. Deciding how to apply and constrain these tools is likely to be a nuanced issue that will require thoughtful and informed debate.Become familiar with generative AI tools in order to have an informed perspective See the links below for some basic introductions to the technology and its implications Consider the Honor Code and its applicability to generative AI tools.The Office of Undergraduate Academic Integrity offers the following guidance: While most students largely engage in honest behavior in the classroom  some may choose to use tools such as ChatGPT to engage in academic dishonesty. Please continue to be clear in your expectations with your student related to the Undergraduate Honor Code and the use of AI software just as you would other websites that may provide students with means to engage in academic dishonesty. The unauthorized use of ChatGPT and other AI software may fall under several definitions of academic dishonesty in the Undergraduate Honor Code. The Graduate Honor System reviews each case in its own context. Faculty are encouraged to provide clear and precise guidance about when or if the use of tools such as ChatGPT are allowed  encouraged  or prohibited and candidly discuss with students the learning value of completing an assignment with or without such tools. GHS decisions about any potential violation will be based on what guidance faculty provided. Avoid being drawn into a confrontational mindset regarding these tools.Given the obvious implications for academic integrity  tools are being developed and promoted that may provide some perspective on whether or not student submissions were written by AI. Due to the evolving nature of AI solutions  these tools are never going to be 100% accurate  and an overreliance on a tool to  catch  anyone using AI is likely to lead to a slippery slope of ineffective and highly stressful interactions with students Set clear expectations for your students regarding the use of generative AI/ChatGPT. Directly address the reasoning behind any restrictions you decide to implement. Consider updating course documentation about academic integrity to include a statement specifically addressing the use of generative AI/ChatGPT (see ideas below). Explore potential changes to your course design and/or assessment strategies Consider incorporating course assessment practices aligned with principles of authentic assessment such as seeking to replicate professional experiences  expecting a task-focused demonstration of understanding  and providing opportunities for practice with feedback. (See Teaching Resources - Assessing Student Learning - Authentic Assessment from Indiana University for some more detailed ideas.) Consider allowing multiple options for action and expression in your assessments. This is a principle of Universal Design for Learning that suggests students be allowed to select from various methods and technology tools to showcase their understanding and support their learning. Proactively incorporate generative AI/ChatGPT into your instructional strategy  inviting students to use these tools to spark creativity  or to test and evaluate the accuracy of their output. In the end  our suggestion is that these tools represent an evolution of existing information technologies and that we should carefully consider how to utilize them to improve our shared experience."
"The Geroge Washington University",   "Guidelines for Using Generative Artificial Intelligence at the George Washington University April 2023 The Promise of Generative Artificial Intelligence The wide availability of Generative Artificial Intelligence (GAI) tools  such as ChatGPT and other large language models  is driving an ongoing conversation about their academic uses. GAI tools represent an exciting addition to the learning process that can be deployed in innovative ways to advance learning objectives. This document provides some guidelines for the use of GAI in connection with academic work at the University. The Office of the Provost encourages the entire University community to embrace these technologies through creative uses and applications. Faculty are invited to make thoughtful use of GAI tools in their teaching and research. Used properly  GAI tools can enhance the design of lessons  assignments  and assessments. Our students will use GAI tools for the rest of their lives. There are many productive ways in which they might use them as students  consistent with stated course policies and objectives. Examples include: brainstorming ideas; summarizing and translating content; explaining new concepts to aid comprehension; generating counter-arguments; suggesting titles; debugging code; gathering sources; and formatting references. Designing Assignments Even as we are learning ourselves  we must teach our students to use GAI tools effectively and responsibly: to draft appropriate prompts; to think critically about the proper use of the tools and their possible effects on society; to evaluate their outputs with respect to accuracy  bias  and equity. Exercises might include having students formulate effective prompts; identify superficial rhetoric in GAI-generated content; and evaluate GAI-generated arguments for soundness and logical validity. Students could be asked to fact-check  criticize  and/or edit GAI-generated content for credit. The Instructional Core in the Division of Libraries and Academic Innovation has provided useful guidance for instructors on Responding to Generative Artificial Intelligence (AI) Tools. The Office of the Provost encourages instructors to consult these resources. Encouraging Responsible Use For all their promise  GAI tools misused could interfere with learning objectives and impair the development of students writing  analytical  and technical skills. There are also legitimate concerns about academic ethics  accuracy  citation of sources  and cheating. The Office of Student Rights & Responsibilities maintains a Faculty Guide to Clarifying Academic Expectations that directly addresses the use of GAI tools in connection with academic work. An instructor who suspects an academic integrity violation should consider submitting a Charge of Academic Dishonesty. Note: the Law School and the School of Medicine and Health Sciences maintain their own codes of academic integrity  so the guidance contained in this document does not apply to these schools. The Office of the Provost encourages instructors to state explicitly and affirmatively their expectations regarding student use of GAI tools. Instructors should specify in writing the permitted and prohibited uses of GAI tools in their courses. Instructors might 1) generally permit the use of GAI tools; 2) generally forbid their use; or 3) permit their use for certain purposes on certain assignments  but not others. If an instructor wishes to permit certain uses of GAI tools  such uses must be set forth explicitly in the course syllabus and/or assignment instructions. Below is some model language for the three permission options: General Permission Generative Artificial Intelligence (GAI) tools such as ChatGPT are becoming important resources in many fields and industries. Accordingly  you are permitted to use such tools to generate content submitted for evaluation in this course  including [papers; take-home examinations; specified other assignments]. You remain responsible for all content you submit for evaluation. [Instructors might also wish to include language regarding pitfalls  such as the following:] You may use GAI tools to help generate ideas and brainstorm. However  you should note that the material generated by these tools may be inaccurate  incomplete  or otherwise problematic. Beware that use may also stifle your own independent thinking and creativity. [Instructors might also wish to include language regarding citation  such as the following:] If you include content (e.g.  ideas  text  code  images) that was generated  in whole or in part  by Generative Artificial Intelligence tools (including  but not limited to  ChatGPT and other large language models) in work submitted for evaluation in this course  you must document and credit your source. For example  text generated using ChatGPT-4 should include a citation such as:  ChatGPT-4. (YYYY  Month DD of query).  Text of your query. Generated using OpenAI. https://chat.openai.com/.  Material generated using other tools should be cited accordingly. Failure to do so in this course constitutes failure to attribute under the George Washington University Code of Academic Integrity. General Prohibition By submitting work for evaluation in this course  you represent it as your own intellectual product. You may not submit for evaluation any content (e.g.  ideas  text  code  images) that was generated  in whole or in part  by Generative Artificial Intelligence tools (including  but not limited to  ChatGPT and other large language models). Doing so in this course constitutes cheating under the George Washington University Code of Academic Integrity. [Instructors might also wish to include language regarding papers about AI:] Although this course generally prohibits use of GAI tools  the instructor may choose to grant an exception if you propose to write a paper about [some aspect of artificial intelligence]. Such an exception must be granted in writing (e.g.  email) to avoid the danger of misunderstanding. Selective Permission By submitting work for evaluation in this course  you represent it as your own intellectual product. You may not submit for evaluation any content (e.g.  ideas  text  code  images) that was generated  in whole or in part  by Generative Artificial Intelligence tools (including  but not limited to  ChatGPT and other large language models) unless the instructor has explicitly granted permission to do so. Your instructor will explain to you the uses of GAI tools that are permitted or prohibited in this course  including on what specific assignments use of GAI tools is permitted. Submitting content for evaluation that was produced in whole or in part by GAI tools  except for the specific purpose(s) and assignment(s) discussed and authorized by the instructor  constitutes cheating in this course under the George Washington University Code of Academic Integrity. [Instructors choosing the Selective Permission option might also wish to include some or all of the additional potential language from the General Permission and General Prohibition options  above.] Default Rules In the absence of explicit directions to the contrary from instructors  the following default rules apply at the University. 1. Work submitted for evaluation is represented as the student s own intellectual product. Students may not submit content (e.g.  ideas  text  code  images) for evaluation that was generated  in whole or in part  by Generative Artificial Intelligence tools (such as ChatGPT and other large language models). Doing so without instructor s explicit permission constitutes cheating under the Code of Academic Integrity and is therefore prohibited. Examples (illustrative only) of conduct that is prohibited unless explicitly permitted by the instructor: • A student types a prompt into a GAI tool and pastes all or part of the generated content into their answer on an out-of-class assessment or test. • A student types a prompt into a GAI tool and incorporates all or part of the generated content into an essay submitted for evaluation  without proper attribution to the GAI tool. 2. Students are permitted to use GAI tools to generate content that is not submitted to an instructor for evaluation. For example  using GAI tools to study for examinations  tests  and quizzes is permitted. Likewise  on assignments where the use of the Internet is not otherwise prohibited by the instructor  GAI tools may be used for learning  studying  and brainstorming. Examples (illustrative only) of permitted conduct: • A student types a prompt into a GAI tool and reviews the generated content to help them study for a test. • A student types a prompt into a GAI tool and uses the generated content to help them brainstorm ideas for a term paper or research project. 3. Unless the instructor explicitly states otherwise in advance and in writing  the use of GAI tools during any assessment (e.g.  examination  test  quiz) whether taken in the classroom or elsewhere  constitutes cheating under the Code of Academic Integrity and is therefore prohibited. This prohibition includes assessments for which the use of the Internet is otherwise permitted. Examples (illustrative only) of conduct that is prohibited unless explicitly permitted by the instructor: • While taking an out-of-class ( take-home ) test on which Internet use is generally permitted  a student types a prompt into a GAI tool and incorporates some or all of the generated content into their submitted answer. • While taking an in-class quiz on which Internet use is generally permitted  a student types a prompt into a GAI tool and incorporates some of the ideas generated into their submitted answer. • Before taking an in-class quiz on which Internet use is generally permitted  a student types a prompt into a GAI tool  saves the generated content to a document  and pastes some or all of the text into their submitted answer while taking the quiz."

"University at Buffalo SUNY",  "Artificial Intelligence Guidance UB has no universal policy about student use of artificial intelligence. Instructors have the academic freedom to determine what tools students can and cannot use in pursuit of meeting course learning objectives. This includes artificial intelligence tools such as ChatGPT.Because there is no universal UB policy about artificial intelligence tools  instructors need to give students clear guidance about what is and is not allowed in their course overall and/or on each assessment. In the same way students are told when exams are  open book  or not  they need to be told when AI tools are allowed or not. This should be done orally in class when discussing each and every assignment or exam as well as in your syllabus. Deciding whether to allow students to use artificial intelligence on course assessments can best be determined by evaluating how that use affects fulfillment of the learning objectives. If an AI tool can be used to complete low-level work that students can already do  for example  it can be used a head start to propel students toward higher level thinking. But if use of the AI tool replaces the student thinking and process that you intend to assess  it should be disallowed. Instructors should make the rationale for their rules around AI as overt as possible. Students don t always understand how the assessments instructors design for them lead to fulfillment of learning objectives. As the expert  it is up to the instructor to help students identify in what ways using artificial intelligence can help or hinder those learning objectives. The more students understand why a tool is disallowed  the more likely they are to respect that rule. Some of the common ways instructors can identify use of AI tools include: Misalignment of student response with what was taught in class. Odd errors in content. (When AI makes these mistakes  they are called  hallucinations. ) Formulaic prose at a general level  lacking specific details. What should I do if I suspect a student has used AI in violation of my guidelines The procedure for pursuing this suspicion is the same as in any academic dishonesty case  and instructors should follow the consultative resolution process dictated by the academic integrity policy. There are some additional considerations that may help here  however  including: Entering your assignment prompt in an AI tool yourself. This will show you the type and tone of output a student would get. Consider doing this three or four times to see the extent of possible outputs.Running the student assessment through an AI-detection tool. Although there are mixed reviews about these tools (they are only providing a  likelihood  that something was generated by AI)  they are a good place to start. Turnitin has an AI-detection tool included in UB s Brightspace package. This is different from  and in addition to  the Turnitin plagiarism-detection tool. You can set this as a default so that student work will run through it. Additionally  there are many other free AI-detection tools you can access to collect multiple reports on the likelihood of AI-generation. Comparing the student s work to an in-class or previous writing sample.Overtly discussing both the content of the assessment and the process the student took to create it at the consultative resolution meeting. If the student prepared the work  they should be able to talk to you about how they did it and what it includes. They may even be able to show earlier drafts  time-stamped documents  etc. It is good to be prepared with discussion starters for this conversation. Whenever an instructor believes that it is  more likely than not  that academic dishonesty occurred  they are obligated to report it to OAI. This standard of evidence is called  preponderance.  Instructors do not need the certainty of  beyond a reasonable doubt.  In the case of unauthorized use of AI  preponderance can come in many forms. If you are uncertain about this  you can contact the Office of Academic Integrity for guidance. While unauthorized use of AI on assessments can fall into a number of the violations described in the policy  it is commonly reported to OAI as  falsifying academic materials.  This violation includes   submitting a report  paper  materials  computer data or examination (or any considerable part thereof) prepared by any person or technology (e.g.  artificial intelligence) other than the student responsible for the assignment.  Since plagiarism implies violating ownership of ideas or language and AI can t have ownership  these cases are typically not processed as plagiarism under UB s policy. There is no foolproof way to do this  but there are some steps you can take to prevent unauthorized AI use on assessments: Move assessments to in-class and proctor well. Apply Lockdown Browser and Respondus Monitor for remote assessments. This ensures that the student cannot access an AI tool on their test-taking device and allows you to observe if they attempt to use another device. Include an oral component to your assessments so students can explain what they ve done and what they know. Consider redesigning your assessments. The more you can make them specific to course content  class materials  and student experience  the less helpful AI tools are. Contact the Office of Curriculum  Assessment and Teaching Transformation (CATT) for more guidance and support on assessment redesign."


"New York University", "NYU s Private Generative AI Service Pilot For NYU community members  NYU IT is offering early access to a private generative AI tool pilot. In this case  private means run by NYU as an internal  secure  managed service. The pilot enables you to submit project ideas and request access to utilize the private generative AI pilot for use in research  instruction  or administrative activities performed by Faculty and/or Administrators in NYU. If you have a project or idea you believe would benefit from a protected  private Open AI ChatGPT service you should request access by submitting your idea. Your project ideas will help us explore a variety of potential uses for Gen AI tools and learn as a community through this experience. Once submitted  project participants are notified by email within five business days regarding next steps. Next steps may include additional questions to help scope out the project  approval of access to the tool  and the completion of a data use agreement and other relevant items to best understand your project submission. Please keep in mind the following factors: Access to the service pilot is restricted to NYU community members and their accepted projects and any information entered is governed by NYU s data privacy policy. The pilot service is a shared resource; individual access to the web portal occurs on a rolling basis to ensure equitable access. Once submitted  project participants are notified by email within three business days regarding next steps. That may include additional questions to help scope out the project  approval of access to the tool  requirement to sign a data use agreement  and other relevant items to best understand your project submission. If you have a non-sensitive for generative AI  please use a public tool instead. Please remember that it is of utmost importance that any use of generative AI applications be in full compliance with existing policies and the law: You must not use any generative AI application in connection with or to generate clinical  student  faculty  or employee documentation  such as field notes or named letters. You must not use any generative AI application with any protected health information  even if de-identified  or any other legally protected information. You must not use any generative AI application with any clinical or human subjects research data  even if de-identified. Do not disclose to any generative AI application any confidential business information. Do not permit any generative AI application to record or otherwise upload recordings of internal meetings or other non-public NYU activities. Do not rely upon any generative AI applications or generative AI application results in your work at NYU. You are responsible for independently verifying any generative AI content that pertains to academic or administrative work."

"University of North Carolina at Chapel Hill",  "To the Instructor:The Committee has developed the following set of guidelines for instructional applications of generative AI. These guidelines aim to establish a framework for the ethical and responsible employment of AI tools in your teaching. Please review these recommendations and integrate them into your instructional practices  tailoring them as necessary to suit your specific course requirements. It is also recommended that you inform your students about the intended use of AI in your course on the first day of class.Given the rapid pace of advancements and instructional applications in generative AI  we anticipate these guidelines to continue to evolve. Thus  if you have any questions or feedback  please do not hesitate to reach out to Dana Riger at driger@unc.edu or your academic unit representative.Teaching Use Guidelines for Generative Artificial Intelligence ChatGPT and other generative Artificial Intelligence ( AI ) tools that can produce text  images  and other media are now widely available. Integrating AI technology into teaching can enhance the learning experience for our students. AI can be a powerful tool to assist instructors in delivering effective instruction  promoting engagement  and facilitating personalized learning. At the same time  AI can create significant disruptions to learning that yield challenges and opportunities for teaching practices. It is crucial to address classroom and pedagogical challenges responsibly  adjust teaching approaches  and maintain a balance between AI use and human interaction to ensure a holistic educational experience. AI tools are important for instructors to understand and use effectively  appropriately  and ethically. Instructors are responsible for understanding the uses and limitations of AI for both education and the workplace. How output is arrived is not clear as the internal processes used to produce a particular output within the generative AI cannot be determined. The output is based on existing data (often scraped from online sources) and may reflect biases that should be acknowledged; it may also be inaccurate or entirely fabricated  even if it appears reliable or factual. AI evokes a range of intellectual property concerns; sourcing and ownership of information is unclear  and the status of AI output raises numerous questions—e.g.  is output equivalent to a published resource? What citational responsibilities are in place for various AI interactions The following sections offer philosophies for AI and teaching and specific guidelines for approaching these AI tools and features. Unless your college  school  or department provides other guidelines  you should use these. Usage of generative AI in your teaching should be based on the following principles: AI should help you teach  not teach for you. AI can serve as a complementary tool to support instructors  but is not a replacement for human interaction. Instructors should continue to play an active role in the teaching process and maintain direct engagement with students. Therefore  make sure you understand how AI tools help achieve learning goals and improve student understanding. Balance quality and timeliness for grading purposes. Take into consideration whether AI is suitable for grading an assignment. If it is deemed appropriate  make sure to verify that the output generated by the AI accurately reflects the actual accomplishments or feedback you would otherwise provide to students. Further  think about the potential discomfort or opposition from students towards AI-driven grading and consider explaining your decision to employ it. You are 100% responsible for your teaching materials. You are responsible for any mistakes made by AI if you choose to incorporate its output into your lectures or other course content. If you are unsure about the accuracy of a statement  it is your responsibility to research and verify it before using it. This includes properly attributing ideas  ensuring the accuracy of facts  and using correct sources. The use of AI should be open and documented. It is essential to be transparent and document the use of AI in your work. Inform your students about the use of AI in generating course assignments  exam questions  and other relevant materials. Provide explanations or demonstrations of how AI is employed  helping students understand the technology s role and limitations. Adjust teaching practices to address AI use concerns. Complement any limits placed on AI use with activities that promote intellectual aims challenged by uncritical AI practices. For example  emphasize in-class generation of knowledge and foreground process-based learning. Consider incorporating oral- or performance-based activities and identify opportunities for reflection and meta-cognition. Select AI tools that align with course objectives. Utilize AI to align teaching strategies with course objectives  making sure that it enhances rather than overshadows the learning process. AI tools should be selected to support students learning needs. Consider ease of use  accessibility  and the potential for personalized learning. Instructors should ask themselves what they are trying to help students learn and which AI tool best facilitates that learning. The integration of AI should be purposeful and beneficial to the learning process  rather than being incorporated merely for its own sake. Ensure that AI use is inclusive. Make sure that the AI tools and instructions provided are accessible to all students  including those with disabilities or diverse learning preferences. Consider the needs of all students when selecting or designing AI-based instructional materials. Facilitate and encourage critical thinking. While AI can provide valuable insights and assistance  instructors must encourage students to think critically  and question information provided by AI tools. Foster a culture of inquiry and intellectual curiosity and assist students in developing an AI literacy. Emphasize human skills. Highlight the importance of human skills such as empathy  creativity  and critical reasoning alongside the use of AI. Challenge uncritical attempts to ascribe human characteristics to AI. Teach students to leverage AI as a tool while emphasizing the unique qualities that humans bring to the learning process. Specify AI policies for your course. Consider tailoring university or departmental guidelines to your specific course. Any guidelines or limits you specify for student submissions supersede the university guidelines. As different instructors and schools may have different guidelines  remind students regularly of your AI policies and how they can use these tools appropriately in your course. Avoid entering confidential or personal data into AI tools. Putting confidential or personal data (e.g.  your students One Card details ) into these tools exposes you and others to the loss of important information. Therefore  do not do so. Stay informed. Keep up to date with advancements in AI technology and instructional best practices. Stay informed about emerging AI tools  research studies  and ethical guidelines related to AI in education. Engage in professional development opportunities to enhance your AI integration skills. Lecture Enhancement: You can utilize AI-powered tools to create visually engaging presentations  such as interactive graphs  visualizations  or simulations. You can also use AI-based language models to generate real-time examples  case studies  or scenarios to enhance lecture delivery and illustrate concepts effectively. Assessments and Exams: While AI tools can quickly generate a large number of questions  it s important to review and modify these questions as needed and to ensure the level of learning being assessed is appropriate. AI can also be used to create simulations or interactive assignments that require students to apply what they have learned to solve real-world problems. These can be generated by instructors for formative or summative assessments or by students for self-assessment. Plagiarism Detection: Exercise caution while utilizing AI plagiarism detection tools  as their accuracy is not guaranteed and there may be instances where they fail to detect plagiarism. Additionally  be aware that individuals could potentially exploit AI technologies to circumvent detection software. Vigilance and mindful use of these tools is recommended. Student Support: You can integrate AI chatbots or virtual assistants to provide timely and automated responses to common student queries  freeing up instructor time. You can also use AI systems to suggest supplementary resources or personalized study plans based on individual student performance. Critical Thinking: Provide guidance to help students identify biases and misinformation associated with AI. Develop activities that prompt students to participate in iterative  inquiry-based thinking while using AI tools. Student Correspondence. Instructors should consider incorporating language into their emails or email signatures to disclose the use of AI-generated text when communicating with students. For example   The content of this email might include AI-generated responses; however  they have been examined and confirmed by the sender. Ethical sourcing: When using AI tools  ensure that the technology and data sources used are ethically obtained and comply with privacy and security regulations. Avoid using AI tools that may compromise student privacy or rely on biased or discriminatory data. Reliability: Before implementing an AI tool  thoroughly evaluate its reliability and accuracy. Consider factors such as the technology s track record  user reviews  and endorsements from reputable sources. Pilot test AI tools before incorporating them into instructional practices. Documentation: Include a general statement in the syllabus acknowledging the use of AI in the creation of certain course materials. This statement serves to inform students about the integration of AI technologies and their impact on the learning experience. Additionally  it is recommended that instructors address the importance of following student use documentation guidelines."


"University of Pittsburgh",  "Teaching with Generative AI The revolution in the capabilities and availability of generative AI tools has caused both excitement and consternation in higher education  not always in equal measure. At the Teaching Center  we acknowledge both the potential benefits and the challenges of using generative AI technologies to enhance our academic work  and especially to support our teaching and learning  across the entire Pitt community. As we explore the applications of generative AI for improving the quality of teaching  we also recognize that it is imperative to uphold the principles of academic integrity and ethical conduct. We understand that all instructors will approach generative AI in their classrooms according to their own levels of knowledge  skill  and comfort with this new technology. We encourage all faculty to make use of this resource page and future AI related workshops and events as you navigate this new terrain. We also strongly recommend including an AI syllabus statement that will clearly communicate your expectations to your students in all your courses. Below you will find several suggested approaches  and samples of syllabus language  which can be used or modified for your own situations. suggested Syllabus Statements. Intellectual integrity is vital to an academic community and for my fair evaluation of your work. All work completed and/or submitted in this course must be your own  completed in accordance with the University s Guidelines on Academic Integrity. You may not engage in unauthorized collaboration or make use of ChatGPT or any other generative AI applications at any time. Some Use of Generative AI Permitted Under Some Circumstances or With Explicit Permission During this class  we may use Generative AI tools such as ChatGPT. You will be informed as to when  where  and how these tools are permitted to be used  along with guidance for attribution. Any use outside of this permission constitutes a violation of Pitt s Guidelines on Academic Integrity [PDF]. Broader Use of Generative AI Permitted/Encouraged Within Specified Guidelines The use of Generative AI tools  including ChatGPT  is encouraged/permitted in this course for students who wish to use them. You may choose to use AI tools to help brainstorm assignments or projects or to revise existing work you have written. However  to adhere to scholarly values  students must cite any AI-generated material that informed their work (this includes in-text citations and/or use of quotations  and in your reference list). Using an AI tool to generate content without proper attribution qualifies as academic dishonesty Potential teaching uses and examples The capacity of generative AI–both to streamline teaching tasks and to facilitate learning activities and assessments–is practically boundless. We offer a few examples below: Use prompt engineering strategies–like specifying length  format  or context or asking a generative AI tool to respond as a specific persona or to address a specific audience–to improve the quality of generative AI output. For example  you could copy/paste an assignment into ChatGPT and ask the AI to act as an undergraduate student in your discipline and identify questions and potential challenges of the assignment. Include a policy on your syllabus that clearly defines when  how  and how much students can use AI in your courses. If you decide to integrate AI into your teaching  definitely teach students about the capabilities  limitations  and best practices for using generative AI tools before they use those tools in class. Ask students to complete a written assignment  then use AI to generate a version of the same assignment. Instruct students to compare the two and reflect on their work. Instruct students to assign an AI tool a specific persona and roleplay a scenario Have students use AI to make a creative work that helps clarify or illustrate a course concept. Ask students to fact check and critique AI output.Encourage students to treat AI like a study buddy. Students can quiz themselves on course concepts using AI. Language-learning students can practice their language skills by chatting with AI. Teach students prompt engineering and ask them to complete authentic tasks that they will perform in their future professions using AI. Give students the option of using AI tools to revise their writing or code. Encourage students to use AI to brainstorm and refine topic and research question ideas Repository of sample assignments Sample Assignments That Integrate Generative AI  Created by Pitt Faculty (must be logged into Canvas to access). This living collection of sample assignments will continue to grow  evolve  and adapt as instructors innovate and share their discoveries with each other. We would like to see and share (with your permission) the fruits of your thinking. If you would like to submit an assignment to the repository  please email us the assignment  along with the course title and learning objectives Ethical use As a new and rapidly evolving tool that will powerfully affect education and most other social and cultural domains  generative AI presents fundamental concerns about how AI tools can or ought to be used. As those concerns develop and as ways of addressing them emerge and change in turn  we will all need to pivot frequently and reassess how we use those tools and how we encourage or monitor how our students use them With the understanding that these principles are not carved in stone  here are our top five considerations for promoting the ethical use of generative AI tools: Keep considerations of ethics on your radar. Be mindful of the need for vigilance  particularly in the early stages of this technology. Identify the ethical considerations relevant to your discipline  as well as considerations for integrating AI into teaching and learning.Recognize diversity  equity  and inclusion concerns as central to the use and proliferation of AI tools. Consider the accessibility of generative AI tools to all users and how AI  which uses the publicly available data it was trained on  can perpetuate biased  discriminatory  or inaccurate information. How will you help students learn to identify and mitigate these issues with AI output? Learn who can use or own the data that AI tools receive as input or produce as output. Large language models store input to use as training data. Explain to students that AI tools store and use their data and avoid inputting student-generated content into AI without their consent. Consider and discuss potential copyright concerns with students. For example: Who owns the product of the AI tool: the user who crafted the initial prompt  the rights-holder of the data that the AI consulted to generate that output  or the owner of the AI tool itself? Consider how our uses of generative AI technology will affect the future. Among the many potential implications of the impact of AI on data governance  politics  the media  and the environment  these tools also call upon us to explore what and how we teach students about using AI. How they see us model the role of users  how we restrict and permit their uses of the technology  and how we train them to deploy these tools in their later lives and careers are all questions of significant reach and impact. Encourage students to be critical consumers of these technologies. Generative AI tools will extend our reach and grasp for the foreseeable future  and it s important to encourage students to use AI productively. However  an uncritical use of generative AI tools–one that assumes that AI-generated material is always correct  accurate  fair  and unbiased  for example–can be harmful. Make your students skilled but skeptical consumers of these new tools. Encourage students to validate AI output using other sources"

"University of Colorado Boulder",  "AI ethics & higher education Casey Fiesler is an associate professor in the Department of Information Science who studies technology ethics and online communities. She s posted several videos about ChatGPT to her popular TikTok channel and has explored how educators might use AI platforms to help students learn. AI strengths and weaknesses Daniel Acuña is an associate professor in the Department of Computer Science and develops AI tools to mine scientific knowledge from vast  unstructured datasets. He recently discussed the strengths and limitations of ChatGPT in an article for The Conversation. AI in business Kai Larsen is associate professor in the Leeds School of Business and co-author of the book Automated Machine Learning for Business. He used ChatGPT to write a children s book about his pet bird called Dewey the Unhappy Cockatoo and can discuss the future of AI in business  education and more AI and the future of K-12 education Peter Foltz is a research professor in the Institute of Cognitive Science who has decades of experience designing  large language models ––a class of AI tools that includes ChatGPT and Bard. He is executive director of a $20-million National Science Foundation institute  which explores how AI might transform K-12 classrooms around the world. On AI and the law Harry Surden  professor of law  is a former software engineer who focuses on the intersection of law and technology  including artificial intelligence and legal automation. He can explain why ChatGPT s launch has surprised even AI experts and why it s taken Google s Bard so long to catch up. He can also discuss how LLMs can have the potential to change society  from both addressing and contributing to discrimination to improving access to justice. Surden has written extensively on topics ranging from ethics of AI in law to values embedded in legal artificial intelligence."

"University of Illinois at Urbana-Champaign",   "On March 21  Google announced that it will begin a slow roll out of its chatbot dubbed Bard  making the artificial intelligence platform available to a small number of users. The announcement follows last year s release of a similar platform called ChatGPT developed by OpenAI. The advanced chatbots can turn simple text prompts into tweets  poetry  songs  term papers and even books. Some critics have raised concerns that students could use these platforms to plagiarize essays or college applications. Others worry they could put certain professionals out of work. CU Boulder experts are available to discuss what the future holds for these AI platforms and what it might mean for people.  Learn more about ChatGPT and AI large language models (LLMs). AI ethics & higher education Casey Fiesler is an associate professor in the Department of Information Science who studies technology ethics and online communities. She s posted several videos about ChatGPT to her popular TikTok channel and has explored how educators might use AI platforms to help students learn. AI strengths and weaknesses Daniel Acuña is an associate professor in the Department of Computer Science and develops AI tools to mine scientific knowledge from vast  unstructured datasets. He recently discussed the strengths and limitations of ChatGPT in an article for The Conversation.AI in business Kai Larsen is associate professor in the Leeds School of Business and co-author of the book Automated Machine Learning for Business. He used ChatGPT to write a children s book about his pet bird called Dewey the Unhappy Cockatoo and can discuss the future of AI in business  education and more AI and the future of K-12 education Peter Foltz is a research professor in the Institute of Cognitive Science who has decades of experience designing  large language models ––a class of AI tools that includes ChatGPT and Bard. He is executive director of a $20-million National Science Foundation institute  which explores how AI might transform K-12 classrooms around the world. Harry Surden  professor of law  is a former software engineer who focuses on the intersection of law and technology  including artificial intelligence and legal automation. He can explain why ChatGPT s launch has surprised even AI experts and why it s taken Google s Bard so long to catch up. He can also discuss how LLMs can have the potential to change society  from both addressing and contributing to discrimination to improving access to justice. Surden has written extensively on topics ranging from ethics of AI in law to values embedded in legal artificial intelligence."
"University of Maryland  College Park", "Generative AI (GAI) is a subset of artificial intelligence that focuses on producing novel content by learning patterns from training data. Unlike conventional AI used for specific tasks  generative AI employs complex algorithms  especially deep learning models like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs)  to create outputs resembling the training data. The central concept is enabling machines to craft original outputs  such as lifelike images of nonexistent objects or unique music compositions  by learning from extensive datasets to grasp patterns. Once trained  the AI generates new data points that bear similarities to the original but are entirely innovative. This technology finds applications in art  creativity  drug discovery  and generating synthetic data for training other AI models  highlighting its broad potential impact across industries and its rapid evolution in the AI domain. Guidance for Students  Faculty  and Staff General Guidance for Using GAI Considerations in Choosing a Generative Artificial Intelligence (GAI) Tool: Privacy risks: Be cautious as some tools might not guarantee data privacy and could be accessible by external parties. Avoid sharing sensitive information like credit card details or personal identifiers Misleading costs: Some tools might appear free initially but might require a credit card for a trial  making it difficult to cancel the subscription later. Stay vigilant of such tactics Learn to use: Familiarize yourself with tools like ChatGPT using available resources  such as training materials from UMD or comprehensive lists of prompts for different purposes Understand limitations: Recognize the capabilities and constraints of GAI tools  as they are predictive models and not sentient beings. Explore information about their limitations to use them effectively Use reputable resources: Ensure the tools you choose are from reliable companies like OpenAI s ChatGPT and DALL-E 2  Google s Bard  and Microsoft s Bing AI Safe computing: Adhere to guidelines provided by DIT to remain safe on the internet. Considerations for the Ethics of Using GAI GAI is not sentient: These models don t possess self-awareness but are trained on datasets  leading to inherent biases and limitations GAI is biased: Due to training on past data  these models may not account for current social changes and could have implicit biases GAI can mislead: Models might produce information that lacks veracity  relying on verbosity rather than actual evidence GAI prefers English: Language models can be biased towards Standard American English  disadvantaging other dialects and writing style Student Guidance for Using GAI How to Use GAI Responsibly in Academic Settings: Seek guidance from professors on appropriate use in coursework Verify information and citations from GAI and supplement with independent research Remember that GAI tools are only tools and shouldn t replace critical thinking Ask yourself relevant questions regarding your usage of GAI  its impact on your learning  content accuracy  and its equitable use compared to peers. Use these tools ethically to contribute positively to society Staff Guidance for Using GAI As GAI presents transformative possibilities for higher education and beyond  consider the following questions regarding your usage: Is the GAI-based tool aiding my learning and cognitive processes? Is the GAI-based tool enhancing or hindering my job performance? Is the content I generate accurate  verifiable and free from biases that may harm others? How will I handle content generated by GAI-based tools? How can my use of GAI-based tools contribute to the greater good of society Remember the ethical responsibility associated with using GAI-based tools  as they can impact both personal growth and societal well-being."


"University of California Davis",  "There is a great deal of interest in using OpenAI / ChatGPT and other large language models in the academic  research  clinical  and administrative areas of UC Davis. While we share in this enthusiasm  AI solutions are readily available far ahead of usage guidelines. Therefore  until there is more information about AI solutions and their appropriate usage at UC  do not use these technologies with sensitive UC Davis systems and data.More specifically  do not provide any text or other inputs to large language models or generative AI that might contain sensitive data  including identified or de-identified student information  personnel data  personnel conduct information  patient data  confidential financial data  confidential research information  or otherwise sensitive university information. For reference review OpenAI/ChatGPT s usage policies: https://openai.com/policies/usage-policies. More information will be provided to the UC Davis community as it becomes available and  once we have had an opportunity to collaborate with stakeholders including the Academic Senate. Additional information is forthcoming about students use for educational purposes. Meanwhile  if you have any questions about proper use of AI"

"University of California  Santa Cruz",  "Instructor Guidelines for Student Use of Generative Artificial Intelligence for Academic Work The University of Southern California s Academic Senate Committee on Information Services recommends that all USC schools  academic departments  and instructors adopt the following guidelines regarding student use of generative artificial intelligence for academic work. Instructors should encourage USC students to explore generative artificial intelligence (AI)  using these new tools to create  analyze  and evaluate new concepts and ideas that inspire them to generate their own academic work. In advance of this exploration  instructors should help students recognize that some contemporary AI-generated content may be specifically designed to appear plausible and persuasive but is sometimes factually inaccurate. Many of the issues that have surfaced with the introduction of ChatGPT – questions about academic integrity  authorship and citations  student engagement  misinformation and disinformation – are issues higher education and society have encountered in the past in response to the need for digital literacy. We suggest that generative AI is simply the newest addition to USC s digital literacy tools. Ultimately  this committee leaves instructors to set their own course policies regarding student use of generative AI. Whatever any given individual instructor decides should be clearly communicated to students in course materials. However  the committee recommends that instructors remind students that the acquisition of academic work in whole or in part from any source (from textbooks and journal articles to web resources to generative AI) and the subsequent presentation of those materials as the student s own work (whether that material is paraphrased or copied in verbatim or near-verbatim form) constitutes an academic integrity violation unless otherwise allowed by the instructor. Individual assignments and exams may have additional  specific requirements related to original work which should be clearly defined by the instructor. Because generative AI is a constantly evolving space  the committee encourages USC s instructors to begin to learn more about generative AI so they can better adjust their pedagogy and evolve as educators. The Current State of Student Use of Generative AI for Academic Work (MidFebruary 2023) Limitations of Guidelines Our focus in this document is narrow: to highlight the steps that USC s instructors need to take today to identify and to state their expectations with respect to student use of generative AI for academic work. In the weeks and months to come  we expect that USC s academic community will be asked to participate in broader conversations about generative AI and its place in academe and society. What is ChatGPT and what can it do? It is hard to overstate how much attention ChatGPT  a free online artificial (AI) chatbot that generates text in response to prompts  has received since its launch on November 30. One reason it has become so popular so quickly  surpassing 100 million monthly active users to become the fastestgrowing consumer internet application in history  is the ease and speed with which it can generate text on demand. Ask ChatGPT to  write a five-paragraph essay on the impact John Stuart Mill s recantation of the wages fund doctrine had on classical economics  or  explain what it means when people say   knowledge is knowing that Frankenstein is not the monster but wisdom is knowing that Frankenstein is the monster   or  write a sonnet about Clay Helton  and it creates plausible  human-like text responses in a matter of seconds. Scholars  researchers  and educators have demonstrated that  given the right prompts  ChatGPT can • Pass the final exam of an MBA-level Operations Management class at Wharton • (Barely) pass questions on a law school exam at the University of Minnesota • Pass all three exams that comprise the United States Medical Licensing Examination • Pass Google s coding exams and interviews at the level of an entry-level software engineer with no prior industry experience. Are students already using ChatGPT for academic work? Yes. Students are starting to use ChatGPT for their academic work. In a late-2022 nationwide survey of 1 000 students currently enrolled in US colleges and universities  nearly one-third of the students said they have already used ChatGPT to complete a written college assignment and nearly two-thirds of that group say that they have used it for 50% or more of their assignments. We expect both percentages to be even higher today. Are there other generative AI text tools like ChatGPT? Yes. ChatGPT is just the first in a wave of generative AI tools that will soon become ubiquitous. Generative AI is algorithms and tools that can be used to create new content  including audio  code  images  text  simulations  and videos. Recent new breakthroughs in the field have the potential to drastically change the way we approach content creation. (McKinsey & Company) Most of these new tools rely on  large language models  AI systems that use advanced statistical techniques to analyze and understand natural language data  such as text or speech  and generate human-like responses. Microsoft  already a major investor in OpenAI (makers of ChatGPT)  launched a new AIpowered Bing search engine and Edge browser in early February 2023 and intends to incorporate AI-content generation into Microsoft Office programs like Outlook  Word  and PowerPoint. Later in 2023  Microsoft will release technology that will allow companies  schools  and governments to create their own custom ChatGPT-powered AI text generators. Google is expected to launch its own ChatGPT competitor named Bard in early 2023. In the summer of 2022  Meta (formerly Facebook) released its Open Pretrained Transformer (OPT) large language model to developers and researchers. And that is just the beginning (see https://www.futuretools.io/ for a list of hundreds of new AI tools that be used to generate text  images  audio  and more). Considering this  we suggest that rather than focusing solely on ChatGPT  instructors should instead focus on what role they would like all generative AI tools to play in their classes and in their students  work going forward. How might instructors approach student use of generative AI? We suggest that there are two ways instructors can approach student use of generative AI: 1. Embrace and Enhance 2. Discourage and Detect Embrace and Enhance The good news is that many of the proven teaching and assessment techniques that worked in a pre-generative AI world still work in a world where any student with a cell phone and a generative AI account can create walls of academic(-sounding) text. USC s Center for Excellence in Teaching (CET) recently published a guide titled  Using AI text  image  and music-generating tools in your courses  that includes helpful ideas for incorporating AI-generators and AI-generated content in your course  including evaluating and critiquing AIgenerated content (including interrogating the content for biases) and asking students to create rebuttals. Like our recommendation that students should use generative AI to create  analyze  and evaluate new concepts and ideas that inspire them to generate their own academic work  CET recommends having your students use AI generators to brainstorm ideas  formulate and iterate question prompts  and refine responses  adding that you should Frame using AI tools as something to build upon. Remind students of the best way to use these tools in their discipline  such as for idea generation  essentializing  brainstorming  or gathering information about the typical understanding of a topic. All uses of AI tools should be supplemented with appropriate evidentiary support and reflection. Some students may lack the foundational knowledge to understand why or how AI-generated content is inaccurate. This presents an excellent teaching opportunity for you to demonstrate for your students generative AI s strengths and weaknesses. CET also offers several suggestions on designing assignments and assessments in the age of AI generators  including • Asking more nuanced questions  beyond simple definitions and common comparisons  related to the course text  articles  media  or activities that may be unknown to or beyond the capabilities of current AI generators  • Having students complete assignments and assessments during class time  • Requiring students to submit drafts of their papers or projects before they submit their finished work  and • Augmenting written papers with additional oral presentations  concept maps  group work  or case studies so that students can further demonstrate their understanding of the course objectives. If you are going to allow your students to use generative AI as a source in their academic work  you may want to consider requiring your students to clearly disclose the role generative AI played in formulating their work. OpenAI also has recommended language that you may want to adapt and adopt: The author generated this text in part with GPT-3  OpenAI s large-scale languagegeneration model. Upon generating draft language  the author reviewed  edited  and revised the language to their own liking and takes ultimate responsibility for the content of this publication. Discourage and Detect Some educators have asked how they can block student use of ChatGPT (see New York City Department of Education and others). We suggest that that would be akin to standing on the shore hoping to block a rising tide. Generative AI is here and is not going away. That said  if you wish to discourage student use of generative AI  let your students know this expectation both in your syllabus and in class."

"University of Arizona" ,   "The following guidance aims to help instructors thinking about the impact of generative artificial intelligence (AI) tools on teaching and learning. Specifically these guidelines suggest instructors: include a syllabus statement regarding use of AI tools; create transparent and productive learning environments by explicitly discussing appropriate  creative  and/or ethical AI use within a course  discipline  and/or profession; and prevent situations in which a student unintentionally engages in academic dishonesty while using AI tools. The University of Arizona Catalog includes a list of required syllabus policies  including The Code of Academic Integrity. The phrase  graded work/exercises must be the product of independent effort unless otherwise instructed  can be interpreted differently. Therefore  instructors should also include a statement specifically addressing course policy on the use of generative AI and discuss this policy with students. If applicable the syllabus should include information about the use of AI detection applications  because these involve sharing student-created work. Example syllabus statements are provided below. Students will potentially face different policies in different courses/assignments in regard to the use of generative AI. Also  there are many different ways students might interact with generative AI in their learning processes. Clarification about expectations is necessary. This is similar to the potentially different meanings of the phrase  open book exam.  Does  open book exam  include using the textbook and notes? Recorded lectures? The internet? Talking with classmates  friends  and family? It is extremely important to be direct and specific about course policies concerning AI. Starting with the syllabus  engage with students as partners in learning about types of AI as related to the course  discipline  and profession; and discussing issues of academic integrity II. Things to Consider About AI  Teaching  and Learning Generative AI tools based on large language models (LLMs) simultaneously present exciting opportunities and worrisome challenges. Prior to developing course policies about generative AI  consider the following issues. 2 Learning Goals for Students: Generative AI tools can augment learning and may be a technology that students will use in the future  but their use may not be relevant or appropriate in all situations. Evaluate how using AI or learning about AI fits with a course s goals and objectives. Consider whether or not the use of generative AI: aligns with the learning outcomes and objectives of the course; provides multiple means of engagement  representation  action or expression of learning; ameliorates differences in students language or preparatory experiences; facilitates process  practice  or develops durable critical thinking skills; prepares students for future employment and equips them with digital and information literacies; and/or makes the learning experience more interactive  personalized  or stimulating. Academic Integrity: The University of Arizona Code of Academic Integrity prohibits  all forms of academic dishonesty  including...cheating  fabrication  facilitating academic dishonesty  and plagiarism.  Definitions of  cheating  vary. Therefore  students need guidelines and explanations from you about what counts as  cheating  or  plagiarism  within the context of a specific course or assignment. Students may not be aware that AI policies can and will vary between courses  sections  instructors  and departments  so take time to support them in understanding and abiding by different policies. When introducing assignments  clearly articulate the expectations and/or boundaries of when  where  and how generative AI might be used—and  if used  how it will be documented. (See guidance on citation/acknowledgment in section III below.) In considering academic integrity in your course  also think about ways to foster honest behavior and if you can prevent or detect cheating. Note that AI-detecting tools are not reliably accurate. The University Center for Assessment  Teaching  and Technology can help you to review and re-think course assessment plans and assignments  and strategize how to promote and protect academic integrity. Accessibility  Equity  Risks  and Ethics: Specific students are likely to be more familiar with generative AI tools. According to a May 2023 Pew Research Study  Americans with higher household incomes and formal education were more likely to know about ChatGPT  and White adults who have heard of ChatGPT are consistently less likely than their Asian  Hispanic or Black counterparts to have used the chatbot for fun  work or education. Some people see this technology as a way to mend inequities. At the moment many generative AI tools are free  but more powerful versions of these tools are starting to charge a subscription fee. There are risks and practical precautions to keep in mind and discuss with your students: The companies that own these tools collect information  so you and your students should not enter confidential information. Review the privacy policies of any tool you use or suggest as class material. Large language models are trained on information from the internet  so their output contains misconceptions  biases  violence  racism  sexism  etc. that exist in that data. The use of intellectual property by large language models is debated; lawsuits about infringement on intellectual property rights are pending. Generative AI makes up (hallucinates) information that is non-existent but sounds plausible. Generative AI can be steered by the bias of human-written prompts  too. Generative AI tools are not search engines; the output needs to be checked. Not all generative AI tools meet the requirements for accessibility as defined by the Americans with Disabilities Act. AI companies have been criticized for unfair labor practices. AI-augmented Teaching: Generative AI can be used to design a course  create lesson plans  write multiple-choice questions  prepare a slide presentation or other course materials  and assist with responding to student work. Consider how you will acknowledge your use of generative AI tools. 3 Instructor Workload: Whatever your policy decision is  workload may increase. This includes  but is not limited to  creating a thoughtful syllabus policy; adjusting or adapting instruction  coursework  and assessments  and addressing students questions about allowable AI use. It may be more time-consuming to disallow the use of generative AI in courses  especially large sections. AI-detection tools are not reliable and the necessary evaluation by a human reader takes time. So  too  do discussions with students and documentation of violations. Consult with the University Center for Assessment  Teaching  and Technology if you would like to talk about your particular courses or learn more about generative AI  teaching  and learning." 


"Michigan State University",   "Developed in collaboration with campus stakeholders  we are pleased to share new university guidance on the use of generative artificial intelligence (AI). As technology continues to advance  it is essential for our community to stay aligned with emerging tools and technologies while simultaneously ensuring responsible and ethical practices.Generative AI  a branch of artificial intelligence that enables machines to create original content  poses both incredible opportunities and challenges. As we encourage the innovative use of new technology across various disciplines  it is equally vital to address potential risks and concerns. The purpose of this guidance is to provide a foundation for leveraging AI responsibly and ethically across all MSU environments  with the understanding that it will be updated as we learn more about both its applications and implications While all MSU community members must adhere to the MSU s established acceptable use and institutional data policies  specific types of data should be handled in different ways when using a generative AI product. Public data Generative AI can safely process publicly available information  general academic concepts  and non-sensitive data. Use of public data must still comply with MSU s policies and be considered relative to its ethical and reputational implications. Confidential or private data Do not enter confidential data  including  but not limited to  social security numbers  contact details  name/image/likeness  and any information covered by FERPA  HIPAA  or other regulations into any generative AI product. Research data Researchers must consider the nature and sensitivity of scholarly data before using generative AI to support research. Do not put data that are confidential  contain sensitive information  or are subject to specific legal or ethical requirements (e.g.  human subjects data) into any generative AI without proper anonymization and evaluation of potential risks  as well as express written consent from any other necessary parties. Intellectual property As questions around intellectual property and the use of generative AI are unresolved  the MSU community must avoid inputting proprietary or confidential information into generative AI  including unpublished research findings  internal university data or documents  or any information protected by intellectual property rights without express written consent from all stakeholders. While utilizing such technology  we must also consider issues surrounding misinformation and inaccuracies  bias and unintentional harm  inappropriate content  and algorithmic implications. More on these topics can be found in the guidelines. As a diverse institution of learning  it is our duty to foster an environment where cutting-edge technologies can be explored and harnessed to advance our uncommon will  resulting in better service to our communities. In partnership with campus partners who provided feedback on this project  we believe that adhering to these guidelines will not only preserve academic integrity but also contribute to the responsible advancement of AI applications. Together  we can shape a future that embraces the transformative power of technology while upholding our commitment to ethics and academic excellence."
"University of Florida",  "ChatGPT is a generative artificial intelligence (Gen AI) that uses a conversational natural language processing (NLP) model created by OpenAI. ChatGPT has made a large impression in many fields because of its ease-of-use and ability to write about seemingly any topic. ChatGPT s language model was trained using billions of words and phrases collected from the internet  and it can generate responses in a conversational  thread  and take previous prompts or instructions into account. ChatGPT can be accessed with a free account on OpenAI s website. Paid accounts are able to access more sophisticated Large Language Models (LLMs) like GPT-4 and connect with outside tools and resources using plugins.CONSIDERATIONS Before using ChatGPT  you should review the privacy and security guidelines on the Fast Path entry on the UFIT Integrated Risk Management website. Any data that falls under the Sensitive or Restricted data types should not be used with ChatGPT. This includes education records  unpublished research  personally identifiable information  and many other examples of data that would be inappropriate to disclose to the public. The CITT has advice on adapting assessments in light of ChatGPT and other generative AI tools on the Generative AI and Teaching page. We also offer consultations and webinars on AI and other tools impacting teaching and learning through our Tech Byte series. To discuss how your course or assignments can be designed with ChatGPT or other generative AI tools in mind  please request assistance with educational technology and tools from the CITT! Our technologists and instructional designers can provide advice on modifying assessments and explain in more detail how ChatGPT could affect your specific course."
"Howard University",   "Generative artificial intelligence (AI) technology is rapidly becoming an ubiquitous component of our daily existence. The Office of the Provost has developed an Initial Set of Guidelines for Use of Generative AI Tools to provide recommendations for engaging AI tools within academic settings by faculty  students  and other University stakeholders. Our Generative AI webpage offers a spectrum of information and resources on best practices related to the utilization of AI. We encourage you to review the guidelines. AI technology is evolving steadily  and we will continue to provide significant updates as appropriate."
"University of Michigan",  "University of Michigan s GenAI offerings With the rise of numerous GenAI-based tools  it is important to know how to choose a tool that works best for you. Tools provided by the University of Michigan  such as U-M GPT are private  secure  and free for students. Data you share while using these tools will not be used for training these models  and hence are not at risk of being leaked. Look for the umich.edu domain in the page link to verify that you are using a U-M website Choosing a GenAI tool to use The GenAI space is rapidly growing and expanding  with new tools and capabilities being revealed every few days. Hence  understanding what to look for in these tools is key. When considering tools outside of what the University offers  be aware of the following when choosing a tool for your needs: Privacy risks: Understand that in most cases  the data you share is not private and will be accessible by external parties hosting the GenAI-based tools. Do not share information that is considered private  or sensitive  such as credit card information  personal details such as ID numbers or addresses  and so on. Misleading costs: Be aware that some tools will be  free-to-start  or provide a more premium option with better functionality. Be wary of tools that require a credit card to sign up for it to start a free trial  as they may employ tactics that make it harder to then cancel the subscription. Learn to use: Educate yourself on the ways to use these tools like ChatGPT better  through resources such as: GenAI Training Resources from U-M 650+ Best Prompts for ChatGPT (Ultimate List for 2023) The 100 Best ChatGPT Prompts to Power Your Workflow Understand limitations: Understand what GenAI-based tools can or cannot do. GenAI might appear to have the ability like a conscious being in a conversation or application  but they are simply very large predictive models that infer from a massive dataset. Learn about what these models are limited at doing as well: 13 ChatGPT Limitations That You Need To Know | Amber What Are the Limitations of ChatGPT? Risks and Limitations of ChatGPT | Codecademy Use reputable resources: Should you use tools that are outside of U-M s offerings  ensure that are legitimate resources. Current companies in the space have a variety of products such as: OpenAI s ChatGPT and DALL-E 3 Google s Bard and  Microsoft s Bing AI and Microsoft 365 Copilot Amazon s Bedrock and CodeWhisperer And as a good rule of thumb  always know the safe computing practices. Safe Computing is a U-M resource for more information about protecting yourself and your data online Considering the ethics of using GenAI Following are some things to consider as you use GenAI-based tools  and how it may affect your usage of them in your day-to-day life: GenAI is not sentient: GenAI models or Large Language models (LLMs) might appear to possess sentience or self-awareness as a human would  but are simply systems trained on large and biased datasets. LLMs are designed to output the most likely  or most common results possible based on their data  and will invariably tend to suppress less common or marginalized information. GenAI is biased: GenAI models carry implicit biases in them that make them unsuitable for use in cases of ethical deliberation and decision  and should not be used in those circumstances. Furthermore  this data is from the past  which results in a loss of context for current social changes. GenAI can mislead: GenAI in its current stage will tend to  hallucinate or make up random data that is not true. Models have no real sense of what is true or false. These models are built to output what is most likely in a verbose manner  even if there might not be enough real information to back it up. GenAI prefers English: LLM models are currently heavily biased toward Standard American English. This means that writing styles and dialects adopted by other cultures and ethnic groups such in cases of African American or Indigenous English are at risk of being penalized for a privileged White-dominated form of writing instead. With that in mind  here are some basic guidelines that can help you in how you use GenAI in academic use: Use U-M s offerings that ensure your data privacy and security. Talk to your professor about how and where GenAI-based tools can be used in your course. Seek clarity on issues of syllabus wording  citation  and methods of use. Do not cite information from GenAI as the truth for the information it presents. Always check the citations that it provides  and research them yourself. You can also reach out to the Librarian for assistance in your research. GenAI-based tools are just that  tools that you wield. Your prompts can determine the quality of information that you get and should assist you in your academic growth. They do not and should not replace your ability for critical thinking and problem-solving as an individual If you have concerns about how GenAI is being used or limited in a course  or have disputes with the course instructor over the usage of these tools  we recommend first contacting your school or college  as they may be able to assist you in accessing training material specifically curated for your area"

"The University of Alabama" , "Guidelines for Faculty in Dealing with the Use of Generative AI Tools Generative Artificial Intelligence (Generative AI) is a computer-based technology that creates a variety of data  such as pictures  videos  music  or words  which look or sound like they were created by a person. It has been predicted that in the future  there will be a greater number of AI systems designed to facilitate creative cooperation between humans and AI. At the University of Alabama  faculty have expressed interests in exploring and applying generative AI tools (such as ChatGPT  DALL.E  Midjourney  Stable Diffusion  and Codex) to collaborative teaching and learning. This document aims at providing UA faculty with understanding the limitations of these tools  offering guidelines to faculty on using these tools in the classroom as they continue to evolve. What are ChatGPT and other GPT-based software and tools? ChatGPT is a large language model (LLM) based chatbot that was made available to the public on November 30  2022. GPT is an abbreviation of Generative Pretrained Transformer  derived from a specific architecture of neural networks for natural language processing. It has been gaining a lot of attention and is evolving rapidly. It has already been integrated into Microsoft Office apps and other software. This type of generative AI analyzes language structure by mimicking how humans comprehend text and then uses this knowledge to automatically create text and other content. The abilities of the generative AI have been expanded from text to images  videos  computer codes  and other data formats  such as DALL.E  Midjourney  Stable Diffusion  and Codex. The functions of GPT-based software and tools are continuously evolving and spanning from text  vision  music  coding  and mathematics. The recent trends have demonstrated interactions with the world  humans  and other internet AI modules and systems  such as AutoGPT and AgentGPT.Next-word-prediction paradigm. The model operates on a next-word-prediction paradigm  which means it only generates the next word  and currently  it has no mechanism to revise or modify its previous output. Some of these limitations could be solved by providing specific prompts  which are called  prompt engineering.  However  the inherent flaw is not solved yet. It generates errors without warning. Erroneous references  content  and statements may be intertwined with correct information and presented in a persuasive and confident manner  making their identification difficult without close inspection and effortful factchecking. Therefore  it still requires extensive efforts to search and fact-check the generated content. You cannot rely on ChatGPT-generated content for research  learning  and education. Bias. All users need to be aware of the inherent bias of these generative AI tools since the GPT models are trained on data from the public internet. Among these data sources  they are riddled with various sources of inherent bias. LLMs may perpetuate or amplify existing bias Experiment and learn these AI tools - Faculty may experiment with generative AI tools in conjunction with their course materials and assignments. To begin  you can create a free account on Open AI s platform with ChatGPT. Once registered  you can input some of your assignment prompts and evaluate the accuracy of the results. Subsequently  you should consider how you can integrate the tool or develop alternative approaches that do not require it. Additionally  involving students in the reflection process can provide a valuable learning experience  enabling them to comprehend the advantages and limitations of these tools. Explain these AI tools explicitly in your class - Talk with students about these generative AI tools explicitly. Invite them to collaboratively consider and establish learning goals and criteria for the task  with consideration for the role of AI software. It would help students to evaluate and judge appropriate contexts in which AI can work as a learning tool. This communication will further seize the opportunity to center the importance of critical thinking and digital literacy among students. - Discuss academic integrity with students. You should clarify the principles and guidelines for using generative AI tools in your courses. In addition to verbal explanations  we recommend a syllabus statement on using AI. - Discuss the ethical issues and limitations of AI with your students. As you experiment with the course materials and assignments using generative AI tools  you may engage in conversations with your students about the effects of inaccurate or biased information generated by these tools  particularly as it pertains to the course materials. Despite the likelihood that students will continue to utilize ChatGPT and similar tools  it is essential that our community shares a common understanding of the associated risks and benefits. Change your assignments so that they may not be easily completed using AI - Create assignments that are not easily completed using AI. It is highly recommended that you provide clear instructions to students regarding the proper citation of generative AI tools in their assignments and requiring them to provide references for all submissions. Students should be required to explain how they utilized these tools in their work. To enhance students  oral communication skills  you may provide more opportunities for in-class presentations or incorporating them into discussion sections. Move to more authentic assessments and include performance elements - You may incorporate a formative assessment practice where students are required to submit drafts of their work for review and feedback. These reviews and feedback could be considered as grading subcomponents of the assignments or tasks. This approach not only helps to detect plagiarism but also guides students in the development of their work  enabling them to improve their performance. Teachers  peers  or self-assessments can provide feedback  which can facilitate the critical evaluation of work in progress. Encouraging peer- and self-feedback can enhance the authenticity of the assessment process."


"University of Tübingen",  "Talk is everywhere about ChatGPT and other generative AI (GenAI) tools. The University of Tübingen believes it is its duty to address this debate so as to help shape developments and produce guidelines. To this end  the President s Office has set up the Generative AI work group  consisting of members from every faculty  central administration and relevant institutions. The role of the work group will be to advise the President s Office on the use of GenAI at the University of Tübingen. Its members take a critical yet optimistic attitude to the potential of GenAI. Together  the President s Office and the work group have discussed principles  which will continue to be developed. Their aim is to achieve the critical  reflexive  transparent and responsible use of GenAI. The current status of the discussion is given below.As a forward-looking and progressive university  the University of Tübingen recognizes the transformative potential of GenAI. This potential currently encompasses many areas of society and is changing both university and non-university work environments. GenAI is already becoming incorporated in various professions at rapid speed. There will no longer be a world without AI. In future  many University of Tübingen students will work in professions where the use of GenAI will be an everyday part of work processes. Likewise  GenAI will increasingly change the day-to-day work of researchers in various disciplines  as well as that of administrative staff. The University of Tübingen sees this as a major challenge  but also a substantial opportunity. After all  the University can be the place where critical  reflexive  transparent and responsible ways of working with GenAI are negotiated  developed  and transmitted. For instance  it contributes to shaping social change in the context of AI in a way that is both sensitive to problems and at the same time constructive.The potential for GenAI in the field of text and data processing is extremely diverse. For the University of Tübingen it extends over every relevant area: GenAI has the potential to change how students learn and operate in a data-saturated scientific world. It can enable new didactic approaches in digital teaching  open up new ways for researchers to work with texts or images  contribute to the expansion of science communication and last but not least provide support at an administrative level. The variety of possibilities makes it especially difficult to determine potential  or to develop rules on how to proceed. What is clear is that – whether in studies  teaching  research or science communication – the potential of GenAI varies  and sweeping assessments have little to offer. At present the University is in an exploratory phase  where it has to investigate  test and discuss critically the potential in all of these fields. Given the speed of technical development and the technological hype  we need to evaluate the potential of GenAI realistically  in order to define a framework in which it can be used by a forward-looking university.Besides its wide potential  GenAI also has many problematic implications. These include the fact that there are still many unresolved copyright and data protection issues. Generated texts can produce erroneous  ambiguous or misleading results and  hallucinate sources. GenAI can reproduce any bias recorded in the system s training data. Social  cultural and scientific prejudices can be incorporated in the system and the generated texts. Developers can sometimes deliberately manipulate the generated texts. In addition  extensive use of GenAI has a substantial ecological footprint  in particular through electricity consumption  CO2 emissions  consumption of minerals and water. Furthermore  different payment models for stronger and weaker AI systems can further increase economic inequalities (e.g. between students with different incomes).Therefore  a key objective of the University of Tübingen is to test the potential of GenAI and apply it productively in various areas of the University  while bearing in mind these problematic implications. This includes developing both basic and subject-specific study programs as well as the legal framework  e.g. for application in examinations. The University will also benefit from a critical discourse on the potential and the limits of GenAI in relation to research  science communication and administration. Achieving these objectives will demand a lot of work and attention. However  it is already clear that key guiding principles will be indispensable. Firstly  members of the University must tackle GenAI in a critical and reflexive way. Many of the problems with GenAI (including at a social level) arise from a naive attitude. A critical and reflexive attitude demands not only the development of a sophisticated awareness of the problems  but also the ability to realistically assess the potential and limitations of GenAI.  Secondly  use of GenAI should be organized transparently. If GenAI is used (whether for research  studies  administration or science communication)  the procedure must be documented and made visible/transparent in the relevant format. Thirdly  all members of the University are exhorted to use GenAI responsibly in line with good scientific practice. Among other things this means that when working with GenAI it is the individual responsibility of the authors to ensure that their texts do not contain any plagiarism and all sources are critically examined. It also means that each user must assume responsibility for how and to what end the data provided by AI systems are processed. The way in which these principles are applied must by their nature be applied differently depending on the field of work and culture of the discipline. Departments and institutions are called on to formulate and provide their own guidelines. The Generative AI work group and the President s Office are currently working on basic solutions in order to respond to urgent procedural questions concerning examinations. These will form the basis for future development in the faculties and institutions. If we can provide the fundamental conditions for critical  reflexive  transparent and responsible use  GenAI can offer potential to enhance work processes both within the University and beyond. What precisely these enhancements will consist of and how a critical process of evaluation can assess them with regard to their problematic implications will be the subject of ongoing discussion at the University of Tübingen in coming years."

"Tufts University",  "We are providing initial guidelines on the use and procurement of generative artificial intelligence (AI) tools—such as OpenAI s ChatGPT and Google Bard—that can generate content in response to prompts. We support responsible experimentation with generative AI tools  but there are important considerations to keep in mind when using these tools  including information security and data privacy  compliance  copyright  and academic integrity. Generative AI is a rapidly evolving technology  and we will watch developments and incorporate feedback from the community to adjust our approach as needed. Initial guidelines for use of generative AI tools AI use is subject to existing Policies and Procedures: using AI does not allow an exception to existing requirements and limitations. Protect confidential data You should not enter data at Levels 2-3 (Pretty much anything that should not be on a public webpage) into unapproved generative AI tools. The approval procedure is described here.  Information shared with generative AI tools using default settings is not private and could expose proprietary or sensitive information to unauthorized parties. You are responsible for any content that you produce or publish that includes AI-generated material AI-generated content can be false  misleading  or worse—AI sometimes makes up events and facts. In addition  AI can infringe Intellectual Property rights  and your use of the results can be considered infringement—subjecting you to lawsuits and damages. On the other side of the Intellectual Property coin  AI results are not well-protected by Intellectual Property laws. All of these risks require you to read and understand the terms that come along with the AI you are using. There is almost never  no contract.  There may be no charge  but Intellectual Property law requires an End User License Agreement  and most producers will have Terms of Use. These are usually very favorable to producer and very unfavorable to you and Tufts. That said  somebody needs to read them  comprehend the risk  and make a responsible decision to accept it. If you are using this AI for a Tufts matter  you should be reaching out to TTS for a technology review (see No. 5 below) Adhere to current policies on academic integrity Review your School s student and faculty handbooks and policies. For example  misuse of ChatGPT already violates our Policies Regarding Student Behavior.  We expect that Schools will be developing and updating their policies as we better understand the implications of using generative AI tools. In the meantime  faculty should be clear with students they re teaching and advising about their policies on permitted uses and required disclosures  if any  of generative AI in classes and on academic work. Students are also encouraged to ask their instructors for clarification about these policies as needed. Connect with TTS before procuring generative AI tools The University is working to ensure that tools procured on behalf of Tufts have the appropriate privacy and security protections and provide the best use of Tufts funds.If you have procured or are considering procuring generative AI tools or have questions  please contact TTS using these instructions.  Vendor generative AI tools must be approved by TTS as described here. It is important to note that these guidelines are not new University policy; rather  they leverage existing University policies."


"University of Wisconsin–Madison" , "This page outlines existing policies governing what you may and may not do when using generative artificial intelligence (AI) tools and services. These policies safeguard institutional data  which everyone in the university is legally and ethically obligated to protect. All university faculty  staff  students and affiliates must follow these policies. You may only enter publicly available information (classified as low risk) when you use generative AI tools and services. You may not enter internal  sensitive or restricted data into any generative AI tool or service. Entering data into a generative AI tool or service is like posting that data on a public website. AI tools collect and store data from users as part of their learning process. Any data you enter into an AI tool becomes part of its training data  which it may then share with other users outside the university. UW–‍Madison does not have enterprise contracts or agreements with any generative AI tool or service provider. No AI tool meets the university s security  privacy and compliance standards for handling anything besides public data. As with everything you do at the university  you must follow UW–‍Madison  UW System Administration (UWSA) and UW System Board of Regents policies when using generative AI tools and services. Read on for more about those policies and tips for using AI safely."

"Boise State University",  "Boise State University has a number of policies that safeguard institutional data  which  university faculty  staff  students  and affiliates must follow. Those using generative AI in their work should consider what data they are using and whether or not such data usage is prohibited by university policy or otherwise generally cautioned against. Entering data into a generative AI tool or service is like posting that data on a public website. AI tools collect and store data from users as part of their learning process. Any data you enter into an AI tool becomes part of its training data  which it may then share with other users outside the university. Boise State University does not have enterprise contracts or agreements with any generative AI tool or service provider. No AI tool meets the university s security  privacy  and compliance standards for handling anything besides public data. Therefore  you may not enter internal  sensitive  or restricted data into any generative AI tool or service. Only publicly available information classified as level three data (data that has no legal or other requirement for confidentiality  integrity  or availability under the Freedom of Information Act) may be used in generative AI tools and services. Questions about university data standards and security should be directed to the Chief Information Security Officer at CISO@boisestate.edu or (208) 426-5701. As with everything you do at the university  you must follow Idaho State Board of Education and University policies when using generative AI tools and services."
"Boston University",   "We re looking for responsible ways of setting boundaries around this   says Mark Crovella  a professor of computer science and of computing and data sciences at CAS and chair of the CDS Academic Policy Committee.  Communicating to students how they re expected to behave in a world in which it s possible for us to use these remarkable machine learning tools to do things that look a lot like intellectual work.  If students use generative AI to do their work for them   they re short-circuiting the educational process   Crovella says.  But  at the same time  the world is never going to  go back to pre-ChatGPT  and we have to understand how to productively coexist with these kinds of tools.  The policy also provides guidelines for faculty in grading  saying they should treat work submitted by students who don t use LLMs as the baseline for grading  and use a lower baseline for students who do use them  depending on how extensive the usage. Faculty should also use AI-generated text detection tools to evaluate the degree to which it is present in student work  the policy says. And faculty should impose a significant penalty for low-energy or unreflective reuse of wording generated by LLMs  to the point of assigning zero points for merely reproducing LLM output. The policy s final language is quite close to the original text the students hashed out after a few weeks of class discussions and small-group efforts. It was discussed by the Academic Policy Committee  as well as in many informal conversations  before Bestavros polled the faculty this week.  I would call it the baseline policy   Bestavros says   because different faculty may want to tweak it further  depending on what the courses are about  and to what extent it is a tool versus something that you want to avoid.  Crovella says it s  pretty cool  that the students came up with such a workable policy so soon. Wildman says the students are proud of their work—as is he. He s waiting for students to start asking how to put a project like this in their CVs or refer to it when they re applying for fellowships or positions. Wildman will also speak on a panel discussion at Monday s CDS symposium for BU faculty  staff  graduate students  and postdoctoral scholars: ChatGPT and Other AI Tools: Challenges  Opportunities  and Strategies for Teaching.  There s a tremendous amount of confusion both among students and among their teachers  so something needs to be done fast   Wildman says.  CDS responsiveness was partly due to the fact that it is small and new and agile  and also because it wants to be a leader helping the University think through these things. Text generation is of course just the beginning for generative AI  which is already roiling fields such as visual art and music. The consensus seems to be that we ve barely begun to see its ramifications."

"Temple University",  "Generative AI (such as ChatGPT  Bard  Bing  Dall-E  etc.) is a type of artificial intelligence that has the capability to create surprisingly coherent text and images. They are large language models that can write and converse with users by drawing on an enormous corpus of text from a variety of sources—including books  web texts  Wikipedia  articles  internet forums  and more—on which they have been trained. These models are growing progressively larger: for instance  GPT-4  the most recent iteration of GPT-3  has 170 trillion parameters compared to its predecessor s 175 billion. Generative AI does not have cognition; that is  it can t think. Instead  in a similar manner to the autocomplete function that works in other applications you use every day  it works by finding and replicating the most common patterns in speech available in its dataset. Note  however  that AI technology is constantly evolving and improving  and we cannot be sure what its future capabilities will be. For an expanded explanation of how these technologies work  visit this article  A curious person s guide to artificial intelligence.  Generative AI tools have the potential to revolutionize the way we interact with technology  opening new doors to faster  more efficient  and more creative learning processes.  But that accelerated pace can run away with us unless we are aware of the downsides of these tools.Generative AI tools have the potential to widen the institutional performance gaps that impact learning in higher education  but also the potential to create a more equitable learning environment. Generative AI is prone to error and can perpetuate biases and stereotypes. Bias may also arise in faculty assessments of which students are making unauthorized use of AI. Students may over-rely on the tools and neglect to develop skills critical to success in higher education and beyond. Inequitable access to broadband internet and to previous education that promoted skills in prompt writing and related skills may exacerbate existing institutional performance gaps. However  generative AI can be thought of as an assistive technology that will support the learning of many of our students. Tools such as ChatGPT can provide useful suggestions for succeeding in college or getting started on assignments  offer immediate feedback on writing and help students develop communication and planning skills. As the efficacy and availability of generative AI tools advances  both we and our students will face a variety of information-related challenges. Generative AI can be used to automate the generation of online misinformation and propaganda  flooding our information environment with disinformation  distracting from accurate information and increasing skepticism in content generated by credible scholarly and journalistic sources. Source material used for training data  the design of a model s algorithm  data labeling processes  product design decisions and policy decisions all contribute to the possible replication of biases and unfair stereotypes (Ferrara  2). Content generated by AI tools can seem accurate but be entirely made up  a phenomenon known as AI hallucinations. Our task as educators is to prepare our students to navigate an information environment characterized by the use of generative AI by inoculating against disinformation  helping them develop the skill and habit of verifying information  and building a conception of the components of a healthy information environment. Instructors will have to make the decision as to whether  and to what extent students will be permitted to use generative AI tools to support their learning. To help you make the decision in your classes  review our  Should I Allow My Students to Use Generative AI Tools?  decision tree. One approach to addressing generative AI in your classes is to encourage students to use the tools to meet course learning goals  for example  by having students experiment with prompt writing or using text generation tools as part of their writing process. AI stands to have a significant impact on how we live and work in coming years. One approach to addressing the existence of generative AI in our classes is to design assignments and activities that take AI as an object of critical inquiry. If your goal is to disallow or discourage students from using generative AI tools  it will be necessary to design assessments and class activities that are either difficult to complete with the use of AI tools or that are completed in a context in which it is difficult to make use of these tools.Whatever approach we decide to take in our classes with respect to the use and study of generative AI tools  it will be critical to talk to our students about AI and learning. It is important that we re transparent with students about the choices we ve made and that we speak with rather than at our students about the impact of AI on their learning and lives. Once you have decided what authorized and appropriate use of AI tools in your classroom will look like  be sure to clearly indicate your expectations in your syllabus. The CAT has drafted syllabus language to get you started. Faculty may disallow the use of generative AI tools  or allow their use but in a limited way. How  then  are we to identify when students are using AI inappropriately? Many companies claim to have created tools that can consistently and accurately identify text or images generated or modified by AI tools  but there is  as of yet  no tool that can fully accurately differentiate AI generated from human generated content. If we choose to use an AI detection tool  we must do so with extreme caution. Temple currently recommends the use of no tool other than Turnitin s AI detector. However  even Turnitin's tool raises concerns. Fore on this issue  see Evaluating the Effectiveness of Turnitin s AI Writing There may be instances where you strongly suspect a student has inappropriately used generative AI to complete work for your course. In such cases: Don t take it personally! Cheating can often feel like a personal attack and a betrayal of all the work you ve put into your teaching. Remember that a student s decision to use AI to take shortcuts is probably about them  not about you.  Check your biases. Is your suspicion of your student s work well-founded? Would you have the same concerns if the work had been handed in by other students? Beware of falsely accusing students outright. Our ability to accurately identify the use of AI generative tools at present is quite weak.  Ask the student to meet with you. Simply say something like  I have some concerns about your assignment. Please come to see me. When you meet with the student  try not to be confrontational (remember that you may not be certain they used AI in an unauthorized manner). Instead  start by asking them questions that will give them a moment to tell the story of their writing process  such as: How were you feeling about the assignment? What do you think was challenging about it? Why don t you tell me what your process was for getting it done. If there is research involved  you can ask what research they used. If they were writing on something they were supposed to read or visit (an art exhibit  for instance)  ask pointed questions that get at whether they actually engaged in that activity. Then state your concerns: I m concerned because the writing in this assignment doesn t seem to match the writing in your other assignments  and the AI detector tool said that it is AI written. Point out any inconsistencies  odd language  repetition  or hallucinated citations with the student. Use developmental language. Remember that your student may have used generative AI without realizing it is considered cheating  or there may have been factors that made them feel that they needed to cheat. A conversation with your student can be a learning opportunity for them. Discuss with the colleagues in your department what a reasonable penalty might be for unauthorized use of generative AI. Consider also when it might be necessary to contact The Office of Student Conduct and Community Standards. (Remember  however  that speaking with your student is always the first step before taking further action.) If your conclusion is that the student cheated  you ll have to decide whether you allow them to complete the assignment again on their own (perhaps with a penalty) or whether you ll give no options to right the ship. Consider that we are in a developmental stage with these tools and it might be good to give the do-over if the student owns up to it. Self-reflect. Given that students often take shortcuts for reasons related to the course structure  review our blog post on academic integrity and AI in order to take steps to promote academic integrity and consider whether your course is designed to reflect these best practices.In a letter to the faculty on August 17  2023  Provost Mandel made clear that  ultimately  it will be important for faculty to determine the appropriate use of AI tools in their classrooms. However  the letter also clarified the following policies for fall 2023: Because we will all need time to fully explore the capabilities of generative AI tools  for the Fall 2023 semester  Temple has established a blanket policy that the use of generative AI tools is prohibited for students  unless an instructor explicitly grants permission. Students will be informed of this policy before the start of the semester  and Temple s revised Student Code of Conduct now explicitly defines unauthorized use of generative AI tools as academic misconduct. In addition  you should add a statement to your syllabus outlining your stance on students  potential use of such tools and discuss your decision with your students. These model syllabus statements  which can be adopted or modified as needed  have been developed to assist you in articulating this decision. Temple has acquired a university-wide license for Turnitin s recently released tool designed to detect AI-generated text (this is a different tool than the plagiarism detection tool that Temple has used for years). This AI-detection tool should be used with an abundance of caution  as it is often inaccurate and does not allow the ability to verify its results. However  it appears to be better than other tools available at this time. For Fall 2023  Turnitin s AI detector tool will be available for you if you wish to use it. You must request access and complete a brief asynchronous training before the tool will be enabled. The training will provide guidance on how to interpret inaccurate and ambiguous results. Please login at tuhelp.temple.edu and select the  Turnitin AI Detector  option to submit your request."

"Balyor University",  "Discuss this issue with students on the first day of class  communicate your expectations to them  and make clear to students that submitting work produced by an AI system as their own is not acceptable and is a violation of Baylor s Honor Code. Familiarize yourself with AI systems. Try some of the essay prompts or assignments you have used in the past to see how these systems work and to see what they produce.  The better you know  for example  what ChatGPT will produce  the better you can design your assignments to address potential issues. Require writing to be done in class (by hand if possible). Write essay prompts that are specific enough to other class assignments such that vague essays produced by AI systems won t be possible. Consider incorporating personal reflections from students into essays where possible. AI systems appear not to be very good when addressing topics after 2021.  Where possible  consider incorporating something about very recent events into essays. AI bots appear to struggle with accuracy with regard to in-text citations and reference lists.  Require both in your essays  where possible  and then look for errors. Consider requiring students to submit multiple drafts of an essay (using what is often referred to as a  scaffolding  approach to writing instruction) that students then revise based upon your feedback. Require a combination of in-person and outside-of-class writing assignments so that a student s outside-of-class writing can be compared to his/her writing that is produced in class. Incorporate a verbal exam requirement tied to an essay so that students are required to discuss what they are turning in. Look for vague general comparisons that tend to  beg the question  as opposed to getting at the heart of an essay topic. Look for factual claims that are asserted confidently but turn out to be false on closer inspection. Look for claims that are backed up with citations of  evidence  but evidence that doesn t support the claims made."

"Drexel University" , "This policy on academic integrity pertaining to Artificial Intelligence clarifies the existing Academic Integrity Policy and the Academic Integrity Conduct Process to explicitly address the use and misuse of Artificial Intelligence Tools in all contexts related to education and learning at Drexel University. This policy applies to the entire University community  faculty  professional staff  students  or a combination of these groups. Implementation of this policy is the responsibility of the Office of the Provost. For inquiries regarding this policy  please contact the Office of the Provost at provost@drexel.edu.The following points are background for these policy: Artificial Intelligence Tools are  and will increasingly be  a vital component of many academic and professional disciplines. Academic units have integrated Artificial Intelligence tools into their courses and curricula  and the University as a whole recognizes the enormous pedagogical value of these tools.The landscape of Artificial Intelligence Tools is rapidly changing  including the names of the most commonly used tools  the wide variety of contexts and uses in which the tools are employed  and the scope and efficacy of these tools. Consequently  no attempt is made to catalog or taxonomize this landscape. Rather  Appendix A  AI Tools: Scope and Use at Drexel University  presents a partial snapshot of the current landscape  with the recognition this snapshot will require regular updates to maintain relevance.The broad scope of the University's education and learning enterprise  including breadth of topic  level  pedagogy  and mode  as well as the broad scope of use of Artificial Intelligence Tools in education and learning naturally lead to a broad scope for the suitable use of these tools in the classroom. Consequently  a foundational component of this policy is that instructors have broad discretion to define the suitable use of Artificial Intelligence Tools in the classroom. It is the right of the course instructor to decide whether AI Tools are to be permitted in the course and  if they are allowed  to describe precisely the conditions and criteria for use. Certain limited exceptions may apply for students with disabilities consistent with ODR-1 and applicable law. Students requesting or requiring accommodations are encouraged to contact the Office of Disability Resources.It is the responsibility of the instructor to include in the course syllabus a clearly written description of the permitted use of AI tools. It is strongly recommended that the instructor discuss this written description at the beginning of the course and as needed throughout the term. It is also expected that faculty describe precisely how students are expected to attribute / cite the use of AI tools. To assist faculty with communicating which AI tools are permitted in a course  Appendix A ( AI Tools: Scope and Use at Drexel University ) provides a checklist of common AI tools that faculty can customize based on their preference and include in the syllabus  and Appendix C ( AI Tools: Sample Syllabi Language ) provides language instructors may use in their syllabus to summarize their course policy on the use of AI. Given the wide and dynamic landscape of AI Tools available for use by students in coursework  it is NOT required for the instructor to specify permitted use of every such tool. Instead  wherever there is a lack of clarity or specification  the default policy on the use of AI Tools in courses is that such tools are not permitted. Below are three important exceptions to this statement: All databases and research tools provided by Drexel University Libraries are approved for use in coursework  unless such usage contradicts instructor guidance on coursework completion. Appendix A ( AI Tools: Scope and Use at Drexel University ) includes a list of AI tools that are approved for use in coursework by default  unless such usage contradicts instructor guidance on coursework completion. Certain exceptions will apply for students with disabilities. Students requesting or requiring accommodations are encouraged to contact the Office of Disability Resources. It is the responsibility of the student to read  understand  and seek clarification from the instructor where necessary on the instructor's written and verbal descriptions of the acceptable use of AI in the course. If usage of AI Tool(s) is permitted by the instructor  students are obligated to follow the instructor's guidance regarding the nature of that usage. If usage of AI Tool(s) is permitted by the instructor  students are obligated to follow the instructor's guidance regarding if and how that usage is to be attributed/cited in the submitted work. If no attribution / citation guidance is given by the instructor  the students should adopt the style typically used in the discipline most closely aligned with the course. Appendix B ( AI Tools: Citation of Use at Drexel University ) aims to assist students with the various citation rules and styles for AI and AI Tools. If usage of AI Tool(s) is permitted by the instructor  the final work product that is submitted is nonetheless the responsibility of the student. It is important that students are aware that AI generated content may be false or biased  and students assume ownership of and responsibility for submitted work that may be violative of other university policies. Inappropriate or offensive content may be reported to Student Conduct & Care or other relevant university offices for consideration of appropriate next steps  if any. The purpose of this section is to clarify the use and potential misuse of so-called  AI Detection Tools.  These tools aim to assess whether or not AI or an AI Tool has been used to create a digital object (e.g.  text  audio  image  video); in this context this applies to any and all student submitted work. There is no restriction on the use of such tools by the instructor  but the instructor is urged to be aware of the potential misuse or misinterpretation of the outputs presented by these tools. Such tools are often fallible; they may both assert the digital object was created by AI when it was not or assert the digital object was not created by AI when it was. Such tools often advertise  error rates  to describe the frequency or likelihood of these mistakes. a. Users of AI Detection Tools should be aware that the method used by these tools to determine if AI was used is particularly likely to yield false positives in the cases of neurodivergent students and students for whom English is not their first language. b. Recent research also indicates that AI Detection Tools yield false negatives where students use paraphrasing tools or edit the document after using AI. The creators and distributors of such tools may misestimate the fallibility of the tool. Instructors are advised to exercise caution regarding the asserted level of accuracy. In the context of plagiarism  for which the same or similar tools are often used  the tool is often able to provide  proof  to accompany an assertion of plagiarism in the form of demonstrating similarity between the object being assessed (i.e.  the work submitted by a student) and another object (i.e.  the reference work from which the student's submission was taken or adapted). In contrast  it is often the case that no such  proof  is available from AI Detection Tools. Due to the possible fallibility  possible misestimation of fallibility  and possible absence of proof to accompany assertions of AI use by AI Detection Tools  it is recommended that instructors use such tools with great caution and with full recognition of their limitations. In general  the  evidence  provided by such tools should be only part of an instructor s case when accusing a student of academic misconduct."
"University of Houston" , "Since its launch in late 2022  ChatGPT has inspired much discourse on potential gains and perceived pitfalls surrounding its use  particularly in academic productivity and scholarly research. The generative artificial intelligence (AI) product created by OpenAI offers responses to questions posed by users  and is trained via machine learning and other language models to provide more refined conversations over time. A new iteration called GPT-4  which can read imagery in addition to text inputs  promotes  safer and more useful responses.   The implications of ChatGPT and other generative AI platforms on information literacy and academic research are part of ongoing discussions at University of Houston  in which faculty and librarians are familiarizing themselves with the technology and gaining a deeper understanding of how students are using it. In conversations with students and faculty  librarians in the department of Teaching and Learning at UH Libraries have learned that students are interacting with ChatGPT for assignments in a variety of ways. They shared that a common use is to prompt ChatGPT to write an essay or at least provide a starting point. Students are also asking it to generate summaries of articles and books to supplement their learning  gain foundational knowledge about a broad topic  or find potential sources for research papers. The academic and scholarly utility of ChatGPT is variable. Because it sometimes provides erroneous or false responses  relying on it to produce a rigorous essay or provide sources that meet academic standards is risky. The temptation for some students to take ChatGPT s responses and submit as their own work can be overwhelming. It s a widely available tool that is here to stay  however  and knowing how it operates  as well as how to use it appropriately  will help mitigate those drawbacks. This is where information literacy plays a significant role in supporting academic integrity  creating an environment in which generative AI and information literacy can coexist for the benefit of scholarly users. Information literacy involves  the reflective discovery of information  understanding how information is produced and valued  and ethical participation in communities of learning.  Teaching and Learning librarians view ChatGPT and other generative AI  as an opportunity to emphasize the importance of verifying information and reinforcing that as a major part of the research process.  Moreover  AI models offer the potential to assist students with language or communication disabilities in drafting or improving essays and other writing. Students might also use ChatGPT to improve vocabulary  sentence structure  and overall communication when learning a new language. UH librarians are responding to the use of ChatGPT by developing their knowledge of generative AI through testing  and are collaborating with UH faculty members to identify teaching materials that could provide instruction for students on applying ChatGPT ethically and as part of an iterative process. Instruction@UH  sponsored by the Office of the Provost  is an online resource for faculty to engage in areas of educational technology and instructional design. A category of content dedicated to AI and ChatGPT offers discussion and practical advice for instructors  such as recommendations on how to integrate the emergent technology in coursework.  For this feature  ChatGPT was asked  how does ChatGPT relate to information literacy?  Its partial response:  ChatGPT  as a language model  can play a role in supporting information literacy…. However  it s important to note that while ChatGPT can be a helpful tool  it s not a substitute for developing one s own information literacy skills. Users should critically evaluate information obtained from any source  including ChatGPT  and seek multiple perspectives to form well-rounded conclusions."


"Thomas Jefferson University" , "By now  you have likely heard about advances in writing AI  including ChatGPT and Bard. Scholars within English studies express excitement by the new developments and concern about inappropriate use. These tools can generate writing for nearly any purpose and tailor the form  genre and tone depending on the user s instructions. AI also offers idea invention and helps writers struggling to get words on the page However  numerous pitfalls exist. For example  students might mistake using AI generators for the act of writing itself; AI may accelerate language injustices that already run rampant in academe  such as the erasure of linguistic diversity and the narrowing of citational spheres; and the tool remains problematic for faculty and students concerned with equity and inclusion (more on that below). The Jefferson community shared recommendations and worries on AI writing tools at Faculty Days earlier this year. Faculty also participated in a task force to make recommendations to the University about AI writing tools in the classroom. The task force recommended faculty members determine the appropriate use of AI for their own classrooms as it s tied to disciplinary standards  including external benchmarks like professional and licensing organizations. This means nursing faculty  for instance  may have different professional and pedagogical standards for AI than design faculty. While each faculty member will decide to what extent AI will be a teaching tool in the classroom  the task force recommends all faculty  regardless of discipline  address its use Given the range of practices students might encounter  Jefferson s writing and rhetoric faculty wanted to distill best practices across disciplines for faculty and students. We hope these recommendations help as you prepare for the fall semester To get the most out of writing in any classroom setting (read: to yield the best student writing)  instructors should help students practice disciplinary forms of writing and critical inquiry of sources and citation practices  as well as respond to feedback to revise. For a brief intro to best practices in teaching writing  review the National Council of Teachers of English statement on Principles for the Postsecondary Teaching of Writing and writing scholar Ed White s foundational Heuristic for the Writer of Writing Assignments. Ask yourself: What will students learn by writing this assignment? AI writing tools don t understand what s authentic  the motivation behind a particular prompt or the cultural context in which its words will be used. Understandably  when encountering AI writing software  developing writers may feel discouraged: Why learn to write if a machine can write my essays for me? Therefore  use ChatGPT to educate students on their unique strengths as human writers. Help them think through   What can I do that AI writing tools cannot?  For example  ChatGPT never has had a sensory experience with anything. If asked to write about a tree  ChatGPT will describe a tree based on input information and the material—previous writing—on which it learned. It cannot sense a particular tree. ChatGPT can help us navigate the existing knowledge about the world  but it cannot itself realize anything new. On a more positive note  ChatGPT can be a great invitation to imagination and play. ChatGPT can rewrite a passage into another author s voice or generate original scenes from  The Office  on class content  which can help students to reengage or encounter material from a different angle. Such playful attitudes facilitate original  divergent thinking  yet another of our human strengths. Because AI generates standard written English  the writing produced can create the impression this English is the only  or best  kind of written English. AI writing generators reflect only the text they know  which means they mirror what s most conventional or easily found online. AI writing tools also don t understand what s authentic  the motivation behind a particular prompt or the cultural context in which its words will be used. This includes understanding how the writing style itself might be inappropriate  offensive or irrelevant. The erasure of linguistic diversity in classroom settings has dire consequences for the relevance and efficacy of academic preparation across disciplines (for example  consider the role of hospitable language practices in public health  medical education  manufacturing instructions or real estate sales). And decades of scholarship on language diversity show professional and academic contexts only gain credibility when they include  gesture to and explicitly invite other Englishes. To counteract the assumption that AI s default style is natural or normal  invite students to write in Englishes relevant to them. Ask students about their home languages  how they want to sound on the page and what help they need to get there. Students will look to faculty for guidance with AI. Make expectations for how students should create and submit writing assignments clear on the syllabus and discuss them each time you approach an assignment. While you may ask students to use AI writing tools differently per assignment  they will likely benefit from a few ground rules relevant to all of them. Ask students to cite the AI generator if it has played a significant role in creating text and offer acceptable and unacceptable uses. This crowdsourced  multidisciplinary and multi-institution AI policy index can be helpful. AI writing tools present a threat to a writer s credibility. These tools are deeply flawed in their accuracy  provide a shallow pool of references and offer simplistic  overgeneralized explanations to complex questions. Deep research  nuance and specificity are the keys to good academic writing. Because AI often is wrong or reductive  you can  talk back  to the AI response to see what s missing and find the edge of the tool s capacity on a particular topic. Ask   Why didn t you consider any sources with a global perspective?  Or   Can you disagree using examples from the [name a local event]?  And   Why can t you find any more evidence about [name of local problem]?  You can then fill in the gaps with further research. If asked to write about a tree  ChatGPT will describe a tree based on input information and the material—previous writing—on which it learned. It cannot sense a particular tree. Writing can be a powerful practice for developing an inner life as it can mobilize personal expression  self-understanding and agency. ChatGPT can t replace this kind of writing and cannot articulate your own story  self or life. While faculty will have differing expectations about the use of personal evidence and pronouns like  I  in written assignments  there s no erasing an author s subjectivity. If you re struggling with an assignment  consider writing the  guts  of it in a letter to a friend or an email window. Then  give ChatGPT the same assignment. What are the differences between the two drafts? Can you combine and revise them to make a richer draft than you would have initially started with? Writing your ideas to yourself or a close friend and combining them with the automation and convention of AI may get you closer to the product the professor expects—without losing your voice  expressiveness or sense of inwardness. Remember to check the AI s facts (see above) and cite the generator s contributions to your work. Most citation styles offer a template for AI. Writing can be a powerful practice for developing an inner life as it can mobilize personal expression  self-understanding and agency. ChatGPT can t replace this kind of writing. Finally  we encourage students and faculty to sign on to any of the AI writing tools and get comfortable with the writing they create. To produce satisfactory writing  you may need to spend some time directing the tool to do specific writing tasks:  Explain the example in paragraph three  and  Explain why you think the example in paragraph three supports the overall point that [repeat of thesis statement].  These specific writing prompts are teaching tools themselves  and taken as a sequence of directions  your prompts become an outline of your writing process. You may not need Bard s help  after all.Faculty who would like support for the teaching of writing can schedule a consultation via the University s Writing Across the Curriculum initiative. Students looking for support can contact the Student Writing Center on Center City Campus or the Academic Success Center on East Falls Campus. Dr. Katie Gindlesparger is associate professor of writing and rhetoric and director of the university writing program; Daniel Cronin is visiting assistant teaching professor of writing and rhetoric; Dr. Abigail Orenstein Ash is assistant teaching professor of writing and rhetoric; and Dr. Valerie Hanson is associate professor of writing and rhetoric and associate dean of the College of Humanities and Sciences."
"Syracuse University"  ,"In response to the emerging field of artificial intelligence  Syracuse University s School of Information Studies launched the class Information Studies 300: AI and Humanity this fall. The class is an introductory course for the Autonomous Systems Policy Institute  a SU initiative launched in 2019  that focuses on the intersection of technology  society and policy. It will be taught by Hamid Ekbia  a professor at the Maxwell School of Citizenship and Public Affairs and the director of ASPI.  All of us  as citizens  need some level of understanding of AI and that is what this course is going to do   Ekbia said the course follows a  bottom-up  approach to build a solid and robust foundation and understanding of AI  which he sees as essential to students at SU.  This class is meant to be on AI  but from a very multidisciplinary perspective   Ekbia said.  The goal is to get students from all over campus and from all different disciplines Although many SU professors have included specific language and guidelines in their syllabi addressing the use of AI in their classrooms  Ekbia intentionally didn t. Instead  he is opting to teach students how to use AI in a responsible and ethical way.  Rather than telling people what to do or what not to do  I m going to teach them to develop a clear sense of how to do this themselves   he said. The use of AI in academic settings has been reflected in classes and syllabi throughout SU as programs like ChatGPT – a widely-used chatbot driven by AI technology – have increased in popularity. ChatGPT became the fastest-growing consumer application in history after reaching 100 million monthly active users in January  only two months after launch  according to Reuters. Nina Iacono Brown  an S.I. Newhouse School Of Public Communications professor who specializes in communications law  said SU s current Academic Integrity Policy  updated in 2021  already indirectly addresses the use of AI in academic work.  Our academic integrity guidelines are pretty clear  what is acceptable and what is not acceptable   Brown said.  So when a professor asks a student to write a response to something  for example  the expectation is that the student is writing the response  not AI.  SU faculty and instructors are also encouraged to include a statement on whether and how artificial intelligence should be included or prohibited in their syllabi  according to SU s Center for Learning and Student Success syllabus recommendations. Dan Pacheco  a Newhouse professor of practice and the Peter A. Horvitz Chair of Journalism Innovation  said he sets specific guidelines in each of his class syllabi that allow the use of AI  as long as students disclose how and when they use it. Classes he teaches like Magazine  News and Digital Journalism 545: Virtual Reality Storytelling have more flexible rules than others.  We are at a unique inflection point in human history with next-generation Generative Artificial Intelligence coming online over the past year   Pacheco wrote in his syllabus for Journalism 221: Foundations of Data and Digital Journalism  which he sent to The Daily Orange.  If you use generative AI to assist in the performance of your coursework  including assignments  you must disclose it.  Pacheco doesn t allow students to use generative AI to write stories or generate and analyze data. Students are permitted to use generative AI in other ways  such as to get instructions on a task or to help write HTML code. Pacheco said he is set to teach a Newhouse class next semester on artificial intelligence for media professionals.  We need to start using these tools in an educational setting in responsible ways that line up with how industries are using them   he said. In response to the emerging field of artificial intelligence  Syracuse University s School of Information Studies launched the class Information Studies 300: AI and Humanity this fall. The class is an introductory course for the Autonomous Systems Policy Institute  a SU initiative launched in 2019  that focuses on the intersection of technology  society and policy. It will be taught by Hamid Ekbia  a professor at the Maxwell School of Citizenship and Public Affairs and the director of ASPI.  All of us  as citizens  need some level of understanding of AI and that is what this course is going to do  Ekbia said the course follows a  bottom-up  approach to build a solid and robust foundation and understanding of AI  which he sees as essential to students at SU.  This class is meant to be on AI  but from a very multidisciplinary perspective   Ekbia said.  The goal is to get students from all over campus and from all different disciplines.  Although many SU professors have included specific language and guidelines in their syllabi addressing the use of AI in their classrooms  Ekbia intentionally didn t. Instead  he is opting to teach students how to use AI in a responsible and ethical way.  Rather than telling people what to do or what not to do  I m going to teach them to develop a clear sense of how to do this themselves   he said. The use of AI in academic settings has been reflected in classes and syllabi throughout SU as programs like ChatGPT – a widely-used chatbot driven by AI technology – have increased in popularity. ChatGPT became the fastest-growing consumer application in history after reaching 100 million monthly active users in January  only two months after launch  according to Reuters. Nina Iacono Brown  an S.I. Newhouse School Of Public Communications professor who specializes in communications law  said SU s current Academic Integrity Policy  updated in 2021  already indirectly addresses the use of AI in academic work.  Our academic integrity guidelines are pretty clear  what is acceptable and what is not acceptable   Brown said.  So when a professor asks a student to write a response to something  for example  the expectation is that the student is writing the response  not AI.  SU faculty and instructors are also encouraged to include a statement on whether and how artificial intelligence should be included or prohibited in their syllabi  according to SU s Center for Learning and Student Success syllabus recommendations. Dan Pacheco  a Newhouse professor of practice and the Peter A. Horvitz Chair of Journalism Innovation  said he sets specific guidelines in each of his class syllabi that allow the use of AI  as long as students disclose how and when they use it. Classes he teaches like Magazine  News and Digital Journalism 545: Virtual Reality Storytelling have more flexible rules than others.  We are at a unique inflection point in human history with next-generation Generative Artificial Intelligence coming online over the past year   Pacheco wrote in his syllabus for Journalism 221: Foundations of Data and Digital Journalism  which he sent to The Daily Orange.  If you use generative AI to assist in the performance of your coursework  including assignments  you must disclose it.  Pacheco doesn t allow students to use generative AI to write stories or generate and analyze data. Students are permitted to use generative AI in other ways  such as to get instructions on a task or to help write HTML code. Pacheco said he is set to teach a Newhouse class next semester on artificial intelligence for media professionals.  We need to start using these tools in an educational setting in responsible ways that line up with how industries are using them   he said. Alex Richards  an assistant professor of Magazine  News and Digital Journalism in Newhouse  also allows some use of AI in his classes. He said AI can play an important role as a  tutor  for students to help them understand anything they want at any time. But he cautions students against relying on it too heavily.  Generative AI is not acceptable to use when it s doing the work for you   Richards said in his class syllabi s generative AI and large language model policy  which he sent to The D.O. The temptation of AI in classrooms  Richards said  presents its own set of problems by creating a  short-cutting  approach that can sever critical thought. Yüksel Sezgin  an associate professor of political science in Maxwell  is also afraid of AI diminishing a student s ability to think individually and critically. Sezgin has not only banned the use of AI in his classes but also the use of all technological devices in his classroom. In response to the rising popularity of ChatGPT  Sezgin said he has stopped giving take-home exams this year  which he has done every year previously.  I have to keep a fair playing ground for all my students between those who cheat and those who don t cheat   Sezgin said.  That is my role as the educator.  Beyond fairness concerns  the negative implications of AI  such as structural biases and misinformation  have been raised by many SU professors.  The biggest concern that I have  especially as a person of color  is the biases that exist in large language models   Pacheco said. They were trained on data from the internet that reflects our cultural biases  so our AI basically will then use those patterns and reflect them back outward.  Pacheco said the best way to avoid feeding the  beast of bias  is to build the time and space for conversations about issues exacerbated by AI and to teach students how to navigate these technologies responsibly. Another concern Richards raised was how AI could potentially misinform students who use it as a research tool.  AI creates something that sounds like it should be right and in the process of doing that  it certainly can be right  it can be correct   Richards said.  But it will also make things up  it will hallucinate  it will generate facts that aren t facts.  Jasmina Tacheva  an assistant professor in the iSchool  said she has concerns about AI s broader societal implications beyond academia  such as the environmental impacts of data centers and pay rates for AI workers who train models.  My appeal to all of us is not to be swept away by the AI hype cycle; instead  we ought to understand these technologies for what they are – mirrors reflecting our society  with all of its inherent complexities and challenges   Tacheva wrote in an email to The D.O. Despite these concerns  Brown acknowledges the educational benefits of AI  as long as professors and students keep in mind that these developing technologies are only just emerging and are inherently flawed. As AI becomes more prevalent in educational settings and beyond  Richards said  it s now up to educators to navigate its place in the classroom.  It s just sort of a brave new world   Richards said.  We re going to have to find ways to respond quickly to AI to keep the whole college experience meaningful and worthwhile." 


"University of California  Santa Barbara",  "UCSB s Office of Teaching and Learning recognizes significant opportunities and challenges associated with the widespread accessibility of AI-assistive technologies  including those that assist with forms of composing like writing  coding  drawing  and completing equations. This document is intended to provide guidance about the ethical use of these technologies by both instructors and students. Communicate expectations for student use of AI-writing assistive technologies in courses and/or other documents such as theses  dissertations  research articles  etc. The use of AI writing technologies falls within the purview of the Student Conduct Code and the Student Guide to Academic Integrity. It states that  Materials (written or otherwise) submitted to fulfill academic requirements must represent a student s own efforts unless otherwise permitted by an instructor.  Therefore  student use of AI-assistive technology for writing is not allowed in courses  on theses  dissertations  research articles  etc. unless specifically allowed by the instructor or supervisor. Explain  why.  As AI tools become more integrated with commonly used programs (e.g. GoogleDocs)  it becomes increasingly important for instructors to explain why and how AI tools should/should not be used. Considerations may include: the accuracy/credibility of AI generated work  potential bias of AI-generated results  developing students  critical thoughts/voice/skills  etc.Consider including a policy statement specifically about the use of AI tools (see examples in Sample Language for Syllabus Policies). See #5 for ideas about how to use LLM/AI in courses. Use AI-Writing Assistance technologies for plagiarism detection  grading and feedback ethically UCSB does not support the use of plagiarism detection software (e.g. Turnitin  ChatGPT Zero) for several reasons: Anti-plagiarism software is highly fallible. LLMs are advancing at lightning speed with huge injections of capital. Procuring  anti  LLM software contributes to a virtual arms race  with detection software always one step behind what LLMs can produce.Submitting student work to anti-plagiarism software may violate students  intellectual property rights.  When student work is uploaded into a AI-Writing/plagiarism detector database  the student may lose ownership of their work and the instructor/University unable to safeguard how it is shared and used in the electronic commons. Use of anti-plagiarism software can undermine the fundamental relationship of trust that must exist between learners and teachers. To move from  detection  of LLM use to  prevention   instructors can  consider  how students can use LLMs as a tool to support their work  and/or craft assignments and activities that cannot be produced by LLMs (see Incorporating AI-Writing Assistance technologies into courses  below). While this approach may represent a shift in perspective or assignments  Office of Teaching and Learning instructional consultants offer extensive support for instructors who would like to pursue this approach. Instructors and TAs should not use AI-assistive technology for grading and feedback unless the technology is supported by UCSB (e.g. use of GradeScope is permitted  as UCSB has a contract for its use and the technology has been vetted for FERPA compliance)  for the reasons outlined above.Report unauthorized student use of AI-assisted writing technologies The Office of Student Conduct adjudicates academic and behavioral violations of the Student Conduct Code. If you suspect unauthorized use of AI technologies  submit an incident report. Be sure to include any samples of earlier/baseline student writing to which the writing in question can be compared. Avoid issues with student use of AI-assistive technologies. Scaffold writing assignments  so that students are writing smaller pieces that will be incorporated into larger assignments with opportunities to incorporate feedback. Add brief reflective writing to assignments that ask students to analyze the choices that they made as they compiled the writing (give examples). Talk with students about the purpose of writing in the course and work with students to use LLMs in productive ways Assign topics that require personal reflection or creative thinking. For example  ask students to reflect on a personal experience related to the course material. Consider incorporating AI Writing Assistance technologies into your course  Create assignments where students use LLMs as part of the writing/thinking activities. You can get inspiration by browsing 101 Creative Ideas to Use AI in Education and other resources under  Ideas for use  at the end of this document. Stimulate discussions about writing processes  strategies  and ethics through discussions of AI writing technology. Work with your students to generate diverse examples  compare and contrast them with student work  and examine their strengths and weaknesses collaboratively. Encourage student creativity and curiosity by leveraging AI writing technology to create prompts  topics  or questions for exploration. Challenge students to interrogate how AI writing technology can help them compose pieces across various genres  styles  and perspectives. Invite students to utilize AI to generate text in specific genres in order to recognize and identify genre conventions and reflect upon the role of audience  purpose  and context in developing rhetorically effective prose. Encourage students to compare AI-generated text with human-generated text to see how individual agency  voice  and ethos impact text. Examine the potential for and risks of integrating AI writing tools into the research process  given that LLMs can  hallucinate  and generate false facts  statements  or sources. Urge students to cross-check AI-generated information and develop critical appraisal skills to maintain the credibility and precision of their work. Examine and address potential biases and fairness concerns that may arise from AI writing technology  including the perpetuation of stereotypes or the exclusion of specific perspectives. Promote critical thinking and discussions to recognize and counteract biases in AI-generated content. Think about your course objectives. What are the cognitive tasks students need to perform without AI assistance? When should students rely on AI assistance? Where can an AI aid facilitate a better outcome? Are new rubrics and assignment descriptions needed?"

"The University of Chicago",  "Generative artificial intelligence (AI) tools offer many capabilities and efficiencies that can greatly enhance our work. When using these tools  members of the University community must also consider issues related to information security  privacy  compliance  and academic integrity.  Below are some guidelines on using and procuring generative AI tools such as OpenAI s ChatGPT  Microsoft s Bing  and Google s Bard. Please note that these guidelines are not a new University policy  but are extensions of existing University policies. 1. Protection of University Data The use of confidential data with publicly available generative AI tools is prohibited without prior security and privacy review. This includes personally identifiable employee data  FERPA-covered student data  HIPAA-covered patient data  and may include research that is not yet publicly available. Some grantors  including the National Institutes of Health  have policies prohibiting the use of generative AI tools in analyzing or reviewing grant applications or proposals. Information shared with publicly available generative AI tools may expose sensitive information to unauthorized parties or violate data use agreements. (Please see Policy 601 for definitions of confidential data and its use for more information.) 2. Responsibility for Content Accuracy and Ownership AI-generated content may be misleading or inaccurate. Generative AI technology may create citations to content that does not exist. Responses from generative AI tools may contain content and materials from other authors and may be copyrighted. It is the responsibility of the tool user to review the accuracy and ownership of any AI-generated content. 3. Academic Integrity For guidance on how generative AI tools intersect with academic honesty  it is recommended that instructors contact the Chicago Center for Teaching and Learning. (See Academic Honesty & Plagiarism in the Student Manual for University policy.) 4. Procuring and Acquiring Generative AI Tools Generative AI systems  applications  and software products that process  analyze  or move confidential data require a security review before they are acquired  even if the software is free. This review will help ensure the security and privacy of University data. Please contact IT Services at itrisk@uchicago.edu before acquiring or using any tools  add-ons  or modules that include generative AI technology with University confidential data  even if they are free. For more information  see the Policy on the Use of External Services and the Policy of Procurement and Engagement."

"University of California  San Diego" , "Introduction With technology advancements such as ChatGPT  Google Bard  and other AI-driven platforms  there's growing enthusiasm within our UC San Diego community to leverage these tools and integrate them into our ecosystem. This guide serves to advise UC San Diego staff on safe and compliant use  ensuring we do not compromise institutional  personal  or proprietary data. This guide does not include guidance for faculty on acceptable use for pedagogical purposes. Guidance tailored to faculty needs may be sought through appropriate channels within the university. Recognizing the dynamic nature of the AI field  this content will be updated regularly to align with the constantly evolving landscape. What is Generative AI? Generative Artificial Intelligence (GenAI) encompasses a range of technologies designed to create new  original content by leveraging extensive training on diverse datasets—ranging from text and music to images. Notable among these tools is ChatGPT  a chatbot equipped to engage users through natural language interactions.  Chat  signifies the user-friendly interface  while  GPT  (Generative Pre-trained Transformer) indicates the underlying machine learning architecture responsible for content generation.GenAI tools like ChatGPT  DALL∙E  and Google Bard excel at generating text  music  images  and even computer code. These models undergo rigorous training on comprehensive datasets  which include an assortment of text from books  websites  and various other sources. By decoding complex patterns and linguistic nuances  they can produce content that is not only contextually appropriate but also grammatically accurate and stylistically coherent. How Generative AI Can Administrative Assistance: Automate routine communications like operational change reminders and policy updates  and summarize public-facing content for ease of access. Coding and Web Development: Draft code for common programming tasks  accelerating the development process. Event Planning: Automate the creation of event descriptions  schedules  and promotional material for public calendars. Image and Video Production: Edit and create images  as well as voiceover tracks for videos  to elevate your media production.Job Descriptions and Postings: Use templates to suggest customized language for position overviews  key responsibilities  and qualifications. Review the language to ensure it is free from unintended biases  as biased wording may discourage certain groups from applying  potentially impacting the diversity of the applicant pool. Language Translation: Generate translations while recommending consultation with native speakers for accuracy and appropriate tone. Training & Onboarding: Develop training materials and FAQs for new tools  and automate responses to common questions during staff training sessions. Website and Communications Content: Edit text for clarity and grammar  suggest optimal layouts  headlines  and meta descriptions  and draft content for course listings  prerequisites  or institutional information. Guidelines for Protecting Institutional Information When Using Generative AI Tools When using tools not covered by UC San Diego or University of California contracts  be careful with the institutional data you share. Do not use ChatGPT or similar tools for confidential or sensitive information. As a standard practice  never share Personally Identifiable Information (PII)  FERPA-protected student records  or data classified as P3 or P4 with any service provider without proper contractual safeguards. If you're uncertain about the data classification applicable to your specific scenario  consult the UCOP website for guidance on information classification. As a user of commercial GenAI services  it's crucial to know your responsibilities when using a service. Both OpenAI  the company behind ChatGPT  and Google set clear restrictions on using their tools for fraudulent or illegal activities. For complete details  refer to OpenAI's usage policy and Google Bard's Privacy Notice.Errors and  Hallucinations  When using generative AI tools like ChatGPT  Google Bard  and similar technologies for business purposes  be vigilant about  hallucinations —moments when the AI generates unverified or incorrect information. Always cross-check the tool's output for accuracy before incorporating it into university-related tasks. While generative AI is potent  it can occasionally produce false or misleading content. Ensure all facts and figures generated by these tools are independently verified through non-AI sources before use. In other words  don't simply copy and paste what is produced into your work. Bias When using Large Language Models (LLMs) like ChatGPT within the UC San Diego community  it's important to recognize that the datasets used to train the models may be trained on incomplete or biased data. Implicit and systemic biases can inadvertently be built into AI systems. Such biases run counter to UC San Diego's institutional values of diversity  equity  and inclusion. Therefore  using outputs in a way that amplifies these biases can be contrary to our shared institutional values. Learn more about bias  inclusion  and belonging through UC San Diego HR courses on these topics or through the resources offered by the Office for Equity  Diversity  and Inclusion."


"University of Minnesota  Twin Cities",  "The use of AI in your classes Discussions about the use (and potential abuse) of artificial intelligence platforms like ChatGPT have been dominating headlines. Our entire university community is learning to adapt to this new terrain  and it can sometimes be hard to know what is or is not acceptable use. The permissibility of artificial intelligence tools will vary from course to course depending on the specific learning and assessment goals of the instructor. You may have already heard from your instructor(s) about their policy in their classes  in their assignments and on their finals. If you have not received clarification from an instructor  and if you are thinking about using ChatGPT or another AI tool for any course assignment  I encourage you to communicate with your instructor to make sure you understand what is permitted.Remember that  per the Student Conduct Code  unauthorized use of online learning support and testing platforms is considered a breach of academic integrity and is subject to the same set of sanctions that would result from other forms of scholastic dishonesty."

"Ohio State University" , "There has been a significant increase in the popularity and availability of a variety of generative artificial intelligence (AI) tools  including ChatGPT  Sudowrite and others. These tools will help shape the future of work  research and technology — but when used in the wrong way  they can stand in conflict with academic integrity at Ohio State. All students have important obligations under the Code of Student Conduct to complete all academic and scholarly activities with fairness and honesty. Our professional students also have the responsibility to uphold the professional and ethical standards found in their respective academic honor codes. Specifically  students are not to use  unauthorized assistance in the laboratory  on field work  in scholarship or on a course assignment  unless such assistance has been authorized specifically by the course instructor. In addition  students are not to submit their work without acknowledging any word-for-word use and/or paraphrasing  of writing  ideas or other work that is not your own. These requirements apply to all students — undergraduate  graduate  and professional. To maintain a culture of integrity and respect  these generative AI tools should not be used in the completion of course assignments unless an instructor for a given course specifically authorizes their use. Some instructors may approve of using generative AI tools in the academic setting for specific goals. However  these tools should be used only with the explicit and clear permission of each individual instructor  and then only in the ways allowed by the instructor."

"Pennsylvania State University",  "Artificial Intelligence (AI) tools have increased in availability  accuracy  and popularity in a short amount of time. This has raised concerns among educational institutions and instructors about the authenticity of student work and how the use of these AI tools affects the work students do in their courses and the credentials they earn because of that work. As a result of AI authoring tools  AI detection tools (AI-giarism detection) have also been developed. Responding to Artificial Intelligence Writing Tools What is ChatGPT and What Can It Be Used For? The James P. Jimirro Professor of Media Effects and Director of the Center for Socially Responsible Artificial Intelligence at Penn State  S. Shyam Sundar  and Assistant Professor of Information Sciences and Technology Director at the University's Human Language Technologies Lab  Shomir Wilson  explain what ChatGPT is and what it can be used for.  In the Penn State News article   What is ChatGPT and what can it be used for?   both Penn State artificial intelligence experts offer their perspectives on the most frequently asked questions on AI and ChatGPT . Will Artificial Intelligence Kill College Writing? Online programs can churn out decent papers on the cheap. What now? In October 2022  the Working Group of Penn State Online Coordinating Council was charged to investigate issues related to Artificial Intelligence and Academic Integrity (AI²). The AI Writing Work Group delivers recommendations for Academic Integrity definitions  policies and procedures; guidance for the design of assignments and assessments; and faculty development resources. AI Writing Work Group members  Chris Millet  Senior Director of Learning Design  World Campus and Wendy Mahan  Director of Learning Design  College of the Liberal Arts presented PowerPoint:  Will Artificial Intelligence Kill College Writing?"  

"Emory University"   ,"Copyright and AI There is some debate as to whether AI corpora and outputs are protected by fair use and/or transformative use guidelines  e.g. Fair Use: Training Generative AI (Creative Commons Article) Copyright implications in text and data mining: Resources for Text and Data Mining LibGuide Recent Cases and Legal Research on AI HeinOnline is a great source for legal research on issues of artificial intelligence and associated technologies. The link below contains a canned search for  Artificial intelligence or machine learning . Hein Online customized search  Recommended AI Blog List from TIGER (Technological Innovation:Generating Economic Results program at Emory Law and Business). Government Resources Interested in finding out what the federal government is discussing and concerned about in regards to applications of AI to federal functions  as well as in regards to privacy and ethics? Consider congressional hearings and reports  which often incorporate overviews of pending legislation and input from expert witnesses in these areas. Your best source for this source of information is ProQuest Congressional. Note thats hearings are also searchable in the library catalog."
 




"Purdue University",  "Artificial intelligence continues to emerge as a powerful tool for education. Purdue is committed to being at the forefront of translating research to practice and extending the frontiers of excellence in teaching and learning. To that end  Purdue s Office of the Vice Provost for Teaching and Learning has issued draft guidance for instructors on the use of AI in Purdue courses and learning environments for spring 2024  with input since summer from University Senate leadership  the Ad Hoc Committee on AI  the Center for Instructional Excellence  and the Innovation Hub. The draft guidance can be viewed on the Office of the Vice Provost for Teaching and Learning webpage. Topics covered include academic integrity  syllabus statements  AI detection tools and instructor responsibilities regarding grading  as well as copyright  the Family Educational Rights and Privacy Act (FERPA) and privacy considerations.The Office of the Vice Provost for Teaching and Learning is seeking feedback on this guidance and welcomes input  via the Qualtrics survey on the office s website  from faculty and staff teaching Purdue courses. The survey will remain open for feedback and review until Dec. 31. The Spring 2024 guidance will be finalized and published on Jan. 2. This guidance will be updated each semester. This guidance will continue to evolve each semester as more feedback is obtained and instructors continue to explore the opportunities these tools provide in the classroom. Separate from this guidance to instructors  Vice Provost Jenna Rickus will continue to collaborate with the University Senate on possible future updates to the academic regulations that may codify AI considerations into university policy. The Office of the Vice Provost for Teaching and Learning will hold a town hall in spring 2024 to solicit additional feedback and discuss the future direction of AI in teaching and learning. A date and more information on this event are forthcoming. In addition to faculty and staff  students will be invited to the town hall  building on conversations that took place with new students during Boiler Gold Rush this semester. To develop the most effective and comprehensive draft guidance  university leaders have collaborated with multiple entities across campus  as mentioned above. Their efforts include funding an AI Innovation Fellow  Lindsay Hamm  at the Innovation Hub to help expand the transdisciplinary network of faculty and staff who are engaged with the innovative integration of AI tools into their teaching. The Innovation Hub also funded a series of AI in teaching and learning grants to provide faculty and staff the opportunity to rapidly deploy experiments for teaching and learning in an AI-rich environment and better understand dimensions of how AI might shape the future of education. On the Teaching@Purdue website  the Innovative Learning Team has compiled resources and suggestions for instructors who want to explore generative AI in their teaching practice. All instructors are encouraged to explore these resources  reach out to the Innovative Learning Team  or participate in Teaching & Learning Community of Practice events this spring." 

"Texas A&M University" ,  "As machines get better at being machines  the primary purpose of higher education must be helping humans get better at being human. Teaching and learning do not happen in a vacuum; educators and learners must contend with emergent technologies (e.g.  Artificial Intelligence)  social movements  and the evolving demands of industry. The sudden and widespread interest in Generative Artificial Intelligence like ChatGPT in late 2022 belies the fact that we have been teaching with AI for quite some time. On this resource page  we provide some timely strategies and basic definitions  and we highlight key modes of thought and areas of skill development relevant to teaching with any technology. We also underscore some of the foundational principles of teaching and learning that bear repeating. Finally  we invite you to join the conversation. If you are utilizing technology in your instruction  we hope that you will consider sharing what you're using and how you're using it. Students of today will be expected to master the technologies of tomorrow. Major companies are already acquiring enterprise licenses for emergent technologies like ChatGPT. As such  incorporating responsible use of these tools in the teaching and learning process can provide students with invaluable experiences and opportunities to prepare to assume their responsibilities as professionals and citizens. Additionally  technologies can be tools to help facilitate and support student learning and success. Instructors can use them to enhance learning by adhering to best practices grounded in the science of teaching and learning. When you want to address and/or incorporate generative AI tools in your course  consider the following principles:Syllabus Statements: Below are two Texas A&M recommended syllabus statement options for instructors to consider adding to their syllabi  informing students of their stance on the use of AI in the course. OPTION 1: According to the Texas A&M University Definitions of Academic Misconduct  plagiarism is the appropriation of another person's ideas  processes  results or words without giving appropriate credit (aggiehonor.tamu.edu). You should credit your use of anyone else's words  graphic images  or ideas using standard citation styles. Artificial Intelligence (AI) text generators and natural language processing tools (colloquially  chatbots - such as ChatGPT)  audio  computer code  video  and image generators should not be used for any work for this class without explicit permission of the instructor and appropriate attribution. This includes  but is not limited to  This excludes pre-existing software additions such as spelling and grammar checkers  which are acceptable.With the emergence of artificial intelligence (AI) technologies  the ways in which we define our creative processes continue to transform. AI generators are rapidly evolving from simple editing for grammatical errors and spelling mistakes (Grammarly  MS Word Spell Check) to sophisticated text production (ChatGPT  Google Bard  etc.)  as well as image  computer code  and audio generation. The presence of such tools  however  does not replace our need to learn how to draft  revise  and reflect on texts  programs  drawings and how to exercise information literacy and personal responsibility in how we locate  evaluate  incorporate  and cite primary/ secondary sources. For example  the Association for Writing Across the Curriculum states the following: Writing to learn is an intellectual activity that is crucial to the cognitive and social development of learners and writers. This vital activity cannot be replaced by AI language generators (AWAC). Engaging in the various aspects of creative pursuits (e.g.  writing  coding  drawing) is critical to education in a broad sense. While AI technologies will continue shaping how we approach these creative tasks  the critical work of creativity relies on integrity  originality  and ethical conduct in regard to appropriate representation as an author or creator. Thus  submitting work with a significant percentage of AI-generated content  unless otherwise permitted  can be considered academic misconduct under Texas A&M University Student Rule 20. Students must therefore cite the use of generative AI tools and document what they have contributed to an assignment. This list represents areas of skill development relevant to teaching with technology. While all of these skills are indeed relevant outside of teaching with technology  they are especially important when seeking to develop our students' capacity for the judgment and decision-making unique to human abilities. Critical thinking involves analyzing and evaluating thinking with a view to improve it (Paul & Elder  2020). Critical thinking is useful in all domains of learning. Critical thought enables students to ask vital questions  formulate problems  assess relevant information  interpret abstract ideas  identify assumptions  draw conclusions  and create solutions. Self-directed  self-disciplined  self-monitored  and self-corrective thinking are all aspects of critical thought that can be nurtured in the learning environment and can be used to guide students as they responsibly employ emergent technologies.Data & information literacy involves the ability to know when and what data are needed  how to obtain data  how to evaluate and use data  and how to derive and communicate insights from data responsibly. With emergent technologies in view  data literacy is realized not only through healthy skepticism about what information these technologies produce but also the information that is used to create these technologies.Ethical reasoning involves making assessments between acts that benefit or enhance the livelihood of others and those that diminish the livelihood of others. Applied  ethical reasoning requires that students be able to identify ethical issues in various situations  understand their own ethical values  and be aware of multiple ethical perspectives. As students practice ethical decision making  their personal identification as an ethical decision maker develops. Examples of elements of ethical reasoning that can be developed through a course or program s curriculum include: ethical self-awareness  ethical issue recognition  and applied ethics implications and consequences. The advent of new technologies or the application of existing technologies to new contexts and use cases provides learners with urgent questions about how these technologies are developed  how they are deployed  and the outcomes that they produce.Strategically appropriate innovation and creativity can be fostered in students. Instructors can take an active role in helping students reframe their views of creativity  specifically as it pertains to what are creative skills and just who can be creative in any given discipline. This section highlights models and methods that can be used to foster creativity and innovation among students as they engage in a wide variety of instructional activities and experiences (e.g.  daily assignments  independent projects  collaborative and group work)Our world is not flat. People are interconnected in a variety of ways  including ideas. As such  current and future global citizens should have know how to interact positively and productively with others. We posit that powerful learning occurs when people are connected with others (situated learning). Ideas and learning can spread through the connections we make. Recognizing those rich experiences constitute one of the most vital aspects of higher education  we therefore encourage the design of learning experiences that promote connections while applying collaboration/teamwork skill application is important. AI tools can help to manage groupwork and to make it more productive. And those with generative capabilities can even act as a near peer - one in the zone of proximal development - for learners. With clear guidance and rational boundary setting  emergent technologies can considerably enhance collaborative efforts and even act as a member of the team. When it comes to the use of emergent technologies for teaching and learning  the possibilities are only limited to one's imagination. But some technologies have been designed expressly for instructional purposes or are so common in instructional contexts as to be nearly ubiquitous. Tools that utilize AI can be used to personalize instruction/feedback/assessment  to act as a tutor or peer reviewer  and to assist with grading."


"Rice University" , "The Glasscock School of Continuing Studies at Rice will host a course exploring the possibilities and potential perils of generative artificial intelligence (AI) starting Sept. 20. The course titled  Generative Artificial Intelligence and Humanity  is open to the public and will examine machine learning and related tools like ChatGPT for various aspects of human life  including education  work  health  creativity  equity  justice  democracy and what it means to be human. Taught by Rice faculty  the course aims to provide a comprehensive overview of the latest developments in AI and its potential impacts on society. A primary part of the Glasscock School s mission is to provide community access to Rice faculty and the incredible and transformative research that is taking place on our campus   said Robert Bruce  dean of the Glasscock School  Additionally  we exist to inform and equip our city with the latest knowledge and skills needed to navigate work and life. This course is a prime example of both of those principles. As the proliferation of AI applications has exponentially accelerated just this year  we are excited to give Houstonians access to some of the leading scholars on the subject to help them understand and navigate this brave new world.  Through a series of lectures  discussions and hands-on exercises  students will explore case studies from various domains to gain a deeper understanding of the potential benefits and drawbacks of these technologies. They will also learn about strategies for ensuring that AI is used in ways that promote equity and justice. AI and Democracy  Moshe Vardi Understanding Generative AI and Machine Learning: How Machines Learn and Decide  Vicente Ordóñez-Román A History of the Limitations and Possibilities of Artificial Intelligence  Elizabeth Petrick How Generative AI May Reshape the Workforce  Fred Oswald Responsible AI for Health  Kirsten OstherrWhat It Means to Be Human in an Age of AI: Philosophical and Ethical Issues  Rodrigo Ferreira How Human Is AI Creativity? Anthony Brandt Generative AI and Education  Richard Baraniuk  It s remarkable how many Rice faculty across disciplines are researching and teaching about the societal impact of generative AI   said Cathy Maris  the Glasscock School s assistant dean for Community Learning and Engagement.  No one field has the solutions to these complex challenges. This course gives the public access to speakers from the fields of computer science  history  psychology  English  medical humanities and music. We hope this confluence of perspectives will offer powerful insights for and with our community." 

"Rutgers University",  "While machine learning tools that  train  data in order to optimize prediction have been in the background of our lives for many years now  the November 2022 release of one particular large language model  OpenAI's ChatGPT has now become a subject of research  discussion and controversy for educators everywhere. Chatbots of this kind work through statistical modeling of data that has been  scraped  from the Internet (usually without consent). As a result of this vast access to data and a great deal of human reinforcement  chatbots and other LLMs respond to prompts with human-like outputs that can be detailed and articulate--though which may be superficial  inaccurate  biased  or  confabulated.  Students  staff  and faculty alike are naturally keen to educate themselves about these new technologies: a process of shared learning that we think of in terms of critical AI literacy. Are chatbots useful for administrative tasks  teaching  or research? Or do their problems and known harms outweigh their benefits. We at OTEAR have been following these discussions carefully and staying up-to-the-minute even as we recognize the need to provide timely advice  useful information  and a few best practices for the consideration of our instructors  students  and colleagues. The resources provided by our AI Roundtable Council   TEACHING CRITICAL AI LITERACIES: Advice for the New Semester   will walk you through a brief history of AI  a discussion of critical AI literacy (which includes detailed information about the technology's harms and limitations)  advice on academic integrity  a sample of statements for your syllabi  and a list of resources. Several members of the council have also agreed to answer any follow-up questions that you have. Announcing the AI Roundtable  a space for the Rutgers community to come together to learn about and discuss issues related to AI in Higher Education. Events held in this space will include discussions about AI and pedagogy  academic integrity and generative language models  and professional use of AI as part of academic and administrative work. Learn what AI tools can and cannot do by reading up on these tools and experimenting with them before incorporating an AI tool into a class activity or restricting its use. Test your assignments by submitting them to ChatGPT and/or other AI tools to understand what these tools produce. Become familiar with the student conduct requirements for charging students with violations of academic integrity if your choice is to restrict its use. Resources available on the OTEAR Canvas site. Consider developing assignments that require students to use higher order thinking  connect concepts to specific personal experiences  cite class readings and discussions  and make innovative connections. These types of prompts are more difficult for students to answer using AI tools. Also consider project-based learning or staged assignments that begin with work in class  perhaps in groups  to be finalized by individual students as homework. Ideas about assignment design are also available on the OTEAR Canvas site. Develop rubrics that emphasize critical thinking  application of knowledge  and evaluation of knowledge rather than the restatement of material or summary. A sample rubric is given on the OTEAR Canvas site Develop clear policies for each course. For example  begin with the Rutgers code of conduct  which mandates  that all work submitted in a course  academic research  or other activity is the student s own and created without the aid of impermissible technologies  materials  or collaborations.  It is useful to repeat the learning goals of the course and how these goals are important in the decision making process to ban or permit AI tools. Consider the discussion in Section 4 of the Advice for the New Semester. Depending on whether AI tools will be banned or permitted  add text that clearly states the conditions specific for the course  such as these below:  Use of AI such as ChatGPT is not permitted in any stages of the writing process on any assignment. Use of AI such as ChatGPT is only permitted to help you brainstorm ideas and see examples. All material you submit must be your own.   Use of AI such as ChatGPT is fully permitted  but you must cite the tool and be able to explain any work that you submit.  Schools and departments should discuss these issues as the tools and their use evolve. OTEAR is available for consultation and discussion at any time via email."


"Indiana University Bloomington" , "Since 2020  there has been an exponential increase in the investment and development of generative artificial intelligence (AI) services. Generative AI is a type of artificial intelligence system that generates new text  images  or other media in response to prompts. Notable generative AI systems include ChatGPT  Microsoft Copilot  and Google Bard. Generative AI has potential applications across a wide range of industries  including art  writing  and software development. However  there are also concerns about the potential misuse of these tools and any data shared with the services. When you provide information to these tools  such as queries  student essays  grant proposals  source code  or datasets  it is the same as posting the information on a public website. Indiana University encourages its affiliates to experiment with using these generative AI services  as long as no institutional data is submitted to them without approval. At IU  Microsoft Bing Chat Enterprise is available for use by IU faculty and staff  and it is the recommended way to use generative AI within the IU environment. As part of the university's enterprise agreement with Microsoft  Bing Chat Enterprise is approved to interact with data classified up to and including University-Internal data . To use Bing Chat Enterprise  you must be logged in with your Microsoft 365 at IU  account (your @iu.edu email address and your IU passphrase). For information about browser and app compatibility  see About Bing Chat Enterprise/Copilot at IU. To date  no other generative AI tools have been approved for data beyond Public classification  and these have not been through the Software and Services Selection Process (SSSP). Prior to the sharing of any institutional data  these services will need to go through review to ensure the necessary contracts and safeguards are in place to protect the data submitted and to ensure the algorithms in use are ethical  transparent  and beneficial to the IU community. Types of institutional data that should not be submitted to public versions of generative AI tools  even when anonymized  include: Data classified as University-Internal or higher (for examples  visit the Data Classification Matrix ) Any data that may be considered student  faculty  or staff intellectual property  unless the individual submitting that intellectual property created it Specific examples that are not appropriate for the public versions of generative AI tools include: Sharing names and information about a real student  employee  research participant  or patient Asking an AI service to summarize and grade a student paper or assignment Sharing employee-related data such as performance or benefit information for communication drafting or analysis Asking an AI service to generate code for IU systems protecting institutional data or sharing IU source code for editing Sharing grant proposals still under review With these precautions in mind  there are numerous ways to use generative AI tools without submitting university data or intellectual property. Using general queries to generate content to pull information from the AI resources is a good way to engage with the products. Students should use generative AI in ways that align with university academic integrity policies and communicate with their instructors before using generative AI in their coursework. Schools and departments may elect to further restrict generative AI. From a data management perspective  examples of acceptable uses of generative AI include: Syllabus and lesson planning: Instructors can use generative AI to help outline course syllabi and lesson plans  getting suggestions for learning objectives  teaching strategies  and assessment methods. Course materials that the instructor has authored (such as course notes) may be submitted by the instructor. Correspondence when no student or employee information is provided: Students  faculty  or staff may use fake information (such as an invented name for the recipient of an email message) to generate drafts of correspondence using AI tools  as long as they are using general queries and do not include institutional data. Professional development and training presentations: Faculty and staff can use AI to draft materials for potential professional development opportunities  including workshops  conferences  and online courses related to their field. Event planning: AI can assist in drafting event plans  including suggesting themes  activities  timelines  and checklists. Reviewing publicly accessible content: AI can help you draft a review  analyze publicly accessible content (for example  proposals  papers and articles) to aid in drafting summaries  or pull together ideas. Even if you use generative AI tools for activities that do not share personal or institutional data  you should still check the tool's output for accuracy. Since these tools have been known to produce inaccurate content (sometimes called  hallucinations )  verify any factual information generated by an AI tool  and make sure to reference the tool as you would any other source."


"University of Kansas",  "The University of Kansas does not have a specific policy about use of generative artificial intelligence in teaching and learning. The University Senate Rules and Regulations do provide guidance on academic integrity  though Academic misconduct by a student shall include  but not be limited to  disruption of classes; threatening an instructor or fellow student in an academic setting; giving or receiving of unauthorized aid on examinations or in the preparation of notebooks  themes  reports or other assignments; knowingly misrepresenting the source of any academic work; unauthorized changing of grades; unauthorized use of University approvals or forging of signatures; falsification of research results; plagiarizing of another's work; violation of regulations or ethical codes for the treatment of human and animal subjects; or otherwise acting dishonestly in research. The KU Code of Ethical Conduct also provides guidance  emphasizing the importance of demonstrating accountability  modeling ethical standards  fostering honest pursuit of knowledge  ensuring originality of work  and attributing ideas drawn from others  intellectual work. To supplement those  we encourage faculty members to include a statement about permissible use of generative artificial intelligence in their classes. We provide examples below. A policy does not have to be extensive  but it should provide clear guidance to students on how they may and may not use generative AI in your class. We urge instructors to permit the use of ChatGPT and other tools wherever appropriate but also to talk with students about why you are approaching things as you are. Here are two examples. One is short. The other offers more explanation to students. The second version is from an editing class that Doug Ward  associate director of CTE  teaches. It can be easily adapted to nearly any discipline  though. You may use ChatGPT and other generative AI tools in this class in some instances. That includes generating ideas  outlining steps in a project  finding sources  getting feedback on your writing  and overcoming obstacles on papers and projects. Using those tools to generate all or most of an assignment  though  will be considered academic misconduct. If you are ever in doubt  ask. In your course work  you will be asked to explain in a reflection statement how you used any generative AI tools. Journalism  like many professions  is learning to adapt to generative artificial intelligence. No one knows what that adaptation might mean in the future  but it seems clear that you will need to know how to use AI tools in whatever career you choose. To help you gain those skills  we will experiment with Bing Chat  ChatGPT and other generative AI tools this semester  with a goal of learning to apply them in meaningful and ethical ways. At times  though  you will not be allowed to use AI. That s because the core skills an editor needs – critical evaluation  creativity  inquiry  collegiality – have nothing to do with technology. Generative AI is useless if you don t know how to evaluate and adapt what it produces. We will work at honing those evaluation and adaptation skills throughout the semester. I will tell you when we will use AI tools and when we won t. Do your work honestly. Turning in work you have cut and pasted from generative AI is academic misconduct. It s no different from cutting and pasting from a website. It is also academic misconduct if you use AI tools when you are asked not to. The goal is to use AI to help you improve your skills  not to avoid doing assignments. Read the university s policy on academic misconduct and the KU Code of Ethical Conduct and follow those in all your work. Explain your use of AI. If you use AI tools to assist in your work  include a paragraph explaining how you used them  how they helped you  and how you made the work your own. Include explanations of where AI wasn t effective or where it provided weak or false information. Also explain what you learned about prompting and how you can improve your prompting in the future. If you aren t sure at any time  ask. That s an important skill all journalists must learn. We understand the wait-and-see approach that many instructors have taken with generative AI  just as we understand the appeal of using AI detectors as a seemingly simple approach to upholding academic integrity. Neither waiting nor trying to prevent the use of AI will serve our students  though. We agree with the U.S. Department of Education  which said in May that it was  imperative to address AI in education now to realize key opportunities  prevent and mitigate emergent risks  and tackle unintended consequences.  Adapting to AI will be crucial for our students and our institutions  but it will also be crucial for democracy. The use of AI to create disinformation  to distort reality  and to mislead the public has already begun. We can push back against that by helping our students understand the workings of large language models and other forms of generative AI  and by helping them grapple with the ethics of AI. We can also help them use AI as a partner in discovery and learning. That will require some bold and perhaps uncomfortable steps. Many instructors banned the use of generative AI after ChatGPT was released and used AI detectors to try to root out offenders. Those detectors have far too many flaws to be reliable and were never intended as a sole indicator of cheating. They still have a place  but they provide information  not indictments. Instructor time is far better spent on helping students use AI responsibly than on trying to forbid AI in the learning process. That takes time. So does pursuing cases of academic misconduct  though.  An inflexible  top-down class policy on use of generative AI is very likely to fail. A better approach would be to talk with students about AI use in your discipline and work together on setting a class policy. When is it appropriate to use generative AI? When is it not? And why? Students can be excellent partners in working through these types of difficult issues. They are grappling with them  too  and having a class discussion helps them better understand the ethics of AI and makes it more likely they will follow the guidelines they help create. By looking at AI as a partner rather than a villain  we can begin to create policies that reflect the reality of an AI-augmented world. Ethical and responsible use of AI does not mean allowing students to turn in the unedited output of chatbots as original work. It does allow use of AI to generate ideas  outlines  and drafts; summarize articles; provide insights into data; and provide feedback on writing  coding  and problem-solving. (See An instructor guide to easing into generative AI.) It must include conversations with students about when not to use AI and how long-established practices help them gain critical skills. It should also include the routine use of reflective statements from students on how they use AI in the work they turn in. Discussions about ethics should be combined with building community and trust among students  and creating meaningful assignments. As much as we would like all faculty to integrate AI immediately  we expect most to do so in stages. To help  we are creating and curating tutorials  examples of AI use in classes  syllabus statements  prompting guides  ethics guidelines  and other materials for faculty and students. We are also planning workshops and discussions to help faculty to learn to use AI effectively  and we will encourage department and school conversations about applying consistent approaches to the use of AI. This will require time from instructors  and departments and schools must keep that in mind. Authentic assignments allow students to apply their developing knowledge to real-world situations  which can improve relevance and motivation (Wiggins and Grant  1998). These can take many forms  depending on the discipline. In general  though  authentic assignments involve application of learning in ways that students are likely to encounter in their careers  that allow students to share their learning outside the class  or that allow students to engage with outside communities or to apply disciplinary thinking to other fields or to a general audience. Students in a chemistry class create posters about how chemical interactions affect everyday life (hand-washing  auto exhaust  water purification). Students in a psychology class create an op-ed article in which they use the principles of psychology to add new perspectives to an event in the news. Students in a journalism class work with a non-profit agency to create messages about the importance of mental health for high-school students. Students in a physics class create a graphic explaining what caused a deep-water submarine to explode.Students in a biology class hold an end-of-semester festival for which students groups create displays and activities that help attendees learn about threatened species. Students in a film and media studies class develop video and social media messages about the importance of digital literacy. All of those examples helped students apply their learning in new ways. Generative AI offers powerful new opportunities to expand authentic assignments and to infuse them with technological skills that students will need in careers. In each of the examples above  generative AI could be used to generate ideas  provide examples  create images and illustrations  design posters and brochures  and create drafts of materials. It could also be used to create discipline-specific case studies or create interactive scenarios in which students grapple with real-world problems. Instructors could also challenge students to create examples of how generative AI could be used in various professions. That would help students learn more about potential careers while also considering ways that technology may change a profession. This provides a better opportunity to guide the use of AI tools so that students focus on areas instructors see as important. Class time is limited  though  and keep in mind that some students don t work well under time pressure. That will mean assignments need to be short enough to complete within a given class period. If your class is large and you feel you must use exams  consider two-stage exams or other types of group exams. Two-stage exams take different forms. A common approach is to have students take an exam individually and then take it again with a group. The group gets only one copy of the exam  though  and must agree on answers. This generates discussion about how students arrived at answers and takes advantage of curiosity students often have about how classmates answered various questions. Students get individual copies of the exam but work with partners or teams. The exam is open book  giving students an opportunity to revisit readings and discuss interpretations with colleagues. This approach also emphasizes application of learning rather than memorization of facts. These ideas and approaches will no doubt expand as we gain more experience in using generative AI. We encourage you to share your ideas  experiences  and discoveries. Doing so not only strengthens our community of teachers and learners but also benefits all our students."
"University of Tennessee  Knoxville" ,  "When using AI tools  it is important to be aware that the user data supplied might be utilized for training AI models or other purposes. Consequently  there is no guarantee that the information you provide will remain confidential. Instructors and students should exercise caution and avoid sharing any sensitive or private information when using these tools. Examples of such information include personally identifiable information (PII)  protected health information (PHI)  financial data  intellectual property (IP)  and any other data that might be legally protected. (i) Open Use Guidelines: Embrace and encourage AI use in assignments  with the requirement that students disclose any AI assistance. In this course  students are encouraged to use Generative AI Tools like ChatGPT to support their work. To maintain academic integrity  students must disclose any AI-generated material they use and properly attribute it  including in-text citations  quotations  and references. A student should include the following statement in assignments to indicate use of a Generative AI Tool:  The author(s) would like to acknowledge the use of [Generative AI Tool Name]  a language model developed by [Generative AI Tool Provider]  in the preparation of this assignment. The [Generative AI Tool Name] was used in the following way(s) in this assignment [e.g.  brainstorming  grammatical correction  citation  which portion of the assignment].  ii) Moderate Use Guidelines: Encourage AI use in specific assignments  but not all. Students must disclose any AI assistance. In this course  students are permitted to use Generative AI Tools such as ChatGPT for specific assignments  as designated by the instructor. To maintain academic integrity  students must disclose any use of AI-generated material. As always  students must properly use attributions  including in-text citations  quotations  and references. A student should include the following statement in assignments to indicate use of a Generative AI Tool:  The author(s) would like to acknowledge the use of [Generative AI Tool Name]  a language model developed by [Generative AI Tool Provider]  in the preparation of this assignment. The [Generative AI Tool Name] was used in the following way(s) in this assignment [e.g.  brainstorming  grammatical correction  citation  which portion of the assignment].  AI Policy: Not Permitted in this Course In this course  it is expected that all submitted work is produced by the students themselves  whether individually or collaboratively. Students must not seek the assistance of Generative AI Tools like ChatGPT. Use of a Generative AI Tool to complete an assignment constitutes academic dishonesty."

"Illinois Institute of Technology"  , "Faculty Guide on Teaching and Generative AI Illinois Tech s mission lends itself to authentic  student-centered teaching. In alignment with that mission  the Center for Learning Innovation guides instructors with best practices to prepare Illinois Tech students to critically and productively engage with new and innovative technologies–like generative AI–to become innovators and leaders of the future. CLI hosts events like the Learning Innovation Symposium to bring faculty together from across the university to discuss topics like generative AI and share successful strategies related to teaching and learning. Best practices include guidance and resources on student-centered teaching with AI  from developing syllabus language  aligning the use of generative AI to course learning objectives and developing assessments. Academic Affairs  the Galvin Library  CAC and the Center for Ethics in the Profession also have a number of resources on generative AI. As generative AI continues to evolve  CLI will continue to identify  curate  develop  and distribute best practices to support instructors and student success at Illinois Tech. Guiding principles to inform best practice in teaching with generative AI Clear and frequent communication with students is essential. Students need transparency when it comes to instructor expectations and the use of AI in the classroom. Expectations around AI use will vary from class to class. Frequent discussions about instructor expectations  course learning objectives  and the relationship between them with the related learning activities and student work—including the use of generative AI—enhances student learning experiences and minimizes opportunities for misunderstanding or misuse. Generative AI systems are technology tools. And like other technology tools like Blackboard  Zoom  and even Google search  generative AI can be used to positively support rigorous learning and enhance engaging learning experiences. The use of generative AI will evolve. Instructors and students should use generative AI responsibly  purposefully  and ethically. If supported by the course learning objectives  instructors should design assessments and learning activities in a way that students can use generative AI as opportunities to learn. Students can better achieve their course learning objective and learn more about the benefits and challenges when using generative AI. 1 of 4 Best practices to consider as you plan your course in light of generative AI Use backwards design concepts to align course learning objectives to assessments and related active learning activities. Doing so can reveal how generative AI could be used to make a positive impact in your course. Post clear expectations on the use of AI in your course syllabus. Academic Affairs provides some brief examples of possible language. Externally  many additional examples are being collected by Lance Eaton from instructors around the country and posted in an open Google Doc; WCET highlighted 3: No use of AI  All work submitted in this course must be your own. Contributions from anyone or anything else- including AI sources  must be properly quoted and cited every time they are used. Failure to do so constitutes an academic integrity violation  and I will follow the institution s policy to the letter in those instances.  A theater course at a small liberal arts college. Some use of AI  You might be permitted to use generative AI tools for specific assignments or class activities. However  assignments created with AI should not exceed 25% of the work submitted and must identify the AI-generated portions. Presenting AI-generated work as your own will have consequences according to university policies. Importantly  while AI programs like ChatGPT can help with idea generation  they are not immune to inaccuracies and limitations. Further  overreliance on AI can hinder independent thinking and creativity. Note that  in the spirit of this policy  it was written in part by ChatGPT.  A marketing course at a public university Significant Use of AI  Within this course  you are welcome to use generative artificial intelligence (AI) models (ChatGPT  DALL-E  GitHub Copilot  and anything after) with acknowledgment. However  you should note that all large language models have a tendency to make up incorrect facts and fake citations  they may perpetuate biases  and image generation models can occasionally come up with offensive products. You will be responsible for any inaccurate  biased  offensive  or otherwise unethical content you submit regardless of whether it originally comes from you or an AI model. If you use an AI model  its contribution must be cited and discussed: · What was your prompt? · Did you revise the Ai model s original output for your submission? · Did you ask follow-up questions? · What did you learn? Having said all these disclaimers  the use of AI models is encouraged  as it may make it possible for you to submit assignments and your work in the field with higher quality and in less time.  A graduate level library sciences course at a public university If you use text-matching software or anti-plagiarism checkers such as Blackboard s SafeAssign or IIT s own chatGPT detector  first  be sure to post that notice in your syllabus.Then encourage your students to use the tools as well. These tools compare submitted work against work in its own databases (typically other users in the same class or institution) and sometimes around the web. Tools may also report if the text resembles or is generated by generative AI. Students can use the tool as a means to ensure compliance with the class's policy on academic honesty and the use of 2 of 4 generative AI. Also mention to your students that in cases of possible infringement of your course policy  a result from one or more of these tools may be used as circumstantial evidence to report the student's infringement to the DDAD. Finally  do keep in mind that the results of these tools only reveal similarity (ie  drafts and final versions of work submitted may result in 100% similarity). Reports based on these tools are typically the starting point for additional conversations before investigating actual policy infringement or actual plagiarism. If you embrace the use of generative AI in your course  avoid making its use a requirement  unless you plan to also offer alternative ways to achieve similar objectives. It is a question making your course accessible: not all students may have the same access or the ability to use generative AI. Offering alternatives is also a general principle in universal design for learning  and can help make your course more accessible for all learners. Integrating AI tools  or motivating compliance with relevant rationale  can be more effective than banning  restricting and detecting AI-generated content with technology tools. Like many other software/apps available on the web (free or not)  access to AI-based tools requires users to agree with specific terms of service and privacy policies. Instructors and students should carefully read these documents and understand the risks associated with their use  prior to accepting the terms."



